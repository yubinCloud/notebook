---
title: Gated RNN
date: 2022-03-31 10:43:50
permalink: /pages/b4c94a/
categories:
  - 深度学习
  - 鱼书进阶-自然语言处理
tags:
  - 
---

上一章的 RNN 存在环路，可以记忆过去的信息，但这个 RNN 的效果并不好。原因在于，许多情况下它都无法很好地学习到时序数据的长期依赖关系。目前简单的 RNN 经常被名为 LSTM 或 GRU 的层所代替。实际上，当我们说 RNN 时，更多的是指 LSTM 层。

LSTM 和 GRU 中增加了一种名为“门”的结构。基于这个门，可以学习到时序数据的长期依赖关系。我们将介绍代替它的 LSTM 和 GRU 等“Gated RNN”，研究 LSTM 的结构并揭示它实现“长期记忆”的机制。

## 1. RNN 的问题

