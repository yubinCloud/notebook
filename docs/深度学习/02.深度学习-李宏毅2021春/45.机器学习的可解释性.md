---
title: 机器学习的可解释性
date: 2022-04-28 11:21:06
permalink: /pages/lhy/explainable-ml/
categories:
  - 深度学习
  - 深度学习-李宏毅2021春
tags:
  - 
---

之前训练的模型可以根据我们的 input 得到 output，但我们不满足于此，我们想要机器给出它得到答案的理由，这就是 <mark>Explainable 的 Machine Learning</mark>。

## 1. Why we need Explainable ML?

**Correct answers ≠ Intelligent**，就算今天机器可以得到正确的答案，也不代表它一定非常聪明。举一个例子，过去有一个神马汉斯，据说可以算数学题，你问它根号 9 等于多少，它会敲三下就停下来，旁边的人就会欢呼。后来有人发现说，它其实是通过侦测到周围人微妙的情感变化来决定什么时候停下跺马蹄，而并不是真的会解数学问题。今天我们看到的种种 AI 的应用，有没有就可能跟神马汉斯一样呢？

**在今天很多真实应用中，可解释性的 model 往往是必须的**：

+ loan issuers are required by law to explain their models.
+ Medical diagnosis model is responsible for human life. Can it be a black box?
+ If a model is used at the court, we must make sure the model behaves in a nondiscriminatory manner.
+ If a self-driving car suddenly acts abnormally, we need to explain why.

**更进一步说，如果 model 具有解释力的话，那未来我们可以凭借着解释的结果，再去修正我们的模型**。现在的 DL 在改进模型时需要调一些 hyperparameter，但我们期待未来，在 DL 犯错的时候，我们可以知道它错在什么地方，为什么犯错，这样也许就有更好的办法来 improve 我们的 model。

## 2. Interpretable v.s. Powerful



