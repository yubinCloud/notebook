---
title: 机器学习攻略
date: 2022-04-03 19:39:56
permalink: /pages/22f046/
categories:
  - 深度学习
  - 深度学习-李宏毅2021春
tags:
  - 
---

## 1. General Guidance

训练模型的过程中，以下就是如何让你做得更好的攻略：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220403195635625.png" alt="image-20220403195635625" style="zoom:67%;" />

当对训练结果不满意时（testing data 的 loss 太大），首先应检查你的 training data，看看你的 model 有没有在 training data 上学起来，再去看 testing 的结果。**如果你发现你的 training data 的 loss 很大，显然它在训练集上面也没有训练好**，接下来你要分析一下在训练集上面没有学好是什么原因。一种原因是 model bias，一种是 optimization 的问题。

### 1.1 model bias

所谓 **model bias 的意思是说，你的 model 太过简单**。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20210311205956634.png" alt="img" style="zoom:80%;" />

举例来说，我们现在写了一个有未知 parameter 的 function，这个未知的 parameter，我们可以代各种不同的数字，你代 $\theta ^1$ 就可以得到一个 function $f_{\theta ^1}(x)$，代 $\theta ^2$ 就可以得到一个 function $f_{\theta ^2}(x)$，把所有的 function 集合起来，可以得到一个 function set。

**如果 model 太简单，那么这个 function set 太小了，使得它没有包含任何一个 function 可以让我们的 loss 变得够低**。这时即便找到这里面最好的那个 function $f_{\theta ^*}(x)$，依然无济于事，这个 loss 还是不够低。

这个状况就像你想要在大海里面捞针，这个针指的是一个 loss 低的 function，结果针根本就不在海里面。

**Solution：重新设计一个 model，给你的 model 更大的弹性**。比如增加输入的 features、设计一个更大的 model …

### 1.2 optimization issue

但是并不是 training 的时候，loss 大就代表一定是 model bias，你可能会遇到另外一个问题：**optimization 做得不好**。

我们可能卡在一个 <mark>local minima</mark> 的地方，这时你没有办法找到一个真的可以让 loss 很低的参数，如图：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20210311213108040.png" alt="img" style="zoom: 67%;" />

这就好像是说我们想大海捞针，针确实在海里，但是我们却没有办法把针捞起来。

这就产生了一个问题：**training data 的 loss 不够低的时候，到底是 model bias，还是 optimization 的问题呢**？一个建议判断的方法，就是你可以透过比较不同的模型，来得知你的 model 现在到底够不够大。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20210311214054168.png" alt="image-20210311214054168" style="zoom:67%;" />

举一个例子，如上图，有两个 network，一个有 20 层，一个有 56 层，现在我们把它们测试在测试集上，这个横轴指的是 training 的过程。随着参数的 update，当然你的 loss 会越来越低,但是结果 20 层的 loss 比较 56 层的 loss还高，这说明 56 层的 network 的 optimization 没有做好，因为 20 层 network 能做到的事，56 层可以轻而易举地做到。

所以如果 56 层的 optimization 成功的话，它的 loss 应当是比 20 层的 network 低的。

那么，**我们怎样知道我们的 optimization 有没有做好**？这边给的建议是：看到一个你从来没有做过的问题，也许你可以先跑一些比较小的、比较浅的network，这些 model 会竭尽全力地找出一组最好的参数，不太会有失败的问题。所以我们可以先 train 一些比较简单的 model，先可以知道它们可以得道什么样的 loss。

<font color="blue">If deeper networks do not obtain smaller loss on training data, then there is optimization issue.</font>

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20210313203557412.png" alt="img" style="zoom:67%;" />

+ 这个 5 layer 的 model 就是 optimization 没有做好

如果 optimization 没有做好该怎么办？我们会在之后讲。

### 1.3 overfitting

假设你现在经过一番的努力，你已经可以让 training data 的 loss 变小了，那接下来你就可以来看 testing data loss，如果它仍很大，那可能真的遇到 overfitting 的问题了。

> 注意，**training 的 loss 小，testing 的 loss 大，才有可能是 overfitting**，而不是一看到 testing 上结果不好就说是 overfitting 了。

什么是 overfitting 不再介绍了。

