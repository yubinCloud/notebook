---
title: 生成对抗网络 GAN
date: 2022-04-17 17:52:01
permalink: /pages/7a65ba/
categories:
  - 深度学习
  - 深度学习-李宏毅2021春
tags:
  - 
---

## 1. Generation

### 1.1 Network as Generator

今天要讲的主题是 **Generation** 这件事情。

之前学的 Network 都是一个 function，给一个 input x 得到一个 output y。而所要学的新的主题是把 network 当做一个 generator 来使用。**特别之处在于现在 network 的输入会加上一个 random 的 variable，即加一个 $z$，而这个 $z$ 是从一个 distribution 中 sample 出来的**。所以现在的 network 可以看成同时从 $x$ 和 $z$ 中得到输出 $y$。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417180213822.png" alt="image-20220417180213822" style="zoom:67%;" />

这个 network 怎样同时看 x 和 z 呢？可以直接拼接起来，也可以相加作为 input …

**$z$ 特别的地方是，它不是固定的**。每次 z 都从一个 distribution 中 sample 一个出来。**这个 distribution 有一个限制：它必须够简单**，这样我们可以知道它的 formulation 并从中 sample。它可以是 uniform distribution，够简单就行了。

每次一个 x 进来时，都从 distribution 中 sample 一个 z，来得到 y，这样随着 sample 的 z 不同，y 也就不同。也就是说，**同样的 x 作为输入，随着 sample 到的 z 不同，经过一个复杂的 network 转换后就变成了一个复杂的 distribution**。图示：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417201241473.png" alt="image-20220417201241473" style="zoom:67%;" />

**这种可以输出一个 distribution 的 network，我们就叫它** <mark>generator</mark>。

### 1.2 Why distribution?

为什么我们需要 generator 的输出是一个 distribution？比如在 video prediction 中，给你的 network 过去的游戏画面，然后它的输出是新的游戏画面。这时候，在训练资料里面，同样的输入再面对转角时，有时候小精灵往左转，有时候往右转，这两种可能性同时存在于训练资料里面，Network 要两面讨好，处理这个问题的一种可能性就是让机器的输出是有几率的：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417202232845.png" alt="image-20220417202232845" style="zoom:67%;" />

**当我们的任务需要一点创造力的时候**，更具体说就是我们想要找一个 function，**同样的输入有多种输出，而且这些不同的输出都是对的，就需要 generator 的 model**。

比如画图这件事就需要一点创造力：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417202657185.png" alt="image-20220417202657185" style="zoom:80%;" />

还比如对话这种事：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417202814659.png" alt="image-20220417202814659" style="zoom:67%;" />

+ 我们问机器说辉夜是谁，其实每个人可能都有不同的答案，这时候就需要 generative 的 model。

## 2. GAN

generative 的 model 中，有一个非常知名，它就是 <mark>Generative Adversarial Network</mark>（**GAN**），我们主要就是介绍它，发音就是 gàn。

它有很多很多的变形，在 GitHub 上可以找到一个 GAN 的 zoo：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417203337948.png" alt="image-20220417203337948" style="zoom:67%;" />

### 2.1 Example：Anime Face Generation

我们举一个让机器生成二次元人物的脸的例子，它是一个 **unconditional generation**，就是我们这边先把 x 拿掉：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417203540867.png" alt="image-20220417203540867" style="zoom:80%;" />

之后讲到 conditional generation 的时候会再把 x 加回来。拿掉 x 后，generator 的输入就是 z 了。<u>之后我们都假设 z 是一个从 normal distribution 中 sample 出来的一个 vector</u>，这个 vector 通常是一个 low-dimensional 的 vector，它的维度是你自己决定的。

一张图片就是一个非常高维的向量，所以 generator 实际上做的事情就是產生一个非常高维的向量，比如 64 × 64 × 3 的 tensor 表示 image。

当从 distribution 中 sample 出不同的 z，输出的 y 都不一样。那我们希望不管这边 sample 到怎样的 z，输出都是动画人物的脸：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417204041070.png" alt="image-20220417204041070" style="zoom:67%;" />

> 为什么是 normal distribution 呢？也可以是别的，但经验是**不同的 distribution 之间的差异，可能并没有真的非常大**。只要是一个够简单的 distribution 就可以了，network 会对应到一个复杂的 distribution 中。

### 2.2 Discriminator

**在 GAN 中，一个特别的地方是，除了 generator 外，我们还要训练另外一个东西，叫做** <mark>discriminator</mark>。它的作用是，它会拿一张图片作为 input，其 output 是一个数值，这个 discriminator 本身也是一个 neural network，是一个 function：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417210543264.png" alt="image-20220417210543264" style="zoom:67%;" />

它输出的 scalar 越大，表示输入的 image 越像真的二次元人物的图像。举例来说：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417210639865.png" alt="image-20220417210639865" style="zoom: 67%;" />

**至于 generator 和 discriminator 的架构长什么样子，你完全可以自己设计，只要有你要的输入输出就可以了**。

### 2.3 Basic idea of GAN

为什么要多一个 disciminator，这要讲一个故事：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417210935981.png" alt="image-20220417210935981" style="zoom: 80%;" />

+ 物竞天择之下，蝴蝶越来越像树叶，以免别天地吃掉。而比比鸟为了吃掉蝴蝶，也逐渐进化越来越不容易被骗过。最终完成了从蝴蝶到枯叶蝶的进化。
+ 在这个过程中，蝴蝶就是 generator，比比鸟就是 discriminator。

现在回到 generator 要画出二次元的人物，disciriminator 就是要去分辨出 generator 的输出和真正的图片：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417211343582.png" alt="image-20220417211343582" style="zoom:67%;" />

+ 一开始 generator 会乱画，这时 discriminator 很容易地根据是否有两个黑眼睛就能分别出真假；之后 generator 调整参数进化了，它为了骗过 discriminator 就画出了眼睛，而后 discriminator 也会进化，开始从嘴巴进行分辨 ……

generator 与 discriminator 之间有一个对抗的关系，就用了 <mark>adversarial</mark> 这个字眼，这只是一个拟人化的说法而已。

### 2.4 Algorithm

下面正式讲一下这个演算法长什么样子。network 训练之前，要**先初始化 generator 和 discriminator 的参数**。

#### step 1：Fix generator G, and update discriminator D

初始化完参数以后，接下来训练的第一步是定住你的 generator，只 train 你的 discriminator。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417212119550.png" alt="image-20220417212119550" style="zoom:67%;" />

+ discriminator 训练的目标是要分辨真正的二次元人物和 generator 產生出来的二次元人物

这种分辨可能是把真正的人物标 1，generator 产生的人物标 2，这就成了一个分类或者 regression 的问题了。具体怎么做，看你喽。

####  step 2：Fix discriminator D, and update generator G

我们训练完 discriminator 以后，接下来定住 discriminator 改成训练 generator。如何训练呢？**拟人化的讲法就是让 generator 想办法去骗过 discriminator**。

实际上的操作方法是：从 distribution 中 sample 出一个 vector 输给 generator，产生一个图片，把它丢给 discriminator，discriminator 会给这个图片一个分数，而 generator 的训练目标就是让这个 discriminator 输出高分，这就意味着 generator 骗过了 discriminator。图示如下：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417214115031.png" alt="image-20220417214115031" style="zoom: 67%;" />

更具体一点，我们可以将 generator 和 discriminator 两个 network 直接接起来当成一个大的 network 来看待，其中某一层的输出代表一张图片：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417215040532.png" alt="image-20220417215040532" style="zoom:67%;" />

至于怎么调 network 的参数，这根训练一般的 network 没什么不同。所以现在讲了两个步骤：

+ step 1：Fix generator G, and update discriminator D
+ step 2：Fix discriminator D, and update generator G

接下来就是反复地训练两个 network：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417220759991.png" alt="image-20220417220759991" style="zoom:67%;" />

### 2.5 示例 Anime Face Generation 的结果

生成二次元人脸的任务，到底可以做到什么样的程度呢？

2000 次的结果如下：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417221310946.png" alt="image-20220417221310946" style="zoom:67%;" />

五万次的结果如下：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417221240299.png" alt="image-20220417221240299" style="zoom:67%;" />

使用 StyleGAN 可以做到下面这个样子：<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417221359408.png" alt="image-20220417221359408" style="zoom:67%;" />

除此之外还有一个 **progressive GAN** 可以产生真是人脸：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417221441996.png" alt="image-20220417221441996" style="zoom:67%;" />

在两个向量之间做内插 interpolation，可以看到这两个向量对应的图片中间的逐渐变化过程：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417221545459.png" alt="image-20220417221545459" style="zoom:67%;" />

用 BigGAN 甚至可以做到产生下面的图片：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417221632458.png" alt="image-20220417221632458" style="zoom:67%;" />

还产生了奇怪的网球狗：<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220417221714205.png" alt="image-20220417221714205" style="zoom:50%;" />

## 3. Theory behind GAN

接下来我们告诉你，为什么 Generator 和 Discriminator 的互动可以让 Generator 产生像是真正人脸的图片。

### 3.1 Our objective

先搞清楚我们的**目标是什么**。在训练 network 时，我们先定一个 loss function，然后用 gradient descent 去调参，最终 minimize 那个 loss 就结束了。我们在 Generation 问题中，要 minimize 的东西是这个样子：

+ 给它一堆从 distribution 中 sample 出来的 vector
+ 丢进 Generator 后，会产生一个比较复杂的 distribution，称之为 <mark>$P_G$</mark>
+ 我们还有另一对 data，这个真正的 data 也形成了另外一个 distribution，称之为 <mark>$P_{data}$</mark>

**我们期待的是 $P_G$ 与 $P_{data}$ 越接近越好**。以一维的状况为例：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220418210550749.png" alt="image-20220418210550749" style="zoom: 50%;" />

+ Generator 的 input、output 和 真正的 data 都是一维 vector

我们期待的是绿色和蓝色的分布越接近越好，写成式子就是：

$$G^* = \arg\min_G \color{blue}{Div}(P_G, P_{data})$$

+ Div 是 <mark>Divergence</mark>（**散度**），可以理解成两个 distribution 之间的某种距离。散度越小，就代表两个 distribution 越像。

这样其实我们就是找一个 Generator 里面的参数，使得这个 Generator 产生出来的 $P_G$ 跟 $P_{data}$ 之间的 Divergence 越小越好。

但我们遇到一个问题：**用在这种 continues 的 distribution 上面的 Divergence 是很难算的**。我们算不出这个 Divergence，那有如何去找 $G^*$ 呢？这就是我们在 train 这种 generator 时会遇到的问题。而 **GAN 有一个神奇的做法，它可以突破“我们不知道怎么计算 Divergence”的限制**。

### 3.2 Sampling is good enough …

现在我们的问题是不知道怎样计算 Divergence，而 **GAN 告诉我们，你不需要知道 $P_G$ 和 $P_{data}$ 实际上的 formulation 长什么样子，而只要能从他们这两个 distribution 中 sample 东西出来，就有办法计算 Divergence**。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420202334209.png" alt="image-20220420202334209" style="zoom:67%;" />

+ 从图库中随机 sample 出来一些图片，就得到 $P_{data}$ sample 的结果
+ 从 simple distribution 中 sample 出一些 vector，丢进 Generator 中，产生出来的图片就是从 $P_G$ 中 sample 的结果

### 3.3 Discriminator

靠 **Discriminator** 的力量，GAN 可以在只做 sample 的前提下去估测出 Divergence。

现在有了下面两种数据去训练 discriminator：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420203735077.png" alt="image-20220420203735077" style="zoom:67%;" />

它的**训练目标**是：看到 real data 就给高分，看到 generative data 就给低分。这个过程可以当成一个 optimazation 的问题，写成如下的式子：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420203952082.png" alt="image-20220420203952082" style="zoom:67%;" />

+ $E_{y\sim P_{data}}[\log D(y)]$ 表示一堆 y 是从 $P_{data}$ 中 sample 出来，即他们是真正的 image，把他们丢进 D 里得到一个分数，再取 $\log D(y)$
+ $E_{y\sim P_G}[\log(1-D(y))]$ 表示另一部分 y 是从 $P_G$ 经 Generator 产生出来的，这些图片丢进 Discriminator 里得到一个分数，再取 $\log(1-D(y))$

在这里，Discriminator 想要 maximize 的 function 称为 <mark>Objective Function</mark>。

> 我们要 maximize 的 function 叫 **Objective Function**，要 minimize 的 function 叫 **Loss Function**。

我们希望这个 objective func $V$ 越大越好。就是希望：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420210420848.png" alt="image-20220420210420848" style="zoom:67%;" />

这个 objective func 不一定非要写成这样，当初写成这个样子是为了与 binary classification 扯上关系，因为这个 func 就是 Cross Entropy 乘以一个负号，所以这相当于我们想 minimize Cross Entropy，也就等于在训练一个 classifier：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420210727037.png" alt="image-20220420210727037" style="zoom:67%;" />

最神奇的是：<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420210834571.png" alt="image-20220420210834571" style="zoom:50%;" />，也就是这个 objective func 的最大值是跟 Divergence 有关的，**因此我们不知道怎么算 Divergence 没关係，train 我们的 Discriminator，train 完之后，看看它的 Objective Function 可以到多大，那个值就跟 Divergence 有关**。

我们不再证明 objective func 为什么跟 Divergence 有关，但直观上看一下：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420211243465.png" alt="image-20220420211243465" style="zoom:50%;" />

+ 假设 $P_G$ 和 $P_{data}$ 之间的 Divergence 很小，也就是两者很像，这时很难分开他们，这个问题也就很难，在解这个 Optimization Problem 时，就没有办法让这个 objective func 的值很大
+ 如果两者很不像，那很轻易将其分开，这个 Objective Function 就可以冲得很大。

所以既然这个 objective func 的最大值跟 Divergence 有关，即：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420212426438.png" alt="image-20220420212426438" style="zoom:50%;" /></center>

那我们可以直接把我们不会算的 Div 换成红框框的部分，于是就有了

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420212534770.png" alt="image-20220420212534770" style="zoom:67%;" /></center>

+ 我们要找一个 Generator $G^*$，去 minimize 红色框框里面的
+ 而红色框框中的这件事，又是另外一个 Optimization Problem，它是在给定 Generator 的情况下，去找一个 Discriminator，这个 Discriminator 可以让 $V$ 这个 objective func 越大越好

之前我们讲的 Generator 跟 Discriminator 互动、互相欺骗的过程，其实就是想解这个问题：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420213147540.png" alt="image-20220420213147540" style="zoom: 50%;" />

那你可能问，为什么用 JS Divergence 而不是别的 Divergence 呢？完全可以，只要改了 objective func 就可以量各式各样的 Divergence：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220420213345950.png" alt="image-20220420213345950" style="zoom:50%;" />

但实际上，GAN 还是很不好 train 的，所以俗话说，No Pain, No Gan。

## 4. Tips for GAN

接下来我们就要讲一些 GAN 训练的小技巧。