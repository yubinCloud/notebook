---
title: Auto-encoder
date: 2022-04-25 11:00:34
permalink: /pages/0d6241/
categories:
  - 深度学习
  - 深度学习-李宏毅2021春
tags:
  - 
---

## 1. Self-supervised Learning Framework

先简短看一下 Self-Supervised Learning 的 Framework：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220425165002280.png" alt="image-20220425165002280" style="zoom: 67%;" />

这个过程中不用标注资料的学习叫做 **Self-Supervised Learning**，也有人叫 **Pre-Training**。学会之后就可以用把 model 用于其他下游的任务里。

在有 BERT、GPT 之前，还有一个更古老的不需要用标注资料的任务，就叫做 Auto-Encoder，所以你也<u>可以把 Auto-Encoder 看作是 Self-Supervised Learning 的一种 Pre-Train 的方法</u>。

## 2. Auto-Encoder

### 2.1 简介

我们用影像来做例子讲解 Auto-Encoder 是怎么运作的：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220425170054928.png" alt="image-20220425170054928" style="zoom:67%;" /></center>

在 Auto-Encoder 中有两个 network，一个叫做 Encoder，一个叫做 Decoder：

+ Encoder 把一张图片读进来，输出一个 vector，接下来这个 vector 会变成 Decoder 的输入；
+ Decoder 会产生一张图片，所以它的架构可能会像 GAN 的 Generator。

**训练的目标**是希望Encoder 的输入跟 Decoder 的输出越接近越好。这个事情也有人叫它 <mark>Reconstruction</mark>。

> 这个 idea 与 Cycle GAN 相同，Cycle GAN 是需要两个 Generator，第一个 G 把 X domain 的 image 转到 Y domain，另一个 G 再把 Y domain 的 image 转回来，并希望最原先的图片跟转完两次后的图片越接近越好。

这个训练过程不需要任何的标注资料，所以它是一个 Unsupervised Learning 的方法。对于 Encoder 输出的 vector，有多种叫法：Embedding、Representation、Code。

怎么把 Train 的 Auto-Encoder 用在 Downstream 的任务里面呢？它**常用于降维**，通常 Encoder 的 input 是一个 high dim，而 output 是 low dim。中间这个 Encoder 的输出又叫做 <mark>Bottleneck</mark>（瓶颈），形容 Auto-Encoder 输入输出都很宽，中间特别窄。Encoder 做的就是把 high dim 转成 low dim，这个过程也叫 <mark>Dimension Reduction</mark>。

> 在很多不是 deep learning base 的 machine learning 中，也有很多 Dimension Reduction 的技术，比如 PCA、t-SNE。

### 2.2 Why Auto-Encoder?

Auto-Encoder 到底好在哪呢？把一个 high dim -> low dim 有什么样的帮助呢？

> 在神雕侠侣中，杨过与樊一翁 PK，樊一翁的武器除了一根钢杖以外，还有他的胡子，他可以甩动胡子当作软鞭，很厉害。但杨过说三招之内减掉他的胡子，而且成功了，这时怎么做到的？因为杨过发现，鬍子是由头所操控的，**虽然鬍子甩开来有两丈那么长，但头能做的变化是有限的**。于是杨过直接打他的头，这样樊一翁不得不闪避，从而逼着他这个胡子所能够动的路线变得有限，然后打败了樊一翁。

那 Auto-Encoder 所做的“把一张图片压缩又还原回来”为什么能成功呢？如下图，我们假设本来的 image 是 3 × 3，Encoder 的 output 是 2 dim，这时怎么有可能从 2 dim 去还原 3 × 3 的 image 呢？

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220425174354626.png" alt="image-20220425174354626" style="zoom:80%;" /></center>

能够做到这件事情是因为，**对于影像来说，并不是所有 3 × 3 的矩阵都是 image，image 的变化其实是有限的**。你随便 sample 一个矩阵，通常都不会是你会看到的图片。当变化受限后，假如将图片收集起来发现说只有两个类型（如上图），其他类型根本就不是你一般在训练的时候会看到的状况，那 Encoder 就可以只用两个维度就可以描述一张 image 了，这样看到第一个类型就让左边维度是 1，看到第二个类型就让右边维度是 1。这就对应到刚才这个樊一翁的例子：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220425175004797.png" alt="image-20220425175004797" style="zoom: 80%;" />

Encoder 做的事情就是化繁为简，本来比较复杂的东西,它只是**表面上比较复杂，事实上它的变化其实是有限的**，就可以用比较简单的方法来表示它。

如果我们可以把复杂的图片，用比较简单的方法来表示它，那么在下游的任务里面，我们可能就只需要比较少的训练资料就可以让机器学到我们本来要它学的事情。以上就是 Auto-Encoder 的概念。

### 2.3 Auto-encoder is not a new idea

Auto-Encoder 从来都不是一个新的想法。Deep Learning 之父 Hinton 在 06 年的 Science 的 paper 中就提出了 Auto-Encoder 的概念，只是那时候的 network 与现在的不太一样，那时候的 Auto-Encoder 长这样：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220425211047273.png" alt="image-20220425211047273" style="zoom: 67%;" />

那时候人们觉得 deep 的 network 是 train 不起来的，每一层应该分开训练，所以用了一个叫做 Restricted Boltzmann Machine（**RBM**，受限玻尔兹曼机）的技术，它将每一层分开 train，等每一层 train 好后再全部接起来做微调，注意它微调的是 pre-train 的 model，这个过程在今天看来就成了 pre-train 的 pre-train。如今很少再提到 Restricted Boltzmann Machine 了，因为它没什么必要。这里也只是想说 Auto-Encoder 不是新的概念，而是一个非常有历史的概念。

### 2.4 De-noising Auto-Encoder

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220425213201805.png" alt="image-20220425213201805" style="zoom:80%;" /></center>

De-noising 的 Auto-Encoder 是说把原来要输进去给 Encoder 的图片，加上一些 noisy，再传给 Encoder，通过 Decoder 试图还原未加入杂讯的图片。所以现在这个 network 还多了一个要学会自己去掉杂讯的任务。

如果你看今天的 BERT 的话，也可以把它看作一个 De-Noising 的 Auto-Encoder，在 BERT pre-train 中会加 masking，那些 masking 其实就是 noise，BERT 的 model 就是 Encoder，output 就是 Embedding：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220425222049498.png" alt="image-20220425222049498" style="zoom: 80%;" />

BERT 的输出就是 Embedding，接下来有一个 Linear 的模型，就是 Decoder，Decoder 要做的事情就是还原原来的句子，也就是把填空题被盖住的地方还原回来。所以我们说 BERT 就是一个 De-Noising 的 Auto-Encoder。

上图中，Decoder 也不一定非要是 Linear。我们换一个说法，最小的 BERT 有 12 层，那我们可以将第 6 层的输出是 Embedding，那剩下的 6 层就是 Decoder。总之这个 Decoder 不一定非要是 Linear。