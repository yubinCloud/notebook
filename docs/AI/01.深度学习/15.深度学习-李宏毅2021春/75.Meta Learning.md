---
title: Meta Learning
date: 2022-10-01 09:16:07
permalink: /pages/lhy/meta-learning/
categories:
  - AI
  - 深度学习
  - 深度学习-李宏毅2021春
tags:
  - 
---

Meta Learning: Learn to learn（学习如何学习）

> What does “meta” mean? meta-X = X about X

Can machine automatically determine the hyper-parameters?

## 1. 回顾 Machine Learning

Machine Learning = Looking for a function

**step 1: Function with unknown**

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001092728938.png" alt="image-20221001092728938" style="zoom:72%;" />

**step 2: Define loss function**

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001092901925.png" alt="image-20221001092901925" style="zoom:72%;" />

**step 3: Optimization**

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001093245180.png" alt="image-20221001093245180" style="zoom:72%;" /></center>

## 2. Introduction of Meta Learning

### 2.1 What is Meta Learning?

其实“学习”这件事，它本身也是一个 function F：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001094058012.png" alt="image-20221001094058012" style="zoom:72%;" /></center>

$F$ 的 input 是 training dataset，output 是一个 model。在 typical ML 中，这里的 learning algorithm $F$ 是 hand-crafted 的，而 <mark>Meta Learning</mark> 就是研究 “Can we learn this function $F$?”

怎么找这个 F 呢？Following the same three steps in ML!

### 2.2 Meta Learning - Step 1

What is **learnable** in a learning algorithm?

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001094947175.png" alt="image-20221001094947175" style="zoom:72%;" />

之前我们将 model 中 learnable parameters 记作 $\theta$，这里我们将 meta learning 中 learnable components 记作 <mark>$\phi$</mark>，相对应的 F 就记为 <mark>$F_\phi$</mark>。

根据什么是 learnable components $\phi$，可以将 meta learning 分成多个种类。

### 2.3 Meta Learning - Step 2

这一步我们需要 Define loss function $L(\phi)$ for learning algorithm $F_\phi$。这样如果 $L(\phi)$ 小的话说明 $F_\phi$ 是一个好的 learning algorithm，反之则是不好的 learning algorithm。

How to define $L(\phi)$? 什么情况下 $L(\phi)$ 应该小呢？如下图所示：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001193549307.png" alt="image-20221001193549307" style="zoom:72%;" />

那我们怎样知道一个 classifier 是好还是坏呢？我们可以 Evaluate the classifier on testing set。图示如下：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001194031345.png" alt="image-20221001194031345" style="zoom:72%;" />

这里怎样计算 loss $l^1$ 呢？计算方式和之前的 machine learning 是差不多的，图示如下：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001194833091.png" alt="image-20221001194833091" style="zoom:67%;" />

这里在测试资料上计算出来的 loss $l^1$ 越小，就代表我们训练出来的 classifier 越好，这样也就代表我们的 learning algorithm 越好。反之亦然。

注意这里的 $F_\phi$ 是一个能够学出 binary classifier 的 learning algorithm，我们上面是在一个 apple 与 orange 的 binary classification 的 task 来评价它的，**但在 meta learning 中，我们不会只拿一个 task 来评价一个 binary classifier learning 的 algorithm $F_\phi$**，而是还会拿其他的 binary classification 的 task 来评价。如下图所示：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001195852322.png" alt="image-20221001195852322" style="zoom:67%;" />

在这里，左右两个 learning algorithm $F_\phi$ 是一样的，但 input 的资料不一样，那 output 的 binary classifier 也不一样。把所有 task 上得到的 loss 加起来，就得到了最终的 total loss $L(\phi)$。

> 这里的举例只讲了两个 task，但实际上你会有非常多的 task，那么 $L(\phi) = \sum^N_{i=1}l^i$

到了这里，有一点你可能觉得怪怪的。在 typical ML 中，你是用 training examples 去计算 loss，**但在 meta learning 中，你却是用 training tasks 的 testing example 来计算的 loss**。这一点 meta learning 与 typical ML 是不同的，在做 meta learning 时，我们是拿 task 作为的训练单位，所以你是可以将 training tasks 的 testing example 用于训练过程中。在之后讲完 meta learning 的整个流程，你会更加清晰。

### 2.4 Meta Learning - Step 3

我们已经有了 learning algorithm 的 loss function $L(\phi)=\sum^N_{i=1}l^i$，现在我们要做的是寻找到能够 minimize $L(\phi)$ 的 $\phi$，即 $\color{blue}{\phi^*} = \arg\min L(\phi)$。

怎么做呢？Using the optimization approach you know:

+ If you know how to compute $\frac{\partial L(\phi)}{\partial \phi}$ => *Gradient descent is your friend.*
+ What if $L(\phi)$ is not differentiable? => *用 RL / Evalutionary Algorithm 硬 train 一发*

反正不管你用什么方法，你最终可以学习出一个 “learning algorithm” $F_{\color{blue}{\phi^*}}$

整个 meta learning 的 framework 如下图所示：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001202936086.png" alt="image-20221001202936086" style="zoom:74%;" /></center>

+ 我们先从 training task 中学习出一个 learned “learning algorithm” $F_{\phi^*}$，然后给他输入 testing task 中的 training examples，得到一个 classifier $f_{\theta^*}$，这时再把这个 classifier 用在 testing task 的 testing examples 里面得到我们想要的结果。
+ 在这个过程中，testing task 是我们真正关心的 task，而 training tasks 是与 testing task 无关的 tasks，这些 training tasks 就是用来寻找出 learned 的演算法 $F_{\phi^*}$。

像这种学习的演算法厉害在哪里呢？一种东西叫做”few-shot learning“，即”小样本学习“，它期待机器只看几个 training example 就可以让 model 学会做 classification。**而在这里 meta learning 中，testing task 就只需要 little labeled training data 就可以**。

**通常想要实现 few-shot learning，这种演算法是人类难以想象出来的，往往需要 meta learning 来把这个演算法给找出来**。所以注意区分好 few-shot learning 与 meta learning 的微妙区别。

> 在 meta learning 中，单说”training data“是很容易造成误解的，所以使用时要小心。在很多 paper 中就很不讲究，很多说的 training data 很容易导致误解。

### 2.5 ML v.s. Meta

#### 2.5.1 Goal

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001210356592.png" alt="image-20221001210356592" style="zoom:72%;" />

#### 2.5.2 Training Data

+ 在 machine learning 里面，我们是拿一个 task 的 training set 来进行训练；
+ 在 meta learning 里面，我们是拿“task”来进行训练，也就是用 training tasks 来进行训练，在每一个 training task 里面，都有 training data 和 testing data。

为了避免对“训练资料”这个说法产生歧义，在 meta learning 中，一个 training task 里面的 training examples 称为 <mark>Support set</mark>，testing examples 称为 <mark>Query set</mark>。在一些文献中就是这么叫的。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001225153142.png" alt="image-20221001225153142" style="zoom:67%;" />

 

#### 2.5.3 Training

+ 在 machine learning 中，我们是有一个 hand-crafted 的 learning algorithm，然后把训练资料丢进去，得到一个训练的 classifier $f_{\color{green}{\theta^*}}$
+ 在 meta learning 中，我们是有一堆 training tasks，然后我们是要用这一堆 training tasks 去得到一个 learned “learning algorithm” $F_{\color{blue}{\phi^*}}$

这里，把 meta learning 的这种 involve 一大堆 tasks 的训练叫做 <mark>Across-task Training</mark>

；而把一般 ML 的训练叫做 <mark>Within-task Training</mark>。这样就可以区别两种 training 的过程了：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001232645243.png" alt="image-20221001232645243" style="zoom:67%;" />

#### 2.5.4 Testing

我们把 meta learning 中这个 testing 过程叫做 <mark>Across-task Testing</mark>，而一般 ML 的 testing 过程叫做 <mark>Within-task Testing</mark>，图示如下：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001234414544.png" alt="image-20221001234414544" style="zoom:67%;" />

在 meta learning 中，我们要测试的不是一个 classifier 的好坏，而是一个 learning algorithm 的好坏，因此**在一个 Across-task Testing 中，还包含了 Within-task Training  和 Within-task Testing 过程**。在有些文献中，一次 Within-task Training 加一次 Within-task Testing 的流程叫做一个 <mark>Episode</mark>。

#### 2.5.5 Loss

typical ML 与 meta learning 的 loss 计算方式也不一样：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001235018279.png" alt="image-20221001235018279" style="zoom:67%;" />

+ ML 的 L 是从一个 task 中算出来的；
+ Meta learning 的 L 是从一把 tasks 中算出来的。

我们单独看一下 meta learning 中 $L(\phi)$ 的计算：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001235645349.png" alt="image-20221001235645349" style="zoom:67%;" />

+ 在进行一次 Across-task training 计算 $L(\phi)$ 时，需要计算多个 $l^i$，而每一个 $l^i$ 的计算都需要经过一个 Within-task training + Within-task testing 的 Episode，计算量还是很大的。
+ 在“Learning to initialize”系列的 paper 中，也称 Across-task training 叫做 **Outer Loop**，称 Within-task training 叫做 **Inner Loop**。

#### 2.5.6 两者的相似点

// TODO
