---
title: Life Long Learning
date: 2022-09-16 10:44:48
permalink: /pages/lhy/life-long-learning/
categories:
  - AI
  - 深度学习
  - 深度学习-李宏毅2021春
tags:
  - 
---

<mark>Life Long Learning</mark>（**LLL**）比较符合人们对 AI 的幻想：

<center><img src="C:\Users\yubin\AppData\Roaming\Typora\typora-user-images\image-20220916104819831.png" alt="image-20220916104819831" style="zoom:80%;" /></center>

+ 人们教他一个 task，他就学会一个 task，最终他就变成了“天网”从而统治人类。

Life Long Learning 有很多很潮的名字：Continuous Learning、Never Ending Learning、Incremental Learning。

在 real-world application 中，LLL 也是有用处的：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916105403356.png" alt="image-20220916105403356" style="zoom:67%;" /></center>

## 1. Catastrophic Forgetting

### 1.1 Catastrophic Forgetting 是什么

下面通过一些 example 来说明 Life Long Learning 的一个难点：Catastrophic Forgetting。如下图所示，假设我们有如下两个 task（这看起来像是同一 task 的两个不同 domain，但目前文献上说的就是这样，还做不到真的两个完全不同的任务），我们现在 task 1 上训练一个 model，可以看到其结果在 task 2 也已经达到了 96% 的正确率了，效果非常好，然后我们继续把这个学好的 model 放到 task 2 上去继续学，学完后分析结果发现，这个 model 预期般地在 task 2 上 performance 更好了，但 task 1 上的 performance 却变得很差了，它发生了遗忘：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916110401418.png" alt="image-20220916110401418" style="zoom:67%;" /></center>

也许你会认为可能是因为 model 大小有限，导致其能力有限，从而导致其学完 task 2 后就忘了 task 1。那接下来看另外一个实验：如下图，我们把 task 1 和 task 2 的训练资料倒在一起同时去训练这个 model，可以发现这个 model 是可以同时学好两个 task 的：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916110923520.png" alt="image-20220916110923520" style="zoom:67%;" /></center>

这说明这个 model 有能力同时学好两个 task，但如果依次去学习这两个 task，它会遗忘旧的 task。

这种现象是很普遍的，在一个 QA 的任务上，这个任务是 Given a document, answer the question based on the document. 这个任务使用的是 bAbi corpus，它是一个很小的数据集，包含了 20 个 QA task，如下图：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916132723497.png" alt="image-20220916132723497" style="zoom:80%;" /></center>

用该数据集训练 model，结果如下：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916133356643.png" alt="image-20220916133356643" style="zoom:67%;" /></center>

+ 左图表示一次用 20 个 task 来训练 model，纵轴表示它在 task 5 上的 accuracy，可以看到当训练完 task 5 后 performance 很好，但一旦用 task 6 训完，它在 task 5 上的 accuracy 就直接掉到 0 了
+ 右图表示同时训练这 20 个 task，每个点表示在某个 task 上的 accuracy，可以看到这个 model 是可以在多个 task 上都表现很好的。

所以我们说 machine “是不为也，非不能也”。这种遗忘很厉害的现象称为 <mark>Catastrophic Forgetting</mark>（**灾难性遗忘**）：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916135616510.png" alt="image-20220916135616510" style="zoom:67%;" /></center>

### 1.2 为什么不用 multi-task training 来解决

根据刚刚说的，那你可能觉得将多个 task 的资料一块训练就可以了，这种方式叫做 <mark>Multi-task training</mark>，但这会导致 Computation issue 和 Storage issue：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916140338649.png" alt="image-20220916140338649" style="zoom:80%;" /></center>

> 这就好比说，你要让一个人学一门新的课，他学的时候还得把以前学过的也再看一遍才不至于遗忘。

Multi-task training can be considered as the upper bound of LLL. 因此在做 LLL 研究时，往往先跑个 multi-task training 的结果，知道它的 upper bound 在哪里，然后再比较新的技术和这个 upper bound。

### 1.3 为什么不 train a model for each task

+ Eventually we cannot store all the models …
+ Knowledge cannot transfer across different tasks.

### 1.4 Life-Long learning v.s. Transfer learning

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916151759272.png" alt="image-20220916151759272" style="zoom: 67%;" /></center>

+ transfer learning 只关注在 task 2 上的 performance
+ life-long learning 同时关注在 task 1 上的 performance

## 2. Evaluation

在讲 life-long learning 之前，我们先讲一下对 LLL performance 的**评估方法**。

首先我们需要一系列的 task：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916153100486.png" alt="image-20220916153100486" style="zoom:67%;" /></center>

+ 在图片的上面部分中，task 1 是正常的手写数字辨识，task 2 其实也是，只不过这里面的图片是 task 1 中的图片经过某种固定规律转换过来的。甚至有的直接将图片旋转个 15 度来作为新的 task。
+ 图片的下面部分中，task 1 是分类 0 和 1，task 2 是分类 2 和 3 …

然后我们就可以进行 life-long learning，并对 model 建立如下 evaluation：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220916170211883.png" alt="image-20220916170211883" style="zoom:67%;" /></center>

其中 $R_{i,j}$：after training task i, performance on task j

