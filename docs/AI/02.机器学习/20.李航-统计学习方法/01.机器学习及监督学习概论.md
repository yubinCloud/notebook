---
title: 机器学习及监督学习概论
date: 2022-07-27 10:51:49
permalink: /pages/ml/statistical-learning-method/supervised-overview/
categories:
  - AI
  - 机器学习
  - 李航-统计学习方法
tags:
  - 
---

## 1. 统计学习方法的定义与分类

### 1.1 统计学习的概念

统计学习已经应用到了生活中的众多领域，比如人工智能、模式识别、数据挖掘、自然语言处理、语音处理、计算视觉、信息检索、生物信息等。

<mark>统计学习</mark>（**Statistical Machine Learning**）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。它所研究对象就是数据，假设同类的数据具有一定的统计规律，那么就可以利用概率统计方法对其处理，从而达到一个对数据分析和预测的目的。

-  以计算机和网络为<u>平台</u> 
-  以数据为<u>研究对象</u> 
-  以预测和分析数据为<u>目的</u> 
-  以方法为<u>中心</u> 
-  是多领域交叉的<u>学科</u>

简而言之，统计学习实现了一个从已知到未知的过程，利用已知数据和各种学科理论来对未知的新数据进行一个预测和分析。

### 1.2 统计学习的步骤

::: theorem Procedures
1. 得到一个有限的训练数据集合
2. 确定学习模型的集合【模型】
3. 确定模型选择的准则【策略】
4. 实现求解最优模型的算法【算法】
5. 通过学习方法选择最优模型
6. 利用学习的最优模型对新数据进行预测或分析
:::

第一步是要得到一个有限的训练数据集合，也就是用来训练模型的。接下来，确定学习模型的集合，这个集合称之为**假设空间**。然后，选择模型，而选择模型需要一定的评价准则，这就是第三步中确定模型选择的准则，我们称之为**策略**。第四步是实现求解最优模型的算法，也就是根据第三步的策略，通过算法实现模型的选择。最后，通过学习方法也就是第 2-4 步，选择出一个最优模型，再将用以预测的数据代入到最优模型中，进行一个预测和分析。

这里注意一下，第二步中的模型，第三步里的策略，还有第四步的算法，是统计学习的三要素，这三个要素一起构成了学习系统：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727110435742.png" alt="image-20220727110435742" style="zoom:67%;" /></center>

如上图所示，首先给定一个训练集，这里面假设包含N个样本，然后放入到学习系统里面，学习系统就包含了模型、策略和算法，然后通过学习系统对于训练集中信息的不断学习，得到了一个最优模型，也就是对应了之前第五步。最后，输入一个新的实例，代入到最优模型中，通过预测系统得到了一个新的输出，也就是对于新数据进行的预测和分析。这就是统计学习方法的一个大概步骤。

### 1.3 统计学习方法的分类

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/640" alt="图片" style="zoom:50%;" /></center>

从模型角度来进行分类，可以分为概率模型与非概率模型，线性模型与非线性模型，参数化模型与非参数化模型。

+ 关于概率模型与非概率模型，概率模型就是用条件概率分布的形式表达的模型 $f(Y|X)$ ，而非概率模型，则是用函数形式表达的 $y=f(x)$。常见的决策树、朴素贝叶斯都属于概率模型，而感知机、支持向量机、神经网络，这些就属于非概率模型了。
+ 关于线性模型与非线性模型，如果模型函数是线性的，那么就是线性模型，反之，是非线性模型。
+ 参数化模型，就是说模型的参数维度是固定的，可以由有限为的参数来刻画。那么非参数化模型就对应着参数维度不固定，所以参数化模型它更适用于简单问题，而非参数化模型，更适用于比较复杂的现实问题。
+ 从算法的角度来分类，分为在线学习和批量学习。在线学习也就是大家熟知的Online Learning。每次接受一个样本，然后预测学习模型，之后不断重复这个步骤。批量学习就是Batch Learning，一次接受所有的数据，然后学习模型进行预测。
+ 按技巧分类，按技巧它分为贝叶斯学习和核方法，贝叶斯学习就是基于贝叶斯定理的一个学习方法，而核方法则是基于核函数的。

## 2. 统计学习方法的基本分类

监督学习、无监督学习、半监督学习，是根据学习的数据中数据所包含的标记信息来区分的。

- 所学习的数据具有标注信息——监督学习；
- 所学习的数据不具有标注信息——无监督学习；
- 所学习的数据，只含有少量标注信息，大多数没有——半监督学习；

这一篇中，我们主要讲解一下监督学习和无监督学习，强化学习这一部分，带着大家简单了解一下。

### 2.1 监督学习

<mark>监督学习</mark>（**Supervised Learning**）是指从标注数据中学习预测模型的机器学习问题，其本质是学习输入到输出的映射的统计规律。

几个概念：

+ **输入空间**（Input Space）：输入的所有可能取值的集合
+ **实例**（Instance）：每一个具体的输入，通常由特征向量（Feature Vector）表示
+ **特征空间**（Feature Space）：所有特征向量存在的空间
+ **输出空间**（Output Space）：输出的所有可能取值的集合

大多时候，输入空间和特征空间是相同的。既然说到大多时候，那就肯定存在不同的时候了，比如支持向量机中，核技巧的基本思想，就是通过一个非线性变换，将输入空间对应到特征空间上。

根据变量的不同类型，要解决的问题可以分为回归问题、分类问题和标注问题：

- 输入变量与输出变量均为连续变量的预测问题——**回归问题**
- 输出变量为有限个离散变量的预测问题——**分类问题**
- 输入变量与输出变量均为变量序列的预测问题—— **标注问题**

以下是相应的**符号表示**：

+ 输入变量 $X$；输入变量的取值 $x$
+ 输出变量 $Y$；输出变量的取值 $y$
+ 输入实例 x 的 feature vector 表示：$x = (x^{(1)},x^{(2)},\dots,x^{(n)})^T$
+ 以 $x_i$ 表示多个输入变量中的第 i 个变量：$x_i = (x_i^{(1)},x_i^{(2)},\dots,x_i^{(n)})^T$
+ 样本容量为 N 的训练集：$T = \{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\}$

对于监督学习，主要就是研究输入到输出之间的统计规律，所以要有关于输入和输出的基本假设：

+ 监督学习的基本假设：X 和 Y 具有联合概率分布 $P(X,Y)$
+ 监督学习的目的：学习一个输入到输出的映射，这一映射以模型表示
+ 模型的形式：条件概率分布 $P(Y|X)$ 或决策函数 $Y=f(X)$
+ 假设空间（Hypothesis Space）：所有这些可能模型的集合

**映射关系以模型来表示的话，主要有两种，一种是条件概率分布的形式，一种是决策函数的形式**。条件概率分布的形式其实就是概率模型，而决策函数的形式就是非概率模型。对具体的输入进行相应的输出预测时，表达为：

$$P(y|x) \ 或 \ y=f(x)$$

流程图如下：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727142802263.png" alt="image-20220727142802263" style="zoom:75%;" /></center>

通过学习系统学习到的模型用加一个帽子表示，即 $\hat f$ 或 $\hat P$。然后，给一个新的实例，这个输出也可以表达成决策函数或者条件概率分布预测值的形式，之所以通过 argmax，选择使条件概率分布最大的y值，就是因为**我们预测的思想就是想找到出现的可能性最大的值**。

### 2.2 无监督学习

<mark>无监督学习</mark>（**Unsupervised Learning**）是指从无标注数据中学习预测模型的机器学习问题，其本质是学习数据中统计规律或潜在结构。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727143255267.png" alt="image-20220727143255267" style="zoom:75%;" /></center>

对于无监督学习，无标注数据，自然直接得到的数据只有输入，输出是隐含的潜在内容。

几个概念：

+ 输入空间：$\mathcal{X}$
+ 隐式结构空间：$\mathcal{Z}$
+ 模型：函数 $z=g(x)$ **或**条件概率分布 $P(z|x)$ **或**条件概率分布 $P(x|z)$
+ 假设空间（Hypothesis Space）：所有这些可能模型的集合
+ 目的：选出在给定评价标准下的最优模型
+ 样本容量为 N 的训练集：$U = {x_1, x_2,\dots,x_N}$

因为无监督学习，本质是研究数据中的潜在结构内容，也就是需要学习隐含在数据结构内部的信息，所以无监督学习对应的不是输出空间，而是隐式结构空间。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727143737519.png" alt="image-20220727143737519" style="zoom:75%;" /></center>

### 2.3 强化学习

强化学习其实要强调一个互动，互动是指的是智能系统与环境之间的一个连续互动，通过这个互动，学习一个最优的行为策略。可以参见李宏毅讲解的一章。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727144002687.png" alt="image-20220727144002687" style="zoom:67%;" /></center>

强化学习可以基于策略，也可以基于价值，基于策略的则是选择最优策略，基于价值是选择最优价值，都可以得到一个最优模型。

## 3. 统计学习方法的三要素

构成统计学习方法的三要素——**模型、策略、算法**。对于监督学习、无监督学习、强化学习，这三要素都是必备的，只不过形式不同。

对于监督学习，处理的是有标注的数据，数据中输出空间的类型已知，所以相应的模型、策略以及算法都是比较具体的。但对于无监督学习，处理的数据是无标注信息的，我们希望找到隐含在数据内部的结构信息，这时候的三要素——模型、策略、算法就不那么具体了。

### 3.1 监督学习的三要素

#### 3.1.1 监督学习的模型

对于监督学习，模型主要可以表达成两种形式，一个是条件概率分布的形式，一个是决策函数的形式。条件概率分布的形式，即概率模型；而决策函数的形式则是非概率模型。

<mark>假设空间</mark>（Hypothesis Space）是所有可能的条件概率分布或决策函数，用 $\mathcal{F}$ 表示。

**如果模型是由决策函数组成的集合**，那么假设空间将是所有可能决策函数的集合。每一个决策函数由一个参数向量决定，而假设空间是由参数向量所决定的函数组构成。我们称所有可能的参数向量组成的空间为**参数空间**，那么这个假设空间就应该是由参数空间决定的了。

+ 若 Hypothesis Space 是决策函数的集合：$\mathcal{F}=\{ f | Y=f(X)\}$
+ $\mathcal{F}$ 由一个参数向量决定的函数族构成：$\mathcal{F} = \{ f|Y=f_\theta(X), \theta \in \mathbf{R}^n\}$
+ 参数空间：$\Theta = \{ \theta| \theta \in \mathbf{R}^n\}$

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727145646811.png" alt="image-20220727145646811" style="zoom:75%;" /></center>

**如果模型表示为条件概率分布的形式**，那么假设空间就是由所有可能的条件概率分布组成的集合。对于每一个条件概率分布，它由一个参数向量来决定的，所以假设空间也可以说成是由一个参数向量决定的条件概率分布族构成的。此处，所有可能的参数构成参数空间。

+ 若 Hypothesis Space 是决策函数的集合：$\mathcal{F} = \{ P|P(Y|X)\}$
+ $\mathcal{F}$ 由一个参数向量决定的条件概率分布族构成：$\mathcal{F} = \{ P|P_\theta(Y|X), \theta \in \mathbf{R}^n\}$

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727150023099.png" alt="image-20220727150023099" style="zoom:75%;" /></center>

#### 3.1.2 监督学习的策略

如何在 Hypothesis Space 里面选择一个最优模型呢？这里就需要用到第二个要素策略。策略其实就是一种学习准则，用来选择最优模型的。想要选择模型，那么一定要知道如何度量模型的好坏。所以，这里先要引入几个概念。

+ <mark>损失函数</mark>：度量模型一次预测的好坏，记作 $L(Y, f(X))$，这里的 Y 是 label
+ <mark>风险函数</mark>：度量平均意义下模型预测的好坏

$$R_{exp}(f) = E_P[L(Y,f(X))]=\int_{\mathcal{X}\times \mathcal{Y}}L(y,f(x))P(x,y)dxdy$$

> $R_{exp}(f)$ 中 exp 表示 expectation，R 表示 Risk，f 表示模型，其计算就是对损失函数求了一下概率期望。如果对于假设空间中的每一个模型，我们都求一下风险函数值，选择一个最小的风险函数值所对应的模型就是我们想要的最优模型了。但是联合分布 $P(x,y)$ 并不是已知的，因此风险函数也就不能直接求出，所以我们需要一个经验值（估计值）来替代这个函数，也就引出了“经验风险”。

+ <mark>经验风险</mark>：模型 $f(X)$ 关于训练集的平均损失 $R_{emp}(f) = \frac{1}{N} \sum^N_{i=1}L(y_i,f(x_i))$，其中训练集 $T = \{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\}$

> emp 表示 empirical

下面我们看几种常见的损失函数：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727152000844.png" alt="image-20220727152000844" style="zoom:80%;" /></center>

**根据大数定律，当样本容量 N 趋于无穷大的时候，经验损失就会趋于风险函数**。所以，在一定程度上用经验损失作为风险函数的估计值是合理的。公式如下：

$$R_{emp}(f) \to R_{exp}(f), \qquad N \to \infty$$

可是在现实生活中，样本容量N一般是有限的，有的时候甚至会很小。因此，**仅仅用经验风险来估计风险函数效果并不理想，需要对其进行一定的矫正**。这里就涉及到监督学习的两个基本策略，一个是经验风险最小化策略，一个是结构风险最小化策略：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727152419887.png" alt="image-20220727152419887" style="zoom:90%;" /></center>

<u>当样本容量 N 足够大的时候</u>，可以认为经验风险是风险函数的一个估计值，此时，只需选取使经验风险最小的模型即可。<u>但当样本容量 N 比较小的时候</u>，仅仅经验风险最小化，容易造成过拟合的现象，于是引入结构风险的概念。结构风险是在经验风险的基础上加了一个惩罚项，惩罚项针对的是模型的复杂度，也就是这里的模型越复杂，J(f) 就越大，当然模型越简单，J(f) 就越小。**结构风险的惩罚系数，可以平衡经验风险和模型的复杂度**。结构风险最小化，则是选取一个使结构风险最小的模型。

关于监督学习的策略，追根究底，就是选取一个目标函数，可以是经验风险，或者是结构风险，然后通过优化这个目标函数，达到学习模型的目的。

#### 3.1.3 监督学习的算法

在假设空间里面，根据策略去选择最优模型，需要一个具体的操作方案，操作方案也就是算法，是用来求解最优模型的。

如果这个最优模型存在显式解析解，那么简单了，直接把这个结果写出来即可。但是往往这个显式解是不存在的，所以需要一定的数值计算方法，比如梯度下降法。

### 3.2 无监督学习的三要素

无监督学习处理的是无标注的数据，所以我们希望在数据内部找到隐含的结构信息。

+ 模型：函数 $z=g_\theta(x)$ **或**条件概率分布 $P_\theta(z|x)$ **或**条件概率分布 $P_\theta(x|z)$
+ 策略：优化目标函数
+ 算法：通常是迭代算法

模型中涉及到的 z 来自于隐式结构空间，此时模型有三种表达方式，一种是函数形式，另外两种是条件概率分布的形式。

假设空间：

- 所有可能的函数所组成的集合
- 给定 x 的条件下，所有可能的 z 的条件概率分布组成的集合
- 给定 z 的情况下，所有可能的 x 的条件概率分布组成的集合

参数空间，则是由所有可能的参数组成的。

对于无监督学习，策略同样是优化目标函数。当然，因为无监督学习处理的数据是无标注信息的，更具有多变性，相应的目标函数会根据数据的不同而发生变化。

## 4. 模型的评估与选择

对模型进行评估时，我们主要从模型对已知数据和未知数据的预测能力来看，需要用到训练误差与测试误差。对于一个模型而言，如果训练误差低，测试误差高，那么容易出现过拟合的现象，与之相对的是欠拟合，这是训练误差高，测试误差低时容易出现的情况。本节将对这部分进行讲解。

### 4.1 Evaluation: Training Error & Test Error

关于模型拟合的好坏，我们可以通过训练集计算训练误差来度量。以训练集代表已知数据，**训练误差就反映了模型对已知数据的拟合能力**。

关于模型的预测效果，可以通过测试集来度量。我们以测试集代表未知数据。假如存在一个样本容量为N'的测试集，我们将测试集中所有的实例都放到预测系统里面，根据之前训练出的模型，就可以计算出一系列的预测值。这些预测值与真实值之间的差异，就是测试误差，通常**以测试误差来度量模型对未知数据的预测效果**。

#### 4.1.1 Training Error

+ 学习到的模型：$Y=\hat{f}(X)$
+ Training Set：$T = \{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\}$
+ Training Error：$R_{emp}(\hat{f}) = \frac{1}{N} \sum^N_{i=1}L(y_i,\hat{f}(x_i))$

训练误差是训练数据集的平均损失，具体来说就是先计算出训练集上每个样本的损失，然后再计算平均值。

#### 4.1.2 Test Error

+ 学习到的模型：$Y=\hat{f}(X)$
+ Test Set：$T' = \{(x_1',y_1'),(x_2',y_2'),\dots,(x_N',y_N')\}$
+ Test Error：$e_{test} = \frac{1}{N'} \sum^{N'}_{i=1}L(y_i',\hat{f}(x_i'))$

测试误差是根据测试数据集所得。具体来说，就是计算测试集中每个样本点的损失，再求平均值。

#### 4.1.3 误差率与准确率

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727161921023.png" alt="image-20220727161921023" style="zoom: 80%;" /></center>

注：$r_{test} + e_{test} = 1$

当计算测试误差时，选取的损失函数是一个 0-1 示性函数，那么就可以得到误差率。所以说，误差率与准确率其实是测试误差的两个特例。

具体解释一下这里所用的示性函数：

- 通过训练出来的模型所得到的预测值，不等于真实值的时候，记损失为 1;
- 通过训练出来的模型所得到的预测值，等于真实值的时候，记损失为 0.

这就可以看出，**误差率体现的是在测试集中预测错误的样本点的个数占测试集样本总个数的比例**，**准确率则是预测正确的样本点个数占测试集样本总个数的比例**。很明显，误差率和准确率之和为 1。

### 4.2 Model Selection

在模型选择时，我们当然希望训练误差和测试误差都很小，但是当训练误差很小的时候，测试误差并不一定小，因此需要二者的一个平衡。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727163304309.png" alt="image-20220727163304309" style="zoom:67%;" /></center>

以 M 代表模型的复杂度，M 越大模型越复杂。橙色的这条折线代表的是测试误差，度量模型对于未知数据的预测能力。蓝色的折线代表的是训练误差，度量模型对已知数据的预测能力。

选择模型的时候，一定要注意：防止过拟合的现象出现。即遵循奥卡姆剃刀原理，选择的模型既要有良好的拟合效果，复杂度又适当，或者说选择使训练误差和测试误差同时达到比较小的模型。

## 5. 正则化与交叉验证

### 5.1 Regularization

#### 5.1.1 正则化项

追溯到模型结构上，过拟合往往由于模型结构太过复杂而导致，欠拟合则是由于模型结构太简单。

为了平衡模型的对已知数据和未知数据的预测能力，我们在原来的经验风险上加上了**正则化项**，以此度量模型复杂度。**经验风险与正则化项一起构成结构风险函数**。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727164034447.png" alt="image-20220727164034447" style="zoom:80%;" /></center>

<mark>正则化</mark>，就是通过使结构风险最小化来实现的。在正则化的一般形式中，目标函数为结构风险。其中**，第一部分是经验风险**，用以度量模型在训练集中的平均损失，**第二部分被称为正则化项或惩罚项**：

+ **$J(f)$ 度量模型的复杂度**，一般模型参数越多，模型越复杂，$J(f)$ 就越大。
+ **系数 $\lambda$ 用以调整经验风险和模型复杂度之间的关系**。 $\lambda$ 越大，模型选择时越重视泛化能力，选出来最优模型参数越少；与之相对地，系数越小，越重视拟合能力，选出来的最优模型可能会出现过拟合。

> 这是因为，如果 λ 很大，J(f) 的微小变化都能引发结构风险的一个很大的变化，那么，通过正则化就会压缩模型复杂度，则会避免过拟合的现象出现。但是，如果 λ 非常小，J(f) 的巨大变化才能引发结构风险的一个很小的变化，那么，此时通过正则化就无法降低模型复杂度了。因此，系数 λ 的选择是个关键。

我们的目的是选择拟合能力和泛化能力都很强的模型。

#### 5.1.2 L1 与 L2 范数

正则化项有很多种形式，最常见的就是 L1 与 L2 范数：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727164609905.png" alt="image-20220727164609905" style="zoom:80%;" /></center>

<mark>L1 范数</mark>即参数绝对值之和，更适用于特征筛选。它倾向于选择出一个稀疏的模型。稀疏模型指的是非零参数个数很少的模型。

<mark>L2 范数</mark>即参数的平方和，主要用以防止过拟合现象的出现。L2 正则化项的构成，使得在正则化的时候，参数可以无限的接近于 0，但是与 L1 范数不同，这里参数只是接近于 0，很难出现直接等于 0 的情况。所以，这一类正则化项可以使得模型越来越简单，防止过拟合现象的出现，但无法起到特征筛选的作用。

> 再说一下，为什么 L2 范数这里有一个 $\frac{1}{2}$？这主要是出于数学运算的方便。求极值时，如果使用求导的方法，那么 $\frac{1}{2}$ 恰好可以约去。

正则化，就用来选择经验风险和模型复杂度同时都很小的模型。这种思想非常符合奥卡姆剃刀原理。

::: note 奥卡姆剃刀原理
在模型选择时，选择所有可能模型中，能很好解释已知数据并且十分简单的模型。
:::

### 5.2 Cross Validation

在样本的数据量足够充足的情况下，通常可以将数据集随机地**分为训练集、验证集和测试集**三部分：

+ Training Set：用于训练模型
+ Validation Set：用于选择模型
+ Test Set：用于最终对学习方法的评估

通常，我们假设验证集中有足够多的数据，这样，通过 training set 所得到的模型放入 validation set 里，选择预测误差最小的那个模型，就是最优模型了。

但现实情况中，样本数据通常是不充足的。那么，为了选择一个好的模型，可以采用交叉验证的方法。**交叉验证的基本思想就是：重复使用数据，以解决数据不足的这种问题**。

这里我们介绍三种交叉验证法，简单交叉验证，S折交叉验证，还有留一交叉验证：

#### 5.2.1 简单交叉验证

<mark>简单交叉验证法</mark>是将数据集随机的分为两个部分，一个作为训练集，一个作为测试集。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727194443900.png" alt="image-20220727194443900" style="zoom:80%;" /></center>

举个例子，假如我们将样本的 70% 作为训练集，30% 作为测试集，那么在不同的情况下，可以通过训练集得到不同的学习模型，将学习训练得到的不同模型放到测试集上，计算测试误差，测试误差最小的模型则是最优模型。

#### 5.2.2 S 折交叉验证

<mark>S 折交叉验证</mark>，随机将数据分为 S 个互不相交、大小相同的子集，其中以 S-1 个子集作为训练集，余下的子集作为测试集。

下面通过一个例子来说明。假如 S=10，我们可以将数据集均匀的分为 T1，T2，......  T10 这十个子集，那么可以将其中九个子集的并集作为训练集，剩余的那个子集作为测试集：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727195047677.png" alt="image-20220727195047677" style="zoom:80%;" /></center>

比如将 T1-T9 的并集作为训练集，用于训练模型，所得模型记做 M1。通过类似的方法，我们还可以得到模型 M2，M3，...... M10。分别在每个模型相应的测试集中计算测试误差，并进行比较，测试误差最小的模型，就是最优模型。

#### 5.2.3 留一交叉验证

<mark>留一交叉验证</mark>，可以认为是S折交叉验证的特殊情况，即 S=N 的情况，这里的 N 指的是数据集的样本容量。留一交叉验证，leave-one-out cross validation，也就是每次用N-1个样本训练模型，余下的那个样本测试模型。这是在数据非常缺乏的情况下才使用的方法。