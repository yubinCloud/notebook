---
title: Sequence Labeling
date: 2022-11-13 15:26:29
permalink: /pages/ml/lhy/sequence-labeling/
categories:
  - AI
  - 机器学习
  - 李宏毅-机器学习（2017）
tags:
  - 
---

## 1. Sequence Labeling Problem

Sequence Labeling 的 problem 是什么呢？它也是一个 seq2seq 的问题：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117155714244.png" alt="image-20221117155714244" style="zoom:50%;" />

RNN 其实也可以解这个问题，但是还存在其他的基于 structured learning 的方法（two steps, three problems）。

今天用 POS tagging 任务（词性标注任务）来作为例子进行讲解。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117160243786.png" alt="image-20221117160243786" style="zoom:72%;" /></center>

POS tagging 对于接下来的 syntactic parsing、word sense disambiguation 等任务都是很有用的。

Outline：

+ Hidden Markov Model（HMM）
+ Conditional Random Field（CRF ）
+ Structured Perceptron/SVM
+ Towards Deep Learning

## 2. Hidden Markov Model (HMM)

### 2.1 HMM 的 assumption

How do you generate a sentence? HMM 做了一个 assumption：先产生一个 POS sequence，在由这个 POS seq 去产生一个 sentence：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117161700358.png" alt="image-20221117161700358" style="zoom:67%;" /></center>

下面看一下这两个步骤：

:arrow_forward: **Step 1: Generate a POS sequence based on the grammar**

HMM 假设这个 grammar 就是 Markov Chain：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117162107620.png" alt="image-20221117162107620" style="zoom:50%;" /></center>

根据这个 Markov Chain，一个 POS sequence 的概率就可以这么算：

$$P("PN \ V \ D \ N") = 0.4 \times 0.8 \times 0.25 \times 0.95 \times 0.1$$

:arrow_forward: **Step 2: Generate a sentence based on the POS sequence**

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117164128139.png" alt="image-20221117164128139" style="zoom:60%;" /></center>

HMM 做的事情就是在帮助我们描述我们是怎样说出一句话的：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117164417415.png" alt="image-20221117164417415" style="zoom:67%;" /></center>

这些概率的计算也都是蛮单纯的。我们用更一般化的方式来描述一下这些概率的计算：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117164650876.png" alt="image-20221117164650876" style="zoom:67%;" /></center>

### 2.2 如何计算这些概率？

接下来的问题就是，我们要怎么算出这些概率呢？我们首先需要收集一大堆的 training data：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117164815692.png" alt="image-20221117164815692" style="zoom:67%;" /></center>

有了这些 training data，这些概率就很好计算了：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117165403220.png" alt="image-20221117165403220" style="zoom:67%;" /></center>

+ 所以就是通过 count 来计算 probabilities，So simple！

> 在语音处理中使用 HMM 时，这里的计算其实要用到 EM 算法来做，但在 POS tagging 中，只需要 count 就好啦，这是没有问题的。
>
> 出现这种差别的原因在于，在一般 HMM 模型中，训练样本对应着的是一个可见的观测样本，一个隐状态序列，这个隐马尔可夫链的状态并不能像这个例子一样可以显性的写出来，因此需要 EM 算法来联合确定。 

### 2.3 HMM 的 inference

有了上面的概率，那我们该如何做 POS Tagging 呢？别忘了我们可以计算 P(x, y)，所以：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221117170216243.png" alt="image-20221117170216243" style="zoom:67%;" /></center>

这里的求解 $y = {\arg\max}_{y \in \mathbb{Y}}P(x, y)$ 可以遍历所有可能的 y 取值，然后代入到 $P(x, y)$ 中，看看哪个计算出来的概率最大。

但这样的计算真的需要我们去遍历所有可能的 y 吗？假如我们是通过遍历 y 来做的话：

+ 假如有 |S| 个 tags，并且 sequence y 的长度是 L
+ 那么就一共有 $|S|^L$ 中可能的 y

幸运的是，我们有 Viterbi Algorithm，它可以把上面的问题在复杂度 $O(L|s|^2)$ 的情况下解出来。如果不知道这个算法也没关系，就可以把它当成是一个 function，你告诉它这个 $P(x, y)$ 怎么算，然后你 call 这个 function 后，就可以知道哪个 y 可以让这个 $P(x, y)$ 最大。

### 2.4 Summary

HMM 其实也是 structured learning 的一种方法，而我们讲过，structured learning 就是要回答三个 problem，那这个 HMM 是如何回答这三个 problem 的呢？

+ **Problem 1: Evaluation**
  + HMM 中的 evaluation function 就是 x 与 y 的 joint probablties：$F(x, y)=P(x, y)=P(y)P(x|y)$
+ **Problem 2: Inference**
  + 就是要解 $\tilde{y} = \arg \max_{y\in \mathbb{Y}}P(x, y)$，HMM 中就是用的 Viterbi algorithm
+ **Problem 3: Training**
  + $P(y)$ and $P(x|y)$ can be simply obtained from training data

### 2.5 Drawbacks

Inference: $\tilde{y} = \arg \max_{y\in \mathbb{Y}}P(x, y)$

为了能够得到正确的结果 $(x, \hat y)$，我们是希望 $P(x, \hat y) \gt P(x,y)$，但是 HMM 却难以保证这一点，因为 P(x, y) 往往不是足够小的。

原因在于：对于没有出现在 training data 中的 (x, y)，HMM 不见得会给它一个低的 probability。也就 HMM 可能产生“脑补”的现象。

但这也不尽然就是它的缺点，因为可能对于现实正确的事情，可能就是没有出现在 training data 中，而 HMM 却能做到给它一个大的 probability。所以你会发现，当 training data 很小的时候，HMM 往往能比其他的 model 表现得更好，但随着 training data 的增多，HMM 就会变得没那么好了。

HMM 表现不好的一个原因是它对于 transition probability 和 emission probability 是分开 model 的，它假设了这两者是 independent 的。

+ More complex model can deal with this problem.
+ However, CRF can deal with this problem based on the same model.

## 3. Conditional Random Field（CRF）

CRF 一样也要描述 $P(x, y)$：

$$P(x, y) \propto exp(\color{purple}{w} \cdot \color{red}{\phi(x, y)})$$

+ $\color{red}{\phi(x, y)}$ is a feature vector. What does it look like?
+ $\color{purple}{w}$ is a weight vector to be learned from training data.
+ $exp(\color{purple}{w} \cdot \color{red}{\phi(x, y)})$ is always positive, can be larger than 1.

CRF 其实不 care $P(x, y)$ 到底是多少，它 care 的是 $P(y|x)$：

$$P(y|x) = \frac{P(x, y)}{\sum_{y'}P(x, y')}$$

又由于有 $P(x, y) = \frac{exp(\color{purple}{w} \cdot \color{red}{\phi(x, y)})}{R}$，于是 $P(y|x)$ 为：

$$P(y|x) = \frac{exp(\color{purple}{w} \cdot \color{red}{\phi(x, y)})}{\color{blue}{\sum_{y' \in \mathbb{Y}} exp(w \cdot \phi(x, y'))}} = \frac{exp(\color{purple}{w} \cdot \color{red}{\phi(x, y)})}{\color{blue}{Z(x)}}$$

### 3.1 P(x,y) for CRF

可能看上去 CRF 与 HMM 很不一样，其实有人证明了这俩其实是一样的。

我们把 HMM 的 P(x, y) 取一下 log 就可以得到：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118212305673.png" alt="image-20221118212305673" style="zoom:55%;" />

然后我们可以把下面红色方框的这一项变成另外一种形式：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118212435459.png" alt="image-20221118212435459" style="zoom:67%;" />

为什么可以这样转换呢？下面举一个例子：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118214006396.png" alt="image-20221118214006396" style="zoom:67%;" />

类似地，对其他也可以做几乎一样的转化：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118221445481.png" alt="image-20221118221445481" style="zoom:67%;" />

这样写开之后又会怎么样呢？我们已经把每一项都写成了如下的形式，然后转换成两个 vector 的 inner  product：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118221559077.png" alt="image-20221118221559077" style="zoom:67%;" />

最后可以看到，我们得到了 $P(x, y)=exp(\color{purple}{w} \cdot \color{red}{\phi(x, y)})$

有一个要注意的是，这里的 weight $w$ 是可以与 HMM 中的概率做一一对应的：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118221859693.png" alt="image-20221118221859693" style="zoom:67%;" />

而如果想把 weight 转回成概率，只需要它的 e 次方就可以了。

However，we do not give $w$ any constraints during training. 所以把上图的 P(x, y) 改写成正比于 $exp(...)$ 而不是等于，从而使其符合一个概率的要求。

:full_moon_with_face:

如果上面没看懂 …. 就算了。就只需要记得 $P(x, y) \propto exp(\color{purple}{w} \cdot \color{red}{\phi(x, y)})$，而且要知道这个 feature vector 长什么样子。

Feature Vector $\phi(x, y)$ 包含两个部分：

:arrow_forward: **part 1**：

<img src="C:\Users\yubin\AppData\Roaming\Typora\typora-user-images\image-20221118222700861.png" alt="image-20221118222700861" style="zoom:67%;" />

+ 如果有 |S| 种可能的 tags，有 |L| 种可能的 words，那 part 1 就一共有 $|S| \times |L|$ dimensions。可以看到这个 part 是非常稀疏的。

:arrow_forward: **part 2**：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118223746553.png" alt="image-20221118223746553" style="zoom:67%;" />

+ 如果有 |S| 种可能的 tags，那这个 part 就是 $|S| \times |S| + 2|S|$ 的 dimensions。

很神奇的是，CRF 可以允许 Define any $\phi(x, y)$ you like!

### 3.2 Training Criterion

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118224638267.png" alt="image-20221118224638267" style="zoom:67%;" /></center>

怎么来优化呢？因为我们是想 maximize 一个 function，所以可以使用 Gradient Ascent：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221118224840552.png" alt="image-20221118224840552" style="zoom:67%;" /></center>