---
title: Neural Network
date: 2022-06-25 17:12:03
permalink: /pages/ml/AndrewNg/neural-network/
categories:
  - AI
  - 机器学习
  - 吴恩达-机器学习
tags:
  - 
---

## 1. Neural Network Layer

### 1.1 One layer

在一个 layer 中，发生如下的计算：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220626121258853.png" alt="image-20220626121258853" style="zoom: 50%;" /></center>

由于这是发生在 layer 1 中，因此也往往将这一层的 params $w、b$ 加一个上标 `[1]`，计算的结果是 $\vec{a}^{[1]}$。

在 layer 2 中，便会发生如下的计算：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220626122213699.png" alt="image-20220626122213699" style="zoom:50%;" /></center>

> 注意这里上标的含义。

### 1.2 More complex neural network

将 layer 进行叠加可以得到：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220626122517034.png" alt="image-20220626122517034" style="zoom:50%;" /></center>

## 2. Advice for Applying Machine Learning

### 2.1 Evaluating a Hypothesis

当我们确定学习算法的 params 的时候，我们考虑的是选择 params 来使训练误差最小化。但仅仅是因为这个 hypothesis 具有很小的训练误差，并不能说明它就一定是一个好的 hypothesis function，因为可能出现 overfitting。那么该**如何判断一个 hypothesis func 是否 overfitting 呢**？

**按照经验可以将数据按照 7:3 分成 training set 和 test set**。很重要的一点是 training set 和 test set 均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再划分。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/9c769fd59c8a9c9f92200f538d1ab29c.png" alt="img" style="zoom: 67%;" />

在通过 training set 让我们的 model 学习得出其 params 后，对 test set 运用该模型通过计算代价函数 $J$ 等方法得到误差。

### 2.2 Model Selection and Train-Validation-Test

在有了 testing set 后，我们可以首先用 training set 得到一个最优的参数 $\theta$，然后用 testing set 进行评估误差，通过这样的方式可以在众多模型中选择一个理想的模型。

但这样做并不能评估模型的**泛化能力**，通过 testing set 评估选择的模型，可能刚好适合 testing set 的数据，并不能说明它对其他数据的预测能力，这时就引入了 validation set。

因此**我们可以将数据分成：training set、validation set 和 testing set**。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20201017131519699.png" alt="image-20201017131519699" style="zoom: 67%;" />

> 验证集也称为 Cross Validation Set（CV），但往往称之为 validation set。

对于每个集合都可以计算相应的误差：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20201017131609332.png" alt="image-20201017131609332" style="zoom:67%;" />

**这样在选择模型的时候，可以先使用 training set 得到每个模型的 $\theta$，然后使用 validation set 评估得到误差最小的模型，最后使用 testing set 评估他的泛化能力**。

### 2.3 Bias and Variance

当运行一个算法时，如果一个算法表现不理想，那么多半是出现了两种情况：要么是 high bias，要么是 high variance。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220626161242084.png" alt="image-20220626161242084" style="zoom:80%;" /></center>

+ 在 Bias (underfit) 的情况下，$J_{train}(\theta)$ will be high，$J_{cv}(\theta) \approx J_{train}(\theta)$；
+ 在 Variance (overfit) 的情况下，$J_{train}(\theta)$ will be low，$J_{cv}(\theta) \gg J_{train}(\theta)$。

### 2.4 Regularization and Bias_Variance

在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是我们可能会正则化的程度太高或太小了，即我们在选择 $\lambda$ 的值时也需要思考与刚才选择多项式模型次数类似的问题：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/2ba317c326547f5b5313489a3f0d66ce.png" alt="img" style="zoom:67%;" />

怎样去选择正则化参数 $\lambda$ 呢？

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220626162945135.png" alt="image-20220626162945135" style="zoom: 60%;" /></center>

+ 选取一系列的 $\lambda$ 值，往往从 0、0.01 开始，然后逐个成倍增加。
+ 对每个候选值，通过 training set 训练出一个 $\theta$，然后再用 validation set 计算 $J_{cv}$，选出一个 cross validation error 最小的 model 的再计算 $J_{test}$ 看看其泛化能力。

将每个 $\lambda$ 与其 error 对应的值绘制出来如下图：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/38eed7de718f44f6bb23727c5a88bf5d.png" alt="img" style="zoom: 75%;" /></center>

### 2.5 Learning Curve

**学习曲线**（Learning Curve）是用来判断某一个学习算法是否处于偏差、方差问题的很好的工具。学习曲线是将 training set 误差和 validation set 误差作为 training set 样本数量（m）的函数绘制的图表。

随着数据量的增加，$J_{train}(\theta)$ 的误差慢慢增大，因为数据越少， model 越容易拟合；$J_{cv}(\theta)$ 慢慢减少，因为数据越多，model 越精准，所以误差减小。

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220626164906090.png" alt="image-20220626164906090" style="zoom: 80%;" />

#### 1）high bias model 的 learning curve

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20201017142532611.png" alt="image-20201017142532611" style="zoom:75%;" /></center>

+ 因为参数很少，数据很多，所以随着数据的增多高偏差的模型的$J_{train}(θ)$ 和 $J_{cv}(\theta)$ 很接近。这时选择增加数据就不是很好的选择了，可以尝试增加数据的特征。

#### 2）high variance model 的 learning curve

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20201017142556080.png" alt="image-20201017142556080" style="zoom:75%;" /></center>

+ high variance 的特点是 training set 和 validation set 之间有很大的差距，这时可以选择增加数据，随着图像右移可以看出训练误差和验证误差会慢慢接近。

### 2.6 决定接下来做什么

Suppose you have implemented regularized linear regression to predict housing prices. However, when you test your hypothesis in a new set of houses, you find that it makes unacceptably large errors in its prediction. What should you try next?

+ Get more training examples.  –> fix high variance
+ Try smaller sets of features  –> fix high variance
+ Try getting additional features  –> fix high bias
+ Try adding polynomial features  –> fix high bias
+ Try decreasing $\lambda$  –> fix high bias
+ Try increasing $\lambda$  –> fix high variance

