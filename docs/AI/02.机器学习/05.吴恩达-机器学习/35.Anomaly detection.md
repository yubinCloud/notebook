---
title: Anomaly detection
date: 2022-07-20 11:23:53
permalink: /pages/ml/AndrewNg/anomaly-detection/
categories:
  - AI
  - 机器学习
  - 吴恩达-机器学习
tags:
  - 
---

## 1. Problem Motivation

异常检测是机器学习算法的一个常见应用。

什么是异常检测呢？假想你是一个飞机引擎制造商，当你生产的飞机引擎从生产线上流出时，你需要进行 QA（质量控制测试），而作为这个测试的一部分，你测量了飞机引擎的一些特征变量，比如引擎运转时产生的热量，或者引擎的振动等等：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720115045502.png" alt="image-20220720115045502" style="zoom:67%;" />

这样一来，你就有了一个数据集，将这些数据绘制成图表，看起来就是这个样子：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720115130730.png" alt="image-20220720115130730" style="zoom:67%;" />

这样，异常检测问题可以定义如下：我们假设后来有一天，你有一个新的飞机引擎从生产线上流出，而你的新飞机引擎有特征变量 $x_{test}$，所谓的异常检测问题就是：我们希望知道这个新的飞机引擎是否有某种异常，或者说，我们希望判断这个引擎是否需要进一步测试。因为，如果它看起来像一个正常的引擎，那么我们可以直接将它运送到客户那里，而不需要进一步的测试。

我们希望知道这个新数据 $x_{test}$ 是不是异常的，就是看这个数据不属于这组正常数据的几率是多少：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720115305421.png" alt="image-20220720115305421" style="zoom:80%;" />

上图中，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。

这种方法称为密度估计，表达如下：

```python
if p(x) < threshold:
    x is anomaly
else
	x is normal
```

这种方式也可以用于做欺诈检测等。

## 2. Gaussian Distribution

### 2.1 Gaussian (Normal) Distribution

高斯分布就是正态分布。

### 2.2 Parameter estimation

给了一个 dataset：$\{ x^{(1)}, x^{(2)}, \dots, x^{(m)} \}$，我们猜测它符合 Gaussian Distribution，即 $x^{(i)} \sim N(\mu, \sigma^2)$，但我们不知道 param $\mu$ 和 $\sigma$ 的值：

 <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720130906566.png" alt="image-20220720130906566" style="zoom:67%;" />

估计这两个参数的公式为：

$$\mu = \frac{1}{m} \sum^m_{i=1}x^{(i)}$$

$$\sigma^2 = \frac{1}{m} \sum^m_{i=1}(x^{(i)} - \mu)^2$$

> 在统计学中，为了达到无偏估计，估计 $\sigma^2$ 时前面的系数应该是 $\frac{1}{m-1}$，不过在机器学习中，当数据量大了之后，就无所谓用哪个了，所以在机器学习中一般是用 $\frac{1}{m}$。

## 3. Algorithm

本节将应用 Gaussian Distribution 开发异常检测算法。

::: theorem Anomaly detection algorithm
<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720133046056.png" alt="image-20220720133046056" style="zoom:67%;" /></center>
:::

## 4. Developing and Evaluating an Anomaly Detection System

When developing a learning algorithm (choosing features, etc.), making decisions is much easier if we have a way of evaluating our learning algorithm.

假定我们有一些 labeled data，y = 0 if normal，y = 1 if anomalous. 那么划分出三个数据集：

+ Training set：$x^{(1)}, x^{(2)}, \dots, x^{(m)}$，这些都是 normal example
+ Cross validation set：$(x_{cv}^{(1)}, y_{cv}^{(1)}), \dots, (x_{cv}^{(m_{cv})}, y_{cv}^{(m_{cv})})$
+ Test set: $(x_{test}^{(1)}, y_{test}^{(1)}), \dots, (x_{test}^{(m_{test})}, y_{test}^{(m_{test})})$

以之前说的飞机引擎作为例子，加入我们有 10000 个 normal example，20 个 anomalous example，可以做如下划分：

+ training set：6000 good engines
+ validation set：2000 good, 10 anomalous
+ test set：2000 good，10 anomalous

不建议让 validation set 和 test set 使用同一个数据集。

划分了数据集后，对算法的评价方法时：

::: theorem Algorithm evaluation
<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720153552405.png" alt="image-20220720153552405" style="zoom:80%;" /></center>
通过在 validation set 上最大化 evaluation metrics 来选择参数 threshold $\epsilon$。
:::

## 5. Anomaly detection  vs.  Supervised learning

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720155112558.png" alt="image-20220720155112558" style="zoom:80%;" /></center>

+ Anomaly detection 常用于 fraud detection、manufacturing、monitoring machines in a data center
+ Supervised learning 常用于 Email spam classification、weather prediction、cancer classification

## 6. Choosing what features to use

### 6.1 面对 non-gaussian features 怎么办？

在刚刚介绍的算法中，我们使用 Gaussian Distribution 来对 feature 建模，所以我们需要**先用直方图画出数据，以确保  feature 在进入 Anomaly detection 算法之前看上去比较接近 Gaussian Distribution**。

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720160752508.png" alt="image-20220720160752508" style="zoom:72%;" /></center>

上图中的上半部分的直方图（hist）是比较接近与 Gaussian Distribution 的，但下半部分的原始数据却显然不接近，这时可以对他进行一个变换，比如 $x := \log(x)$ 后就变成了右边的图像，从而接近于 Gaussian Distribution。

当然还存在其他变换，比如可以 $x := \log(x + c)$，其中 c 是一个常数；可以 $x := x^{\frac{1}{2}}$、$x := x^{\frac{1}{3}}$ 等等，**具体采用哪种变换是需要自己去调的**。

### 6.2 怎样得到这些 feature？

在 Anomaly Detection 中，我们希望的是：

+ 当 x 是 normal example 时 $p(x)$ 尽可能大
+ 当 x 是 anomalous example 时 $p(x)$ 尽可能小。

但一个问题是，很多 feature 的 $p(x)$ 在 normal 和 anomalous 时都是差不多大的。

仍以监控计算机作为例子。**Choose features that might take on unusually large or small values in the event of an anomaly**. 假如有以下 features：

+ $x_1$: memory use of computer
+ $x_2$: number of disk accesses/sec
+ $x_3$: CPU load
+ $x_4$: network traffic

如果有一台服务器的程序陷入了死循环，那么就会出现 CPU load 很大，但 network traffic 很低的情况，这时候就可以将 $\frac{CPU \ load}{network \ traffic}$ 作为一个 feature，这个 feature 可以帮助我们检测到异常的情况。

## 7. 多变量高斯分布

// TODO：选修，还没有学