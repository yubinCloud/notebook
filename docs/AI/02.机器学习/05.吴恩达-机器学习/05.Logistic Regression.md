---
title: Logistic Regression
date: 2022-06-02 14:52:51
permalink: /pages/ml/AndrewNg/logistic-regression
categories:
  - AI
  - 机器学习
  - 吴恩达-机器学习
tags:
  - 
---

## 1. Classification Problem

在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。我们从二元的分类问题开始讨论。

我们将因变量（**dependent variable**）可能属于的两个类分别称为负向类（**negative class**）和正向类（**positive class**），则 dependent var $y \in \{0, 1\}$，其中 0 表示负向类，1 表示正向类。

**为什么不能用 Linear Regression 的 hypothesis 来解 classification 问题**？对于 classification，y range from 0 or 1，但如果使用 Linear Regression，那 hypothesis func 的 output 可能远大于 1 或 远小于 0，而 label 取值 0 或 1，这样就会感觉很奇怪。因此我们需要研究 Logistic Regression，其 output 永远在 0~1 之间，它适用于 label y 取值离散的情况，比如 0 1 1 0。

> Logistic Regression 是一个 classification 算法，不要被名字里面的 “regression” 给迷惑了。

## 2. Hypothesis Representation

本节展示 logistic regression 的 hypothesis func 表达式。我们希望它的值在 0 和 1 之间，此时就有了：

+ 当 $h_\theta(x) \ge 0.5$ 时，预测 $y=1$；
+ 当 $h_\theta(x) \lt 0.5$ 时，预测 $y=0$。

Logistic Regression 模型的 hypothesis 是： 

$$h_\theta(x) = g(\theta^TX)$$

其中 X 代表特征向量，g 代表 **logistic function**，它也是 sigmoid function，公式为 $g(z)=\frac{1}{1+e^{-z}}$，图像为：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1073efb17b0d053b4f9218d4393246cc.jpg" alt="img" style="zoom:67%;" />

$h_\theta(x)$ 的作用是：<u>对于给定的 input x，根据选择的参数 $\theta$ 计算出 output = 1 的可能性</u>，即 $h_\theta(x)=P(y=1|x;\theta)$。例如给定 x，计算 $h_\theta(x)=0.7$，那表示有 70% 的概率 y 为 positive class，30% 的概率为 negative class。

## 3. Decision Boundary

在 Logistic Regression 中，我们预测：

+ 当 $h_\theta(x) \ge 0.5$ 时，预测 $y=1$；
+ 当 $h_\theta(x) \lt 0.5$ 时，预测 $y=0$。

 根据 logistic function 的 S 型函数图像，我们知道：

+ z = 0 时 g(z) = 0.5
+ z > 0 时 g(z) > 0.5
+ z < 0 时 g(z) < 0.5

又 $z=\theta^Tx$，即：$\theta^Tx \ge 0$ 时预测 y=1，$\theta^Tx \lt 0$ 时预测 y=0。这样此时 Decision Boundary 是坐标轴的竖直方向的轴。

现在假设我们又有一个模型：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/58d098bbb415f2c3797a63bd870c3b8f.png" alt="img" style="zoom:67%;" /></center>

现在假设参数 $\theta$ 是 vector $[-3,1,1]^T$，那么当 $-3+x_1+x_2 \ge 0$ 时，即 $x_1+x_2 \ge 3$ 时，模型将预测 y=1，这时我们绘制直线 $x_1+x_2=3$，这条线便是我们模型的分界线，将预测为 1 的区域和预测为 0 的区域分隔开：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/f71fb6102e1ceb616314499a027336dc.jpg" alt="img" style="zoom:67%;" />

对于更复杂的数据分布情况，z 可能需要是二次方特征来划分出 Decision Boundary：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/197d605aa74bee1556720ea248bab182.jpg" alt="img" style="zoom:67%;" />

<u>我们可以用非常复杂的模型来适应非常复杂形状的判定边界</u>。

## 4. Cost Function

