---
title: 协同过滤
date: 2022-07-20 16:55:18
permalink: /pages/ml/AndrewNg/collaborative-filtering/
categories:
  - AI
  - 机器学习
  - 吴恩达-机器学习
tags:
  - 
---

## 1. Problem Formulation

本章主要讲一下推荐系统（Recommender Systems），它是机器学习中的一个重要的应用，在学术界也具有一定的份额。借助推荐系统，我们还将领略一下特征学习的思想，即不手动设计 feature 而是采用一个算法来进行学习。

我们从一个例子开始定义推荐系统的问题。假使我们是一个电影供应商，我们有 5 部电影和 4 个用户，我们要求用户为电影打分：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720185838047.png" alt="image-20220720185838047" style="zoom:67%;" /></center>

前三部电影是爱情片，后两部则是动作片，我们可以看出 Alice 和 Bob 更倾向于爱情片，而 Carol 和 Dave 更倾向于动作片，并且没有一个用户给所有的电影都打过分。**我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并以此作为推荐的依据**。

下面先引入一些标记：

+ $n_u$：用户的数量
+ $n_m$：电影的数量
+ $r(i,j)$：如果用户 j 给电影 i 评过分，则 $r(i,j)=1$
+ $y^{(i,j)}$：代表用户 j 给电影 i 的评分
+ $m_j$：代表用户 j 评过分的电影的总数

## 2. 基于内容的推荐系统

在一个基于内容的推荐系统算法中，我们假设对于我们希望推荐的东西有一些数据，这些数据是有关这些东西的特征。

在我们的例子中，我们可以假设每部电影都有两个 feature，$x_1$ 代表电影的浪漫程度，$x_2$ 代表电影的动作程度：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720220144087.png" alt="image-20220720220144087" style="zoom:80%;" />

每部电影都有一个 feature vector，如第一部电影 $x^{(1)} = [0.9,  0]^T$。

下面我们要基于这些特征来构建一个推荐系统算法。假设我们采用线性回归模型，我们可以针对每一个用户都训练一个线性回归模型，如 $\theta^{(1)}$ 是第一个用户的模型的参数。先定义一下几个符号：

+ $\theta^{(j)}$ 是用户 j 的参数向量，$\theta^{(j)} \in \mathcal{R}^{n+1}$，n 是电影的 number of feature，在上例中是 n=2。
+ $x^{(i)}$ 是电影 i 的特征向量，$x^{(i)} \in \mathcal{R}^{n+1}$，n 是电影的 number of feature，在上例中是 n=2，加 1 是加了个偏置 1，即 $x^{(i)}_0 \equiv 0$。

**预测 user $j$ 会给 movie $i$ 打分：$(\theta^{(j)})^T x^{(i)}$**。

比如上例中，$x^{(3)} = [1, 0.99, 0]^T$，并假设 $\theta^{(1)}=[0,5,0]^T$，那么 Alice 对 *Cute puppies of love* 这部电影的打分可以预测为 $(\theta^{(1)})^T x^{(3)} = 5 \times 0.99 = 4.95$，这是合理的。

我们把问题正式的表达出来：为了 learn $\theta^{(j)}$，我们是要寻找 $\theta^{(j)}$ 能够最小化下面这个式子：

$$\frac{1}{2m^{(j)}} \sum_{i: r(i,j)=1}[(\theta^{(j)})^T x^{(i)} - y^{(i,j)}]^2 + \color{blue}{\frac{\lambda}{2m^{(j)}} \sum^n_{k=1}(\theta_k^{(j)})^2}$$

+ 式子的后半部分是 regularization
+ 前后两部分系数中都有 $m^{(j)}$，因此它可以作为一个常数而去掉。 

所以，Optimization objective 可以写成下面这样：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720222010471.png" alt="image-20220720222010471" style="zoom:70%;" /></center>

下面的就是将所有 user 的参数一块算，用 gradient descent 来做的话就是：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720223900528.png" alt="image-20220720223900528" style="zoom: 80%;" /></center>

上面所介绍的算法就是<mark>基于内容的推荐算法</mark>，因为我们假设变量是已有的，即我们有描述电影内容的特征量，比如这个电影的爱情程度怎么样。但是对于许多电影来说，我们并没有或者很难获取这些的特征量。

下一节我们将介绍不是基于内容的算法，即不去假设我们已经得到这些所有的电影的特征。

## 3. 协同过滤算法

在之前的基于内容的推荐系统中，对于每一部电影，我们都掌握了可用的特征，使用这些特征训练出了每一个用户的参数。**相反地，如果我们拥有用户的参数，我们可以学习得出电影的特征**。

假设我们知道一个用户的喜好，他比较喜欢爱情片，那他的 $\theta^{(1)} = [0,5,0]^T$，其余类似。对于电影 j 的 feature vector $x^{(j)}$，我们希望的是 $(\theta^{(i)})^T x^{(j)}$ 的值与 $y^{(i,j)}$ 越接近越好：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720234027758.png" alt="image-20220720234027758" style="zoom:67%;" />

优化过程可以写成如下：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720234146360.png" alt="image-20220720234146360" style="zoom:75%;" /></center>

+ 下面是用于计算所有电影的 feature vector 的式子。

我们先看一个基本的 Collaborative filtering 算法：

+ **Given $x^{(1)}, \dots, x^{(n_m)}$ and movie ratings, we can estimate $\theta^{(1)}, \dots, \theta^{(n_u)}$**
+ **Given $\theta^{(1)}, \dots, \theta^{(n_u)}$, we can estimate $x^{(1)},\dots,x^{(n_m)}$**

所有我们可以先随机地猜取一些 $\theta$ 值，然后就可以估计出 $x$，再用这些 $x$ 可以计算出更好的 $\theta$… 来回重复地迭代计算，最终将得到一个收敛的结果，这个结果就会是一组合理的电影特征以及一组对不同用户的参数的合理估计：

$$\theta \to x \to \theta \to x \to \dots$$

这是一个基本的协同过滤算法，但不是我们要最终应用的。下面我们来改进这个算法。

考虑如果我们既没有用户的参数，也没有电影的特征，那上面提到的两种方法都不可行了。协同过滤算法可以同时学习这两者。

我们的优化目标便改为同时针对 $x$ 和 $\theta$ 进行：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220720235543400.png" alt="image-20220720235543400" style="zoom:80%;" /></center>

+ 可以看到，紫色部分都一样，因此可以合并
+ 其实，当固定 $\theta$ 或 $x$ 的其中一个来估计另一个时，所做的优化过程其实与最下面这个合起来的式子做的事情是一样的，因为一旦固定一个，这个合起来的式子总会有一项的值为常数。

这里与前面的区别在于，$\theta$ 和 $x$ 都是 $\in R^n$，因为我们把之前向量中的第 0 个元素的偏置给去掉了，因为如果需要这个偏置，算法会自动学习出来。

::: theorem Collaborative filtering algorithm
1. Initialize $x^{(1)}, \dots, x^{(n_m)}, \theta^{(1)}, \dots, \theta^{(n_u)}$ to small random values.
2. Minimize $J(x^{(1)}, \dots, x^{(n_m)}, \theta^{(1)}, \dots, \theta^{(n_u)})$ using gradient descent (or an advanced optimization algorithm). E.g. for every $j=1, \dots, n_u; i = 1, \dots, n_m$:

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220721000332891.png" alt="image-20220721000332891" style="zoom:80%;" /></center>

3. For a user with parameters $\theta$ and a movie with (learned) features $x$, predict a star rating of $\theta^T x$.
:::

上面介绍的就是 Collaborative filtering 算法，它可以同时算出所有电影的 feature vector 和用户的 params vector，并能预测出用户未评价部分的分数。

## 4. Vectorization: Low Rank Matrix Factorization

本节讲述协同过滤算法的向量化实现，以及说说有关该算法你可以做的其他事情。举例子：

1. 当给出一件产品时，你能否找到与之相关的其它产品。
2. 一位用户最近看上一件产品，有没有其它相关的产品，你可以推荐给他。

我将要做的是：实现一种选择的方法，写出协同过滤算法的预测情况。

我们有关于五部电影的数据集，我将要做的是，将这些用户的电影评分，进行分组并存到一个矩阵中：

| **Movie**            | **Alice (1)** | **Bob (2)** | **Carol (3)** | **Dave (4)** |
| :------------------- | :------------ | :---------- | :------------ | :----------- |
| Love at last         | 5             | 5           | 0             | 0            |
| Romance forever      | 5             | ?           | ?             | 0            |
| Cute puppies of love | ?             | 4           | 0             | ?            |
| Nonstop car chases   | 0             | 0           | 5             | 4            |
| Swords vs. karate    | 0             | 0           | 5             | ?            |

对应写成矩阵就是：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220721104622193.png" alt="image-20220721104622193" style="zoom:80%;" />

预测出评分：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220721104721165.png" alt="image-20220721104721165" style="zoom:80%;" />

这个评分的计算过程有一个比较简单的向量化的方法来写出它们：每个 $(x^{(i)})^T$ 作为一个行向量，进行堆叠得到 $X$，每个 $(\theta^{(i)})^T$ 作为一个行向量，进行堆叠得到 $\Theta$，那么上面**预测评分的矩阵就可以通过 $X \Theta^T$ 计算出来**。这种方法就叫做<mark>低秩矩阵分解</mark>（**Low Rank Matrix Factorization**）。

找到相关影片：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220721104747006.png" alt="image-20220721104747006" style="zoom: 67%;" />

**既然已经学到了电影的 feature vector $x$，那我们就可以用它来度量两部电影的相似性**。如果 $x^{(i)}$ 与 $x^{(j)}$ 的距离很小，那么就说明电影 $i$ 与电影 $j$ 之间很相似，这样如果有人喜欢电影 $i$，那么很有可能也对电影 $j$ 感兴趣。

**总结一下，当用户在看某部电影 $i$ 的时候，为了能给用户推荐 5 部新电影，你可以找到与电影 $i$ 距离最小的 5 部电影**。

通过这个方法，希望你能知道，如何进行一个向量化的计算来对所有的用户和所有的电影进行评分计算。同时希望你也能掌握，通过学习特征参数，来找到相关电影和产品的方法。

## 5. Mean Normalization

让我们来看下面的用户评分数据：

<img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220721105936692.png" alt="image-20220721105936692" style="zoom:80%;" />

相比于之前，我们新增了一个用户 Eve，并且 Eve 没有给任何电影评分，那么我们以什么为依据为 Eve 推荐电影呢？

如果还是和之前的一样去学习该用户的参数向量的话，目标函数的正则化项会倾向于让这个向量变为零向量，而其余项对该参数向量的更新没有效果，因此最终会学出一个零向量。这显然不是我们期待的结果，因为如果这样的话，我们还是没法给该用户做推荐。

我们首先需要对结果矩阵 $Y$ 进行 <mark>Mean Normalization</mark> 处理，将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值：

<center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220721112517999.png" alt="image-20220721112517999" style="zoom:80%;" /></center>

然后我们利用这个新的 $Y$ 矩阵来训练算法。如果我们要用新训练出的算法来预测评分，则需要将平均值重新加回去，即预测值为：

$$(\theta^{(j)})^T x^{(i)} + \mu_i$$

这样对于 Eve，我们的新模型会认为她给每部电影的评分都是该电影的平均分。

我们刚刚讲的 Mean Normalization 就是把 $Y$ 矩阵的每一行给均值化了，让每一行的均为都是 0，这时这个方法名称的来源。

