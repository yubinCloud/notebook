---
title: 爬虫
date: 2021-09-24 12:54:59
permalink: /pages/7e3e85/
categories:
  - 基础
tags:
  - python
---

前面你已经学会了使用 requests 库爬取网页，并学会使用网页解析工具来解析网页中的数据。`发送请求 -> 接收响应 -> 解析数据 -> 处理数据`就是一个网络爬虫的任务，现在尝试使用爬虫框架来爬取一个网站。

## 任务

### TASK 1：简单网络爬虫

**任务描述**：

+ 使用 requests 库请求[校园新闻](http://today.hitwh.edu.cn/2018/1119/c1026a100732/page.htm)，得到响应后解析网页数据；
+ 采用lxml.etree.xpath 或者 beautifulsoup 筛选网站内容，提取并整理出此条新闻的标题、发布时间等信息；
+ 将获得的数据打印出来。

::: tip
我们发送请求获取到网页内容实质上就是模拟了用户的访问，网站服务器返回了我们要访问的页面的 HTML 源码
对返回的页面的内容进行提取同样是十分重要的，要善于用xpath或beautifulsoup的标签筛选、python的字符串处理、正则表达式等方式提取内容，注意对其它相似且不相同网站的兼容性
:::

### TASK 2：批量网络爬虫

**任务描述**：

Scrapy 是一个性能强劲的爬虫框架，以往被广泛使用，现在新出的 feapder 框架有着更完整的功能，更容易使用，所以我们使用 feapder 来完成一个爬虫任务。

[feapder文档](https://boris-code.gitee.io/feapder/#)

在 feapder 文档中，`快速入门`中有一个爬取“糗事百科”的例子，运行代码并读懂代码。

尝试使用该框架批量爬取学校[通知公告](http://today.hitwh.edu.cn/_s31/1024/list.psp)的数据。