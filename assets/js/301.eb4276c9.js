(window.webpackJsonp=window.webpackJsonp||[]).push([[301],{1054:function(t,a,s){"use strict";s.r(a);var n=s(22),r=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("blockquote",[s("p",[t._v("参考 "),s("a",{attrs:{href:"https://time.geekbang.org/column/intro/100029201",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka 核心技术与实战"),s("OutboundLink")],1),t._v(" 第 09-11 讲")])]),t._v(" "),s("h2",{attrs:{id:"_1-生产者消息分区机制原理剖析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-生产者消息分区机制原理剖析"}},[t._v("#")]),t._v(" 1. 生产者消息分区机制原理剖析")]),t._v(" "),s("p",[t._v("当我们生产和消费大量数据时，怎样才能将大数据量均匀地分配到 Kafka 的各个 Broker 上，就成为了一个非常重要的问题。")]),t._v(" "),s("blockquote",[s("p",[t._v("这里主要以 Java API 为例来分析 Kafka 生产者如何实现这个需求，其他语言的实现逻辑类似。")])]),t._v(" "),s("h3",{attrs:{id:"_1-1-为什么分区"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-为什么分区"}},[t._v("#")]),t._v(" 1.1 为什么分区？")]),t._v(" "),s("p",[t._v("Kafka 的 Topic 是承载真实数据的逻辑容器，而在主题之下还有若干个分区，也就是说 Kafka 的消息组织方式实际上是三级结构：主题 - 分区 - 消息。主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份。官网的下图非常清晰地展示了 kafka 的三级结构：")]),t._v(" "),s("center",[s("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20230614213407.png",alt:"20230614213407"}})]),t._v(" "),s("p",[t._v("那为什么 Kafka 使用分区的概念而不是直接使用多个 topic 呢？")]),t._v(" "),s("p",[t._v("其实"),s("strong",[t._v("分区的作用就是提供负载均衡的能力，或者说对数据进行分区的主要原因，就是为了实现系统的高伸缩性")]),t._v("（Scalability）。不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，我们还可以通过添加新的节点机器来增加整体系统的吞吐量。")]),t._v(" "),s("p",[t._v("除了提供负载均衡这种最核心的功能之外，利用分区也可以实现其他一些业务级别的需求，比如实现业务级别的消息顺序的问题，后面会对使用案例对其说明。")]),t._v(" "),s("h3",{attrs:{id:"_1-2-都有哪些分区策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-都有哪些分区策略"}},[t._v("#")]),t._v(" 1.2 都有哪些分区策略？")]),t._v(" "),s("p",[s("mark",[t._v("分区策略")]),t._v("是决定生产者将消息发送到哪个分区的算法。Kafka 为我们提供了默认的分区策略，同时它也支持你自定义分区策略。")]),t._v(" "),s("p",[t._v("如果要自定义分区策略，你需要显式地配置生产者端的参数partitioner.class。这个参数该怎么设定呢？方法很简单，在编写生产者程序时，你可以编写一个具体的类实现 "),s("code",[t._v("org.apache.kafka.clients.producer.Partitioner")]),t._v(" 接口。这个接口也很简单，只定义了两个方法：partition()和close()，通常你只需要实现最重要的 partition 方法。我们来看看这个方法的方法签名：")]),t._v(" "),s("div",{staticClass:"language-cpp line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-cpp"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("partition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("String topic"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Object key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" byte"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" keyBytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Object value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" byte"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" valueBytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Cluster cluster"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("这里的topic、key、keyBytes、value和valueBytes都属于消息数据，cluster则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。Kafka 给你这么多信息，就是希望让你能够充分地利用这些信息对消息进行分区，计算出它要被发送到哪个分区中。只要你自己的实现类定义好了 partition 方法，同时设置partitioner.class参数为你自己实现类的 Full Qualified Name，那么生产者程序就会按照你的代码逻辑对消息进行分区。虽说可以有无数种分区的可能，但比较常见的分区策略也就那么几种，下面我来详细介绍一下。")]),t._v(" "),s("h4",{attrs:{id:"_1-2-1-轮询策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-1-轮询策略"}},[t._v("#")]),t._v(" 1.2.1 轮询策略")]),t._v(" "),s("p",[t._v("也称 "),s("mark",[t._v("Round-robin 策略")]),t._v("，即顺序分配。比如一个主题下有 3 个分区，那么第一条消息被发送到分区 0，第二条被发送到分区 1，第三条被发送到分区 2，以此类推。当生产第 4 条消息时又会重新开始，即将其分配到分区 0，就像下面这张图展示的那样：")]),t._v(" "),s("center",[s("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20230614215747.png",alt:"20230614215747"}})]),t._v(" "),s("p",[t._v("轮询策略是 Kafka Java 生产者 API 默认提供的分区策略。"),s("strong",[t._v("轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一")]),t._v("。")]),t._v(" "),s("h4",{attrs:{id:"_1-2-2-随机策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-2-随机策略"}},[t._v("#")]),t._v(" 1.2.2 随机策略")]),t._v(" "),s("p",[t._v("也称 "),s("mark",[t._v("Randomness 策略")]),t._v("。所谓随机就是我们随意地将消息放置到任意一个分区上，如下面这张图所示：")]),t._v(" "),s("center",[s("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20230614215857.png",alt:"20230614215857"}})]),t._v(" "),s("p",[t._v("如果要实现随机策略版的 partition 方法，很简单，只需要两行代码即可：")]),t._v(" "),s("div",{staticClass:"language-java line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PartitionInfo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" partitions "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cluster"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("partitionsForTopic")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topic"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ThreadLocalRandom")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("current")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("nextInt")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("partitions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("p",[t._v("本质上看随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要逊于轮询策略，所以"),s("strong",[t._v("如果追求数据的均匀分布，还是使用轮询策略比较好")]),t._v("。")]),t._v(" "),s("h4",{attrs:{id:"_1-2-3-按消息键保序策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-3-按消息键保序策略"}},[t._v("#")]),t._v(" 1.2.3 按消息键保序策略")]),t._v(" "),s("p",[t._v("也称 "),s("mark",[t._v("Key-ordering 策略")]),t._v("。有点尴尬的是，这个名词是我自己编的，Kafka 官网上并无这样的提法。")]),t._v(" "),s("p",[t._v("Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key 的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以用来表征消息元数据。特别是在 Kafka 不支持时间戳的年代，在一些场景中，工程师们都是直接将消息创建时间封装进 Key 里面的。"),s("strong",[t._v("一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略")]),t._v("，如下图所示：")]),t._v(" "),s("center",[s("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20230614220144.png",alt:"20230614220144"}})]),t._v(" "),s("p",[t._v("实现这个策略的 partition 方法同样简单，只需要下面两行代码即可：")]),t._v(" "),s("div",{staticClass:"language-java line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PartitionInfo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" partitions "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cluster"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("partitionsForTopic")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topic"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Math")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("abs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashCode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" partitions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("p",[t._v("前面提到的 Kafka 默认分区策略实际上同时实现了两种策略："),s("strong",[t._v("如果指定了 Key，那么默认实现按消息键保序策略；如果没有指定 Key，则使用轮询策略")]),t._v("。")]),t._v(" "),s("p",[t._v("在你了解了 Kafka 默认的分区策略之后，我来给你讲一个真实的案例，希望能加强你对分区策略重要性的理解。")]),t._v(" "),s("p",[t._v("我曾经给一个国企进行过 Kafka 培训，当时碰到的一个问题就是如何实现消息的顺序问题。这家企业发送的 Kafka 的消息是有因果关系的，故处理因果关系也必须要保证有序性，否则先处理了“果”后处理“因”必然造成业务上的混乱。")]),t._v(" "),s("p",[t._v("当时那家企业的做法是给 Kafka 主题设置单分区，也就是 1 个分区。这样所有的消息都只在这一个分区内读写，因此保证了全局的顺序性。这样做虽然实现了因果关系的顺序性，但也丧失了 Kafka 多分区带来的高吞吐量和负载均衡的优势。")]),t._v(" "),s("p",[t._v("后来经过了解和调研，我发现这种具有因果关系的消息都有一定的特点，比如在消息体中都封装了固定的标志位，后来我就建议他们对此标志位设定专门的分区策略，保证同一标志位的所有消息都发送到同一分区，这样既可以保证分区内的消息顺序，也可以享受到多分区带来的性能红利。")]),t._v(" "),s("p",[t._v("这种基于个别字段的分区策略本质上就是按消息键保序的思想，其实更加合适的做法是把标志位数据提取出来统一放到 Key 中，这样更加符合 Kafka 的设计思想。经过改造之后，这个企业的消息处理吞吐量一下提升了 40 多倍，从这个案例你也可以看到自定制分区策略的效果可见一斑。")]),t._v(" "),s("h4",{attrs:{id:"_1-2-4-其他分区策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-4-其他分区策略"}},[t._v("#")]),t._v(" 1.2.4 其他分区策略")]),t._v(" "),s("p",[t._v("上面这几种分区策略都是比较基础的策略，除此之外你还能想到哪些有实际用途的分区策略？其实还有一种比较常见的，即所谓的基于地理位置的分区策略。当然这种策略一般只针对那些大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群。")]),t._v(" "),s("p",[t._v("比如我们希望在国内根据南北方地理位置的不同，发送到北京和南京两个不同的机房中，那我们就可以根据 Broker 所在的 IP 地址实现定制化的分区策略。比如下面这段代码：")]),t._v(" "),s("div",{staticClass:"language-java line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PartitionInfo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" partitions "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cluster"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("partitionsForTopic")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topic"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" partitions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("isSouth")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("leader")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("host")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PartitionInfo")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("::")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("partition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("findAny")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("p",[t._v("我们可以从所有分区中找出那些 Leader 副本在南方的所有分区，然后随机挑选一个进行消息发送。")]),t._v(" "),s("h3",{attrs:{id:"_1-3-小结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-小结"}},[t._v("#")]),t._v(" 1.3 小结")]),t._v(" "),s("p",[t._v("这一章讨论了 kafka 的分区机制和分区策略。"),s("strong",[t._v("切记分区是实现负载均衡以及高吞吐量的关键")]),t._v("，故在生产者这一端就要仔细盘算合适的分区策略，避免造成消息数据的“倾斜”，使得某些分区成为性能瓶颈，这样极易引发下游数据消费的性能下降。")]),t._v(" "),s("h2",{attrs:{id:"_2-生产者压缩算法面面观"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-生产者压缩算法面面观"}},[t._v("#")]),t._v(" 2. 生产者压缩算法面面观")]),t._v(" "),s("p",[t._v("压缩（compression）秉承了“用时间换空间”的经典 trade-off 思想，来减少磁盘空间或网络 IO 的传输量。在 Kafka 中，压缩也是如此。")]),t._v(" "),s("h3",{attrs:{id:"_2-1-怎么压缩"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-怎么压缩"}},[t._v("#")]),t._v(" 2.1 怎么压缩？")]),t._v(" "),s("p",[t._v("目前 Kafka 有两大类消息格式：V1 和 V2 版本。（V2 于 Kafka 0.11.0.0 中正式引入）")]),t._v(" "),s("p",[t._v("不论是哪个版本，Kafka 的消息层次分为两层："),s("strong",[t._v("消息集合")]),t._v("（message set）以及"),s("strong",[t._v("消息")]),t._v("（message）。一个消息集合中包含若干条"),s("strong",[t._v("日志项")]),t._v("（record item），而日志项才是真正封装消息的地方。Kafka 底层的消息日志由一系列消息集合日志项组成。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。")]),t._v(" "),s("p",[t._v("那 V2 相对 V1 的修改有哪些呢？这里先介绍一个，就是"),s("strong",[t._v("把消息的公共数据部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些数据了")]),t._v("。")]),t._v(" "),s("p",[t._v("比如，原来在 V1 版本中，每条消息都需要执行 CRC 校验，但有些情况下消息的 CRC 值是会发生变化的。比如在 Broker 端可能会对消息时间戳字段进行更新，那么重新计算之后的 CRC 值也会相应更新；再比如 Broker 端在执行消息格式转换时（主要是为了兼容老版本客户端程序），也会带来 CRC 值的变化。鉴于这些情况，再对每条消息都执行 CRC 校验就有点没必要了，不仅浪费空间还耽误 CPU 时间，因此在 V2 版本中，消息的 CRC 校验工作就被移到了消息集合这一层。")]),t._v(" "),s("p",[t._v("V2 针对压缩的另一个改进就是：保存压缩消息的方法发生了变化。之前 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本的做法是对整个消息集合进行压缩。显然后者应该比前者有更好的压缩效果。")]),t._v(" "),s("p",[t._v("我对两个版本分别做了一个简单的测试，结果显示，在相同条件下，不论是否启用压缩，V2 版本都比 V1 版本节省磁盘空间。当启用压缩时，这种节省空间的效果更加明显，就像下面这两张图展示的那样：")]),t._v(" "),s("center",[s("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20230616215504.png",alt:"20230616215504"}})]),t._v(" "),s("h3",{attrs:{id:"_2-2-何时压缩"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-何时压缩"}},[t._v("#")]),t._v(" 2.2 何时压缩？")]),t._v(" "),s("p",[t._v("kafka 中压缩可能发生在两个地方：Producer 端和 Broker 端。")]),t._v(" "),s("p",[t._v("生产者程序中配置 "),s("strong",[t._v("compression.type 参数")]),t._v("即表示启用指定类型的压缩算法。比如下面这段程序代码展示了如何构建一个开启 GZIP 的 Producer 对象：")]),t._v(" "),s("div",{staticClass:"language-java line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Properties")]),t._v(" props "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Properties")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bootstrap.servers"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:9092"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"acks"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"key.serializer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org.apache.kafka.common.serialization.StringSerializer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"value.serializer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org.apache.kafka.common.serialization.StringSerializer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 开启 GZIP 压缩")]),t._v("\n props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"compression.type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gzip"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n \n "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Producer")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" producer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("KafkaProducer")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br")])]),s("ul",[s("li",[t._v("这样 Producer 启动后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。")])]),t._v(" "),s("p",[t._v("在生产者端启用压缩是很自然的想法，那为什么我说在 Broker 端也可能进行压缩呢？其实大部分情况下 Broker 从 Producer 端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改，但这里的“大部分情况”也是要满足一定条件的。"),s("strong",[t._v("有两种例外情况就可能让 Broker 重新压缩消息")]),t._v("：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("情况一：Broker 端指定了和 Producer 端不同的压缩算法")]),t._v("。")])]),t._v(" "),s("p",[t._v("如果 Broker 需要的压缩消息与 Producer 的压缩算法一致，那没问题；但如果不一致，就只能 Broker 在接受到消息之后解压并重新压缩。Broker 端就有一个 compression.type 参数，这个参数与 Producer 的同名，默认值为 "),s("code",[t._v("producer")]),t._v("，表示 Broker 端会尊重 Producer 端使用的压缩算法，可一旦你在 Broker 端设置了不同的 compression.type 值，那就可能会发生预料之外的压缩 / 解压缩操作，通常表现为 Broker 端 CPU 使用率飙升。")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("情况二：Broker 端发生了消息格式转换")]),t._v("。")])]),t._v(" "),s("p",[t._v("所谓的消息格式转换主要是为了兼容老版本的消费者程序。还记得之前说过的 V1、V2 版本吧？在一个生产环境中，Kafka 集群中同时保存多种版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息执行向老版本格式的转换。这个过程中会涉及消息的解压缩和重新压缩。"),s("strong",[t._v("一般情况下这种消息格式转换对性能是有很大影响的")]),t._v("，除了这里的压缩之外，它还让 Kafka 丧失了引以为豪的 Zero Copy 特性。")]),t._v(" "),s("h3",{attrs:{id:"_2-3-何时解压缩"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-何时解压缩"}},[t._v("#")]),t._v(" 2.3 何时解压缩？")]),t._v(" "),s("p",[s("strong",[t._v("通常来说解压缩发生在消费者程序中")]),t._v("，也就是说 Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。")]),t._v(" "),s("blockquote",[s("p",[t._v("压缩算法类型被封装在了消息集合，因此 Consumer 可以采用相对应的解压缩算法。")])]),t._v(" "),s("p",[t._v("如果用一句话总结一下压缩和解压缩，那么我希望你记住这句话："),s("font",{attrs:{color:"blue"}},[t._v("Producer 端压缩、Broker 端保持、Consumer 端解压缩")]),t._v("。")],1),t._v(" "),s("p",[t._v("除了在 Consumer 端解压缩，Broker 端也会进行解压缩。注意了，这和前面提到消息格式转换时发生的解压缩是不同的场景。"),s("strong",[t._v("每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证")]),t._v("。我们必须承认这种解压缩对 Broker 端性能是有一定影响的，特别是对 CPU 的使用率而言。")]),t._v(" "),s("blockquote",[s("p",[t._v("目前已经可以规避 broker 端为执行校验而做的解压缩操作。")])]),t._v(" "),s("h3",{attrs:{id:"_2-4-各种压缩算法对比"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-各种压缩算法对比"}},[t._v("#")]),t._v(" 2.4 各种压缩算法对比")]),t._v(" "),s("p",[t._v("这一节比较一下各个压缩算法的优劣，这样我们才能有针对性地配置适合我们业务的压缩策略。")]),t._v(" "),s("p",[t._v("在 Kafka 2.1.0 版本之前，Kafka 支持 3 种压缩算法："),s("strong",[t._v("GZIP")]),t._v("、"),s("strong",[t._v("Snappy")]),t._v(" 和 "),s("strong",[t._v("LZ4")]),t._v("。从 2.1.0 开始，Kafka 正式支持 Zstandard 算法（简写为 "),s("strong",[t._v("zstd")]),t._v("）。它是 Facebook 开源的一个压缩算法，能够提供超高的压缩比（compression ratio）。")]),t._v(" "),s("p",[t._v("对了，看一个压缩算法的优劣，有两个重要的指标：")]),t._v(" "),s("ul",[s("li",[t._v("一个指标是"),s("strong",[t._v("压缩比")]),t._v("，原先占 100 份空间的东西经压缩之后变成了占 20 份空间，那么压缩比就是 5，显然压缩比越高越好；")]),t._v(" "),s("li",[t._v("另一个指标就是"),s("strong",[t._v("压缩 / 解压缩吞吐量")]),t._v("，比如每秒能压缩或解压缩多少 MB 的数据。同样地，吞吐量也是越高越好。")])]),t._v(" "),s("p",[t._v("下面这张表是 Facebook Zstandard 官网提供的一份压缩算法 benchmark 比较结果：")]),t._v(" "),s("center",[s("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20230616221148.png",alt:"20230616221148"}})]),t._v(" "),s("p",[t._v("从表中我们可以发现 zstd 算法有着最高的压缩比，而在吞吐量上的表现只能说中规中矩。反观 LZ4 算法，它在吞吐量方面则是毫无疑问的执牛耳者。当然对于表格中数据的权威性我不做过多解读，只想用它来说明一下当前各种压缩算法的大致表现。")]),t._v(" "),s("p",[t._v("在实际使用中，GZIP、Snappy、LZ4 甚至是 zstd 的表现各有千秋。但对于 Kafka 而言，它们的性能测试结果却出奇得一致，即在吞吐量方面：LZ4 > Snappy > zstd 和 GZIP；而在压缩比方面，zstd > LZ4 > GZIP > Snappy。具体到物理资源，使用 Snappy 算法占用的网络带宽最多，zstd 最少，这是合理的，毕竟 zstd 就是要提供超高的压缩比；在 CPU 使用率方面，各个算法表现得差不多，只是在压缩时 Snappy 算法使用的 CPU 较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU。")]),t._v(" "),s("h3",{attrs:{id:"_2-5-最佳实践"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-最佳实践"}},[t._v("#")]),t._v(" 2.5 最佳实践")]),t._v(" "),s("p",[t._v("了解了这些算法对比，我们就能根据自身的实际情况有针对性地启用合适的压缩算法。")]),t._v(" "),s("p",[t._v("首先来说压缩。何时启用压缩是比较合适的时机呢？")]),t._v(" "),s("p",[t._v("你现在已经知道 Producer 端完成的压缩，那么"),s("strong",[t._v("启用压缩的一个条件就是 Producer 程序运行机器上的 CPU 资源要很充足")]),t._v("。如果 Producer 运行机器本身 CPU 已经消耗殆尽了，那么启用消息压缩无疑是雪上加霜，只会适得其反。")]),t._v(" "),s("p",[t._v("除了 CPU 资源充足这一条件，"),s("strong",[t._v("如果你的环境中带宽资源有限，那么我也建议你开启压缩")]),t._v("。事实上我见过的很多 Kafka 生产环境都遭遇过带宽被打满的情况。"),s("strong",[t._v("这年头，带宽可是比 CPU 和内存还要珍贵的稀缺资源")]),t._v("，毕竟万兆网络还不是普通公司的标配，因此千兆网络中 Kafka 集群带宽资源耗尽这件事情就特别容易出现。如果你的客户端机器 CPU 资源有很多富余，"),s("strong",[t._v("我强烈建议你开启 zstd 压缩，这样能极大地节省网络资源消耗")]),t._v("。")]),t._v(" "),s("p",[t._v("其次说说解压缩。其实也没什么可说的。一旦启用压缩，解压缩是不可避免的事情。这里只想强调一点："),s("strong",[t._v("我们对不可抗拒的解压缩无能为力，但至少能规避掉那些意料之外的解压缩")]),t._v("。就像我前面说的，因为要兼容老版本而引入的解压缩操作就属于这类。有条件的话尽量保证不要出现消息格式转换的情况。")]),t._v(" "),s("h3",{attrs:{id:"_2-6-小结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-小结"}},[t._v("#")]),t._v(" 2.6 小结")]),t._v(" "),s("p",[t._v("这里讨论了 Kafka 消息压缩的各个方面，目的只有一个：希望能根据自身的实际情况恰当地选择合适的 Kafka 压缩算法，以求实现最大的资源利用率。")]),t._v(" "),s("h2",{attrs:{id:"_3-无消息丢失配置怎么实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-无消息丢失配置怎么实现"}},[t._v("#")]),t._v(" 3. 无消息丢失配置怎么实现？")]),t._v(" "),s("p",[t._v("今天分享的主题是：如何配置 Kafka 无消息丢失。")]),t._v(" "),s("h3",{attrs:{id:"_3-1-什么情况下能保证消息无丢失"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-什么情况下能保证消息无丢失"}},[t._v("#")]),t._v(" 3.1 什么情况下能保证消息无丢失？")]),t._v(" "),s("p",[t._v("首先先确定好责任的边界，即 Kafka 在什么情况下能保证消息不丢失。一句话概括："),s("strong",[t._v("Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证")]),t._v("。")]),t._v(" "),s("p",[t._v("这句话里面有两个核心要素，我们一一来看。")]),t._v(" "),s("p",[t._v("第一个核心要素是“"),s("strong",[t._v("已提交的消息")]),t._v("”。什么是已提交的消息？当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。")]),t._v(" "),s("p",[t._v("那为什么是若干个 Broker 呢？这取决于你对“已提交”的定义。你可以选择只要有一个 Broker 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。不论哪种情况，"),s("strong",[t._v("Kafka 只对已提交的消息做持久化保证这件事情是不变的")]),t._v("。")]),t._v(" "),s("p",[t._v("第二个核心要素就是“"),s("strong",[t._v("有限度的持久化保证")]),t._v("”，也就是说 Kafka 不可能保证在任何情况下都做到不丢失消息。举个极端点的例子，如果地球都不存在了，Kafka 还能保存任何消息吗？显然不能！倘若这种情况下你依然还想要 Kafka 不丢消息，那么只能在别的星球部署 Kafka Broker 服务器了。")]),t._v(" "),s("p",[t._v("现在你应该能够稍微体会出这里的“有限度”的含义了吧，其实就是说 Kafka 不丢消息是有前提条件的。"),s("strong",[t._v("假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活")]),t._v("。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。")]),t._v(" "),s("p",[s("font",{attrs:{color:"blue"}},[t._v("总结一下，Kafka 是能做到不丢失消息的，只不过这些消息必须是已提交的消息，而且还要至少有一个存有该消息的 Broker 存活")]),t._v("。当然，说明这件事并不是要为 Kafka 推卸责任，而是为了在出现该类问题时我们能够明确责任边界。")],1),t._v(" "),s("h3",{attrs:{id:"_3-2-消息丢失的案例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-消息丢失的案例"}},[t._v("#")]),t._v(" 3.2 消息丢失的案例")]),t._v(" "),s("p",[t._v("下面看一下那些常见的 “Kafka 消息丢失”的案例。注意，这里可是带引号的消息丢失哦，其实有些时候我们只是冤枉了 Kafka 而已。")]),t._v(" "),s("h4",{attrs:{id:"案例-1-生产者程序丢失数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#案例-1-生产者程序丢失数据"}},[t._v("#")]),t._v(" 案例 1：生产者程序丢失数据")]),t._v(" "),s("p",[t._v("Producer 程序丢失消息，这应该算是被抱怨最多的数据丢失场景了。我来描述一个场景：你写了一个 Producer 应用向 Kafka 发送消息，最后发现 Kafka 没有保存，于是大骂：“Kafka 真烂，消息发送居然都能丢失，而且还不告诉我？！”如果你有过这样的经历，那么请先消消气，我们来分析下可能的原因。")]),t._v(" "),s("p",[t._v("目前 Kafka Producer 是异步发送消息的，也就是说如果你调用的是 "),s("code",[t._v("producer.send(msg)")]),t._v(" 这个 API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。这种方式有个有趣的名字："),s("strong",[t._v("fire and forget")]),t._v("，意思是，执行完一个操作后不去管它的结果是否成功。因此如果出现消息丢失，我们是无法知晓的。这个发送方式挺不靠谱吧，不过有些公司真的就是在使用这个 API 发送消息。")]),t._v(" "),s("p",[t._v("如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？其实原因有很多，例如网络抖动，导致消息压根就没有发送到 Broker 端；或者消息本身不合格导致 Broker 拒绝接收（比如消息太大了，超过了 Broker 的承受能力）等。这么来看，让 Kafka“背锅”就有点冤枉它了。就像前面说过的，Kafka 不认为消息是已提交的，因此也就没有 Kafka 丢失消息这一说了。")]),t._v(" "),s("p",[t._v("这个问题的解决办法非常简单："),s("font",{attrs:{color:"red"}},[t._v("Producer 永远要使用带有回调通知的发送 API，也就是说不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)")]),t._v("。")],1),t._v(" "),s("p",[t._v("不要小瞧这里的 callback（回调），它能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理，毕竟这时的责任在 Producer，可以进行重试或调整格式后重发。")]),t._v(" "),s("p",[t._v("当然发送失败也可能是 Broker 端造成的，比如如果所有 Broker 都宕机了，那 Producer 无论怎样重试都会失败。此时你要做的是赶快处理 Broker 端的问题。")]),t._v(" "),s("h4",{attrs:{id:"案例-2-消费者程序丢失数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#案例-2-消费者程序丢失数据"}},[t._v("#")]),t._v(" 案例 2：消费者程序丢失数据")]),t._v(" "),s("p",[t._v("Consumer 端丢失数据主要体现在 Consumer 端要消费的消息不见了。Consumer 程序有个“位移”的概念，表示的是这个 Consumer 当前消费到的 Topic 分区的位置。下面这张图来自于官网，它清晰地展示了 Consumer 端的位移数据：")]),t._v(" "),s("center",[s("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/20230616224317.png",alt:"20230616224317"}})]),t._v(" "),s("p",[t._v("比如对于 Consumer A 而言，它当前的位移值就是 9；Consumer B 的位移值是 11。")]),t._v(" "),s("p",[t._v("这里的“位移”类似于我们看书时使用的书签，它会标记我们当前阅读了多少页，下次翻书的时候我们能直接跳到书签页继续阅读。")]),t._v(" "),s("p",[t._v("正确使用书签有两个步骤：第一步是读书，第二步是更新书签页。如果这两步的顺序颠倒了，就可能出现这样的场景：当前的书签页是第 90 页，我先将书签放到第 100 页上，之后开始读书。当阅读到第 95 页时，我临时有事中止了阅读。那么问题来了，当我下次直接跳到书签页阅读时，我就丢失了第 96～99 页的内容，即这些消息就丢失了。")]),t._v(" "),s("p",[t._v("同理，Kafka 中 Consumer 端的消息丢失就是这么一回事。要对抗这种消息丢失，办法很简单："),s("font",{attrs:{color:"red"}},[t._v("维持先消费消息（阅读），再更新位移（书签）的顺序即可")]),t._v("。这样就能最大限度地保证消息不丢失。")],1),t._v(" "),s("p",[t._v("当然，这种处理方式可能带来的问题是消息的重复处理，类似于同一页书被读了很多遍，但这不属于消息丢失的情形。后面会分享如何解决重复消息的问题。")]),t._v(" "),s("p",[t._v("除了上面所说的场景，其实还存在一种比较隐蔽的消息丢失场景。当 Consumer 程序从 Kafka 获取到消息后开启了多个线程异步处理消息，而 Consumer 程序自动地向前更新位移。假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于 Consumer 而言实际上是丢失了。")]),t._v(" "),s("p",[t._v("这里的关键在于 Consumer 自动提交位移，你没有真正地确认消息是否真的被消费就“盲目”地更新了位移。解决方法也很简单："),s("font",{attrs:{color:"red"}},[t._v("如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移")]),t._v("。\n在这里我要提醒你一下，单个 Consumer 程序使用多线程来消费消息说起来容易，写成代码却异常困难，因为你很难正确地处理位移的更新，也就是说"),s("strong",[t._v("避免无消费消息丢失很简单，但极易出现消息被消费了多次的情况")]),t._v("。")],1),t._v(" "),s("h3",{attrs:{id:"_3-3-最佳实践"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-最佳实践"}},[t._v("#")]),t._v(" 3.3 最佳实践")]),t._v(" "),s("p",[t._v("看完这两个案例之后，我来分享一下 Kafka 无消息丢失的配置，每一个其实都能对应上面提到的问题。")]),t._v(" "),s("ol",[s("li",[t._v("不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，"),s("strong",[t._v("一定要使用带有回调通知的 send 方法")]),t._v("。")]),t._v(" "),s("li",[s("strong",[t._v("设置 acks = all")]),t._v("。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。")]),t._v(" "),s("li",[s("strong",[t._v("设置 retries 为一个较大的值")]),t._v("。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。")]),t._v(" "),s("li",[s("strong",[t._v("设置 unclean.leader.election.enable = false")]),t._v("。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。")]),t._v(" "),s("li",[t._v("设置 replication.factor >= 3。这也是 Broker 端的参数。其实这里想表述的是，"),s("strong",[t._v("最好将消息多保存几份")]),t._v("，毕竟目前防止消息丢失的主要机制就是冗余。")]),t._v(" "),s("li",[s("strong",[t._v("设置 min.insync.replicas > 1")]),t._v("。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。")]),t._v(" "),s("li",[s("strong",[t._v("确保 replication.factor > min.insync.replicas")]),t._v("。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。")]),t._v(" "),s("li",[s("strong",[t._v("确保消息消费完成再提交")]),t._v("。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。")])]),t._v(" "),s("h3",{attrs:{id:"_3-4-小结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-小结"}},[t._v("#")]),t._v(" 3.4 小结")]),t._v(" "),s("p",[t._v("今天讨论了 Kafka 无消息丢失的方方面面。首先明确了 Kafka 持久化保证的责任边界，随后以这个规则为标尺衡量了一些常见的数据丢失场景，最后通过分析这些场景，给出了 Kafka 无消息丢失的“最佳实践”。总结起来，这一章应该有两个收获：")]),t._v(" "),s("ul",[s("li",[t._v("明确 Kafka 持久化保证的含义和限定条件。")]),t._v(" "),s("li",[t._v("熟练配置 Kafka 无消息丢失参数。")])]),t._v(" "),s("div",{staticClass:"custom-block note"},[s("p",{staticClass:"custom-block-title"},[t._v("开放讨论")]),t._v(" "),s("p",[t._v("其实，Kafka 还有一种特别隐秘的消息丢失场景：增加主题分区。当增加主题分区后，在某段“不凑巧”的时间间隔后，Producer 先于 Consumer 感知到新增加的分区，而 Consumer 设置的是“从最新位移处”开始读取消息，因此在 Consumer 感知到新分区前，Producer 发送的这些消息就全部“丢失”了，或者说 Consumer 无法读取到这些消息。严格来说这是 Kafka 设计上的一个小缺陷，你有什么解决的办法吗？")]),t._v(" "),s("p",[t._v("其实这只能先停止程序再增加分区，毕竟为了更强的消息持久化保证，只能牺牲一点高可用性了。")])])],1)}),[],!1,null,null,null);a.default=r.exports}}]);