(window.webpackJsonp=window.webpackJsonp||[]).push([[65],{818:function(t,s,a){"use strict";a.r(s);var n=a(22),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("blockquote",[a("p",[t._v("转自 "),a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/590730770",target:"_blank",rel:"noopener noreferrer"}},[t._v("PyTorch 中学习率调度器可视化介绍"),a("OutboundLink")],1)])]),t._v(" "),a("p",[t._v("神经网络有许多影响模型性能的超参数。一个最基本的超参数是学习率（LR），它决定了在训练步骤之间模型权重的变化程度。在最简单的情况下，LR 值是 0 到 1 之间的固定值。")]),t._v(" "),a("p",[t._v("选择正确的 LR 值是具有挑战性。一方面较大的学习率有助于算法快速收敛，但它也会导致算法在最小值附近跳跃而没有达到它，甚至在它太大时跳过它。另一方面，较小的学习率可以更好地收敛到最小值，但是如果优化器太小，可能需要太长时间才能收敛，或者陷入停滞。")]),t._v(" "),a("h2",{attrs:{id:"_1-learning-rate-scheduler"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-learning-rate-scheduler"}},[t._v("#")]),t._v(" 1. Learning Rate Scheduler")]),t._v(" "),a("p",[t._v("一种帮助算法快速收敛到最优的解决方案是使用"),a("mark",[t._v("学习率调度器")]),t._v("。学习率调度器"),a("strong",[t._v("在训练过程中根据预先定义的时间表调整学习率")]),t._v("。")]),t._v(" "),a("p",[t._v("通常，学习率在训练开始时设置为比较高的值，允许更快的收敛。随着训练的进行，学习率会降低，使收敛到最优，获得更好的性能。在训练过程中降低学习率也称为退火或衰减。")]),t._v(" "),a("p",[t._v("学习率调度器有很多个，并且我们还可以自定义调度器。本文将介绍 PyTorch 中不同的预定义学习率调度器如何在训练期间调整学习率。")]),t._v(" "),a("p",[t._v("对于本文，我们使用 PyTorch 1.13.0 版本。可以在 PyTorch 文档中阅读更多关于学习率调度器的细节。")]),t._v(" "),a("h3",{attrs:{id:"_1-1-steplr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-steplr"}},[t._v("#")]),t._v(" 1.1 StepLR")]),t._v(" "),a("p",[t._v("在每个预定义的训练步骤数之后，StepLR 通过乘法因子降低学习率。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StepLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StepLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                   step_size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Period of learning rate decay ")]),t._v("\n                   gamma "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Multiplicative factor of learning rate decay")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/v2-95428d51bee14643ef4224a394fb0215_r.jpg",alt:"img"}})]),t._v(" "),a("h3",{attrs:{id:"_1-2-multisteplr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-multisteplr"}},[t._v("#")]),t._v(" 1.2 MultiStepLR")]),t._v(" "),a("p",[t._v("MultiStepLR 类似于 StepLR，也通过乘法因子降低了学习率，但可以自定义修改学习率的时间节点。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" MultiStepLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MultiStepLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                        milestones"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("28")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# List of epoch indices ")]),t._v("\n                        gamma "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Multiplicative factor of learning rate decay")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221210225224119.png",alt:"image-20221210225224119"}})]),t._v(" "),a("h3",{attrs:{id:"_1-3-constantlr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-constantlr"}},[t._v("#")]),t._v(" 1.3 ConstantLR")]),t._v(" "),a("p",[t._v("ConstantLR 通过乘法因子降低学习率，直到训练达到预定义步数。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ConstantLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ConstantLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                       factor "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The number we multiply learning rate until the milestone. ")]),t._v("\n                       total_iters "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The number of steps that the scheduler decays the learning rate")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221210225416587.png",alt:"image-20221210225416587"}})]),t._v(" "),a("ul",[a("li",[a("u",[t._v("如果起始因子小于 1，那么学习率调度器在训练过程中会提高学习率，而不是降低学习率")]),t._v("。")])]),t._v(" "),a("h3",{attrs:{id:"_1-4-linearlr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-linearlr"}},[t._v("#")]),t._v(" 1.4 LinearLR")]),t._v(" "),a("p",[t._v("LinearLR，类似于 ConstantLR，在训练开始时通过乘法因子降低了学习率。但是它会在一定数量的训练步骤中线性地改变学习率，直到它达到最初设定的学习率。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LinearLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LinearLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                     start_factor "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The number we multiply learning rate in the first epoch ")]),t._v("\n                     total_iters "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The number of iterations that multiplicative factor reaches to 1")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212205420996.png",alt:"image-20221212205420996"}})]),t._v(" "),a("h3",{attrs:{id:"_1-5-exponentiallr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-exponentiallr"}},[t._v("#")]),t._v(" 1.5 ExponentialLR")]),t._v(" "),a("p",[t._v("ExponentialLR 在每个训练步骤中通过乘法因子降低学习率。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ExponentialLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ExponentialLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                          gamma "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Multiplicative factor of learning rate decay.")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br")])]),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212205622475.png",alt:"image-20221212205622475"}})]),t._v(" "),a("h3",{attrs:{id:"_1-6-polynomiallr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-polynomiallr"}},[t._v("#")]),t._v(" 1.6 PolynomialLR")]),t._v(" "),a("p",[t._v("PolynomialLR 通过对定义的步骤数使用多项式函数来降低学习率。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PolynomialLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PolynomialLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                         total_iters "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The number of steps that the scheduler decays the learning rate. ")]),t._v("\n                         power "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The power of the polynomial.")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("p",[t._v("下图为 power= 1 时的学习率衰减结果：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212205811257.png",alt:"image-20221212205811257"}})]),t._v(" "),a("p",[t._v("power= 2 时，学习率衰减如下所示：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212205846640.png",alt:"image-20221212205846640"}})]),t._v(" "),a("h3",{attrs:{id:"_1-7-cosineannealinglr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-7-cosineannealinglr"}},[t._v("#")]),t._v(" 1.7 CosineAnnealingLR")]),t._v(" "),a("p",[t._v("CosineAnnealingLR 通过余弦函数降低学习率。可以从技术上安排学习率调整以跟随多个周期，但它的思想是在半个周期内衰减学习率以获得最大的迭代次数。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CosineAnnealingLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CosineAnnealingLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                              T_max "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Maximum number of iterations. ")]),t._v("\n                             eta_min "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Minimum learning rate.")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212210035597.png",alt:"image-20221212210035597"}})]),t._v(" "),a("p",[t._v("两位 Kaggle 大赛大师Philipp Singer和 Yauhen Babakhin 建议使用余弦衰减作为深度迁移学习的学习率调度器。")]),t._v(" "),a("h3",{attrs:{id:"_1-8-cosineannealingwarmrestartslr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-8-cosineannealingwarmrestartslr"}},[t._v("#")]),t._v(" 1.8 CosineAnnealingWarmRestartsLR")]),t._v(" "),a("p",[t._v("CosineAnnealingWarmRestartsLR 类似于 CosineAnnealingLR。但是它允许在(例如，每个轮次中)使用初始 LR 重新启动 LR 计划。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CosineAnnealingWarmRestarts \nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CosineAnnealingWarmRestarts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                                        T_0 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Number of iterations for the first restart ")]),t._v("\n                                        T_mult "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# A factor increases TiTi after a restart ")]),t._v("\n                                        eta_min "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Minimum learning rate")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212211742501.png",alt:"image-20221212211742501"}})]),t._v(" "),a("p",[t._v("这个计划调度于2017年推出。虽然增加LR会导致模型发散但是这种有意的分歧使模型能够逃避局部最小值，并找到更好的全局最小值。")]),t._v(" "),a("h3",{attrs:{id:"_1-9-cycliclr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-9-cycliclr"}},[t._v("#")]),t._v(" 1.9 CyclicLR")]),t._v(" "),a("p",[t._v("CyclicLR 根据循环学习率策略调整学习率，该策略基于我们在前一节中讨论过的重启的概念。在 PyTorch 中有三个内置策略。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CyclicLR \n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CyclicLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                     base_lr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0001")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Initial learning rate which is the lower boundary in the cycle for each parameter group ")]),t._v("\n                     max_lr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Upper learning rate boundaries in the cycle for each parameter group ")]),t._v("\n                     step_size_up "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Number of training iterations in the increasing half of a cycle ")]),t._v("\n                     mode "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"triangular"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br")])]),a("p",[t._v('当mode = " triangle "时，学习率衰减将遵循一个基本的三角形循环，没有振幅缩放，如下图所示。')]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212211904800.png",alt:"image-20221212211904800"}})]),t._v(" "),a("p",[t._v('对于mode = " triangar2 "，所得到的学习率衰减将遵循一个基本的三角形循环，每个循环将初始振幅缩放一半，如下图所示：')]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212211934110.png",alt:"image-20221212211934110"}})]),t._v(" "),a("p",[t._v('使用mode = "exp_range"，得到的学习率衰减将如下所示：')]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212212002421.png",alt:"image-20221212212002421"}})]),t._v(" "),a("h3",{attrs:{id:"_1-10-onecyclelr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-10-onecyclelr"}},[t._v("#")]),t._v(" 1.10 OneCycleLR")]),t._v(" "),a("p",[t._v("OneCycleLR根据 1cycle 学习率策略降低学习率，该策略在2017年的一篇论文中提出。与许多其他学习率调度器相比，学习率不仅在训练过程中下降。相反，学习率从初始学习率增加到某个最大学习率，然后再次下降。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OneCycleLR \n\n\nscheduler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" OneCycleLR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n                       max_lr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Upper learning rate boundaries in the cycle for each parameter group ")]),t._v("\n                       steps_per_epoch "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The number of steps per epoch to train for. ")]),t._v("\n                       epochs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The number of epochs to train for. ")]),t._v("\n                       anneal_strategy "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cos'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Specifies the annealing strategy")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br")])]),a("p",[t._v('使用anneal_strategy = "cos"得到的学习率衰减将如下所示：')]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212212125563.png",alt:"image-20221212212125563"}})]),t._v(" "),a("p",[t._v('使用anneal_strategy = "linear"，得到的学习率衰减将如下所示：')]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221212212158299.png",alt:"image-20221212212158299"}})]),t._v(" "),a("h3",{attrs:{id:"_1-11-reducelronplateaulr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-11-reducelronplateaulr"}},[t._v("#")]),t._v(" 1.11 ReduceLROnPlateauLR")]),t._v(" "),a("p",[t._v("当指标度量停止改进时，ReduceLROnPlateau会降低学习率。这很难可视化，因为学习率降低时间取决于您的模型、数据和超参数。")]),t._v(" "),a("h3",{attrs:{id:"_1-12-自定义学习率调度器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-12-自定义学习率调度器"}},[t._v("#")]),t._v(" 1.12 自定义学习率调度器")]),t._v(" "),a("p",[t._v("如果内置的学习率调度器不能满足需求，我们可以使用 lambda 函数定义一个调度器。lambda函数是一个返回基于epoch值的乘法因子的函数。")]),t._v(" "),a("p",[a("mark",[t._v("LambdaLR")]),t._v(" 通过将 lambda 函数的乘法因子应用到初始 LR 来调整学习速率：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("lr_epoch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_initial "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("p",[a("mark",[t._v("MultiplicativeLR")]),t._v(" 通过将 lambda 函数的乘法因子应用到前一个 epoch 的 LR 来调整学习速率：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("lr_epoch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_epoch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("t"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("p",[t._v("这些学习率调度器也有点难以可视化，因为它们高度依赖于已定义的 lambda 函数。")]),t._v(" "),a("h2",{attrs:{id:"_2-总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-总结"}},[t._v("#")]),t._v(" 2. 总结")]),t._v(" "),a("p",[t._v("以上就是PyTorch内置的学习率调度器，应该为深度学习项目选择哪种学习率调度器呢？")]),t._v(" "),a("p",[t._v("答案并不那么容易，ReduceLROnPlateau 是一个流行的学习率调度器。而现在其他的方法如 CosineAnnealingLR 和 OneCycleLR 或像 cosineannealingwarmrestart 和 CyclicLR 这样的热重启方法已经越来越受欢迎。")]),t._v(" "),a("p",[t._v("所以我们需要运行一些实验来确定哪种学习率调度器最适合要解决问题。但是可以说的是使用任何学习调度器都会影响到模型性能。")]),t._v(" "),a("h2",{attrs:{id:"_3-用于可视化学习率调度器的代码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-用于可视化学习率调度器的代码"}},[t._v("#")]),t._v(" 3. 用于可视化学习率调度器的代码")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lr_scheduler "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StepLR "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Import your choice of scheduler here ")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ticker "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" MultipleLocator \n\nLEARNING_RATE "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-3")]),t._v(" \nEPOCHS "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" \nSTEPS_IN_EPOCH "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set model and optimizer ")]),t._v("\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \noptimizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("LEARNING_RATE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Define your scheduler here as described above ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ... ")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get learning rates as each training step ")]),t._v("\nlearning_rates "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EPOCHS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("STEPS_IN_EPOCH"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n    optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    learning_rates"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("param_groups"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lr"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    scheduler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Visualize learinig rate scheduler ")]),t._v("\nfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" figsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("EPOCHS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("STEPS_IN_EPOCH"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n        learning_rates"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n        marker"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'o'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n        color"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'black'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_xlim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" EPOCHS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("STEPS_IN_EPOCH"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_ylim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" LEARNING_RATE "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0001")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_xlabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Steps'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_ylabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Learning Rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'top'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_visible"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'right'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_visible"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xaxis"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_major_locator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MultipleLocator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("STEPS_IN_EPOCH"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xaxis"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_minor_locator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MultipleLocator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br"),a("span",{staticClass:"line-number"},[t._v("33")]),a("br"),a("span",{staticClass:"line-number"},[t._v("34")]),a("br"),a("span",{staticClass:"line-number"},[t._v("35")]),a("br"),a("span",{staticClass:"line-number"},[t._v("36")]),a("br"),a("span",{staticClass:"line-number"},[t._v("37")]),a("br"),a("span",{staticClass:"line-number"},[t._v("38")]),a("br"),a("span",{staticClass:"line-number"},[t._v("39")]),a("br"),a("span",{staticClass:"line-number"},[t._v("40")]),a("br")])])],1)}),[],!1,null,null,null);s.default=e.exports}}]);