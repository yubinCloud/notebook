(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{819:function(t,s,a){"use strict";a.r(s);var n=a(22),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"_1-pytorch-神经网络工具箱"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-pytorch-神经网络工具箱"}},[t._v("#")]),t._v(" 1. PyTorch 神经网络工具箱")]),t._v(" "),a("h3",{attrs:{id:"_1-1-神经网络核心组件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-神经网络核心组件"}},[t._v("#")]),t._v(" 1.1 神经网络核心组件")]),t._v(" "),a("p",[t._v("当把神经网络的核心组件确定后，这个神经网络基本就确定了。这些核心组件包括：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("层")]),t._v("：神经网络的基本结构，将输入张量转换为输出张量。")]),t._v(" "),a("li",[a("strong",[t._v("模型")]),t._v("：层构成的网络。")]),t._v(" "),a("li",[a("strong",[t._v("损失函数")]),t._v("：参数学习的目标函数，通过最小化损失函数来学习各种参数。")]),t._v(" "),a("li",[a("strong",[t._v("优化器")]),t._v("：如何是损失函数最小，这就涉及到优化器。")])]),t._v(" "),a("p",[t._v("多个层链接在一起构成一个模型或网络，输入数据通过这个模型转换为预测值，然后损失函数把预测值与真实值进行比较，得到损失值（损失值可以是距离、概率值等），该损失值用于衡量预测值与目标结果的匹配或相似程度，优化器利用损失值更新权重参数，从而使损失值越来越小。这是一个循环过程，损失值达到一个阀值或循环次数到达指定次数，循环结束。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220119183547379.png",alt:"image-20220119183547379"}})]),t._v(" "),a("ul",[a("li",[t._v("构建网络层可以基于Module类或函数（nn.functional）。nn.functional 中函数与 nn.Module 中的 layer 的主要区别是后者继承 Module 类，会自动提取可学习的参数。而 nn.functional 更像是纯函数。")])]),t._v(" "),a("h3",{attrs:{id:"_1-2-如何构建神经网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-如何构建神经网络"}},[t._v("#")]),t._v(" 1.2 如何构建神经网络")]),t._v(" "),a("p",[t._v("我们用 "),a("code",[t._v("nn")]),t._v(" 工具箱，搭建一个神经网络，步骤好像不少，但关键就是选择网络层，构建网络，然后选择损失和优化器。")]),t._v(" "),a("h4",{attrs:{id:"_1-构建网络层"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-构建网络层"}},[t._v("#")]),t._v(" 1）构建网络层")]),t._v(" "),a("p",[t._v("我们可以使用 "),a("code",[t._v("torch.nn.Sequential()")]),t._v(" 构建网络层，使用起来就像搭积木一样，非常方便。")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("nn.Sequential")]),t._v(": A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.")]),t._v(" "),a("p",[t._v("一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数。")])]),t._v(" "),a("p",[t._v("一个三层网络的示例：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Net")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" in_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      \tself"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("in_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n            nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("，\n            nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_hidden_1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n_hidden_2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("，\n            nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("，\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最后一层不需要添加激活函数")]),t._v("\n            nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_hidden_2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  \t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("forward")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      \tx "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      \t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" x\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br")])]),a("p",[t._v("如果要对每层定义一个名称，我们可以采用 "),a("code",[t._v("Sequential")]),t._v(" 的一种改进方法，"),a("u",[t._v("在 Sequential 的基础上，通过add_module() 添加每一层，并且为每一层增加一个单独的名字")]),t._v("。此外，还可以在 Sequential 基础上，"),a("strong",[t._v("通过字典的形式添加每一层，并且设置单独的层名称")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Net")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Net4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            OrderedDict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"conv1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Conv2d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"relu1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pool"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MaxPool2d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n \n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            OrderedDict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dense1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("128")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"relu2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dense2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("128")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br")])]),a("h4",{attrs:{id:"_2-前向传播"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-前向传播"}},[t._v("#")]),t._v(" 2）前向传播")]),t._v(" "),a("p",[t._v("定义好每层后，最后还需要通过前向传播的方式把这些串起来。"),a("strong",[t._v("forward 函数")]),t._v("的任务需要把输入层、网络层、输出层链接起来，实现信息的前向传导。该函数的参数一般为输入数据，返回值为输出数据。")]),t._v(" "),a("p",[t._v("在forward函数中，有些层来自 nn.Module，也可以使用 nn.functional 定义。来自 nn.Module 的需要实例化，而使用 nn.functional 定义的可以直接使用。")]),t._v(" "),a("h4",{attrs:{id:"_3-反向传播"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-反向传播"}},[t._v("#")]),t._v(" 3）反向传播")]),t._v(" "),a("p",[t._v("关键是利用复合函数的链式法则。Pytorch 提供了自动反向传播的功能，使用 nn 工具箱，我们无需自己编写反向传播，"),a("strong",[t._v("直接让损失函数(loss)调用 backward() 即可")]),t._v("，非常方便和高效。")]),t._v(" "),a("h4",{attrs:{id:"_4-训练模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-训练模型"}},[t._v("#")]),t._v(" 4）训练模型")]),t._v(" "),a("p",[t._v("层、模型、损失函数和优化器等都定义或创建好，接下来就是训练模型。训练模型时需要注意使模型处于训练模式，即调用model.train()。")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("训练模型时需要注意使模型处于训练模式")]),t._v("，即调用 "),a("code",[t._v("model.train()")]),t._v(" 。调用model.train()会把所有的module设置为训练模式。")]),t._v(" "),a("li",[a("strong",[t._v("测试或验证阶段则需要使模型处于验证阶段")]),t._v("，即调用 "),a("code",[t._v("model.eval()")]),t._v("。调用model.eval()会把所有的training属性设置为 False。")])]),t._v(" "),a("p",[t._v("缺省情况下梯度是累加的，"),a("strong",[t._v("需要手工把梯度初始化或清零")]),t._v("，调用 "),a("code",[t._v("optimizer.zero_grad()")]),t._v(" 即可。训练过程中，正向传播生成网络的输出，计算输出和实际值之间的损失值。 调用 "),a("code",[t._v("loss.backward()")]),t._v(" 自动生成梯度，然后使用 "),a("code",[t._v("optimizer.step()")]),t._v(" 执行优化器，把梯度传播回每个网络。")]),t._v(" "),a("p",[t._v("如果希望用 GPU 训练，需要把模型、训练数据、测试数据发送到 GPU 上，即调用 "),a("code",[t._v(".to(device)")]),t._v("。如果需要使用多 GPU 进行处理，可使模型或相关数据引用 nn.DataParallel。")]),t._v(" "),a("h3",{attrs:{id:"_1-3-nn-module-和-nn-functional"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-nn-module-和-nn-functional"}},[t._v("#")]),t._v(" 1.3 nn.Module 和 nn.functional")]),t._v(" "),a("p",[t._v("前面我们使用 autograd 及 Tensor 实现机器学习实例时，需要做不少设置，如对叶子节点的参数 requires_grad 设置为 True，然后调用 backward，再从 grad 属性中提取梯度。对于大规模的网络，autograd 太过于底层和繁琐。而 "),a("u",[a("code",[t._v("nn.Module")]),t._v(" 能够自动检测到自己的 Parameter，并将其作为学习参数，且针对 GPU 运行进行了 CUDA 优化")]),t._v("。")]),t._v(" "),a("p",[a("code",[t._v("nn")]),t._v(" 中的层，"),a("strong",[t._v("一类是继承了 nn.Module")]),t._v("，其命名一般为 nn.Xxx（第一个是大写），如 nn.Linear、nn.Conv2d、nn.CrossEntropyLoss等。"),a("strong",[t._v("另一类是 nn.functional 中的函数")]),t._v("，其名称一般为nn.funtional.xxx，如 nn.funtional.linear、nn.funtional.conv2d、nn.funtional.cross_entropy等。"),a("u",[t._v("从功能来说两者相当")]),t._v("，基于 nn.Module 能实现的层，使用 nn.funtional 也可实现，反之亦然，而且性能方面两者也没有太大差异。不过"),a("u",[t._v("在具体使用时，两者还是有区别")]),t._v("，主要区别如下：")]),t._v(" "),a("ul",[a("li",[t._v("nn.Xxx 继承于 nn.Module，"),a("strong",[t._v("nn.Xxx 需要先实例化并传入参数，然后以函数调用的方式调用实例化的对象并传入输入数据")]),t._v("。它能够很好的与 nn.Sequential 结合使用，而 nn.functional.xxx 无法与 nn.Sequential 结合使用。")]),t._v(" "),a("li",[t._v("nn.Xxx 不需要自己定义和管理weight、bias参数；而 "),a("strong",[t._v("nn.functional.xxx 需要你自己定义weight、bias")]),t._v("，每次调用的时候都需要手动传入weight、bias等参数, 不利于代码复用。")]),t._v(" "),a("li",[t._v("dropout 操作在训练和测试阶段是有区别的，使用 nn.Xxx 方式定义dropout，在调用 model.eval() 之后，自动"),a("strong",[t._v("实现状态的转换")]),t._v("，而使用 nn.functional.xxx 却无此功能。")])]),t._v(" "),a("p",[t._v("总的来说，两种功能都是相同的，但 PyTorch 官方推荐："),a("font",{attrs:{color:"blue"}},[t._v("具有学习参数的采用nn.Xxx 方式；没有学习参数的等根据个人选择使用 nn.functional.xxx 或者 nn.Xxx 方式")]),t._v("。")],1),t._v(" "),a("h4",{attrs:{id:"●-linear-layer-fully-connected-layer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#●-linear-layer-fully-connected-layer"}},[t._v("#")]),t._v(" ● Linear Layer（Fully-connected Layer）")]),t._v(" "),a("p",[a("code",[t._v("nn.Linear(in_features, out_features)")])]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220123185035938.png",alt:"image-20220123185035938"}}),t._v(" "),a("ul",[a("li",[t._v("注意输入 Tensor 的前面的维度可以是任意的。")])]),t._v(" "),a("p",[t._v("上面那一层的计算过程如下：")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220123185243015.png",alt:"image-20220123185243015"}}),t._v(" "),a("h3",{attrs:{id:"_1-4-优化器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-优化器"}},[t._v("#")]),t._v(" 1.4 优化器")]),t._v(" "),a("p",[t._v("PyTorch 常用的优化方法"),a("u",[t._v("都封装在 "),a("code",[t._v("torch.optim")]),t._v(" 里面")]),t._v("，其设计很灵活，可以扩展为自定义的优化方法。所有的优化方法都是继承了基类 "),a("code",[t._v("optim.Optimizer")]),t._v("。并实现了自己的优化步骤。"),a("u",[t._v("最常用的优化算法就是梯度下降法及其各种变种")]),t._v("，这类优化算法使用参数的梯度值更新参数。")]),t._v(" "),a("p",[t._v("使用优化器的一般步骤为：")]),t._v(" "),a("h4",{attrs:{id:"_1-建立优化器实例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-建立优化器实例"}},[t._v("#")]),t._v(" 1）建立优化器实例")]),t._v(" "),a("p",[t._v("导入 optim 模块，实例化 SGD 优化器，这里使用动量参数 momentum（该值一般在(0,1)之间），是 SGD 的改进版，效果一般比不使用动量规则的要好：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" optim\noptimizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" optim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("lr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" momentum"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("momentum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br")])]),a("p",[t._v("以下步骤在训练模型的 for 循环中。")]),t._v(" "),a("h4",{attrs:{id:"_2-前向传播-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-前向传播-2"}},[t._v("#")]),t._v(" 2）前向传播")]),t._v(" "),a("p",[t._v("把输入数据传入神经网络 Net 实例化对象 model 中，自动执行 forward 函数，得到 out 输出值，然后用 out 与标记 label 计算损失值 loss。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("out "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br")])]),a("h4",{attrs:{id:"_3-清空梯度"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-清空梯度"}},[t._v("#")]),t._v(" 3）清空梯度")]),t._v(" "),a("p",[t._v("缺省情况梯度是累加的，"),a("strong",[t._v("在梯度反向传播前，先需把梯度清零")]),t._v("。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zero_grad"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("h4",{attrs:{id:"_4-反向传播"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-反向传播"}},[t._v("#")]),t._v(" 4）反向传播")]),t._v(" "),a("p",[t._v("基于损失值，把梯度进行反向传播。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("backward"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("h4",{attrs:{id:"_5-更新参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-更新参数"}},[t._v("#")]),t._v(" 5）更新参数")]),t._v(" "),a("p",[t._v("基于当前梯度（存储在参数的 "),a("code",[t._v(".grad")]),t._v(" 属性中）更新参数。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("h3",{attrs:{id:"_1-5-动态修改学习率参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-动态修改学习率参数"}},[t._v("#")]),t._v(" 1.5 动态修改学习率参数")]),t._v(" "),a("p",[t._v("修改参数的方式可以通过修改参数 "),a("code",[t._v("optimizer.params_groups")]),t._v(" 或新建 optimizer：")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("新建 optimizer 比较简单，optimizer 十分轻量级，所以开销很小。但是新的优化器会初始化动量等状态信息，这对于使用动量的优化器（momentum参数的 sgd）可能会造成收敛中的震荡。")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("optimizer.param_groups")]),t._v("：长度1的list。"),a("code",[t._v("optimizer.param_groups[0]")]),t._v(" 是长度为 6 的字典，包括权重参数、lr、momentum 等参数。示例如下：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("div",{staticClass:"highlight-lines"},[a("br"),a("br"),a("br"),a("div",{staticClass:"highlighted"},[t._v(" ")]),a("br"),a("br"),a("br")]),a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" epoch "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_epoches"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" epoch "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("param_groups"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lr'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 动态修改参数学习率")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("param_groups"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lr'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" train_loader"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br")])])])]),t._v(" "),a("h2",{attrs:{id:"_2-pytorch-数据处理工具箱"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-pytorch-数据处理工具箱"}},[t._v("#")]),t._v(" 2. PyTorch 数据处理工具箱")]),t._v(" "),a("h3",{attrs:{id:"_2-1-dataset-dataloader"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-dataset-dataloader"}},[t._v("#")]),t._v(" 2.1 Dataset & Dataloader")]),t._v(" "),a("p",[t._v("定义 Dataset：")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220123184436135.png",alt:"image-20220123184436135"}}),t._v(" "),a("p",[t._v("实例化 dataset 和 dataloader：")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220123184534185.png",alt:"image-20220123184534185"}}),t._v(" "),a("p",[t._v("两者关系：")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220123184617022.png",alt:"image-20220123184617022"}})])}),[],!1,null,null,null);s.default=e.exports}}]);