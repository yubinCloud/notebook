(window.webpackJsonp=window.webpackJsonp||[]).push([[129],{883:function(s,t,a){"use strict";a.r(t);var n=a(22),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#_5-1-探究语义-web-的组件"}},[s._v("5.1 探究语义 Web 的组件")]),a("ul",[a("li",[a("a",{attrs:{href:"#_5-1-1-语义-web-框架"}},[s._v("5.1.1 语义 Web 框架")])]),a("li",[a("a",{attrs:{href:"#_5-1-2-存储和检索-rdf"}},[s._v("5.1.2 存储和检索 RDF")])]),a("li",[a("a",{attrs:{href:"#_5-1-3-正向推理与反向推理"}},[s._v("5.1.3 正向推理与反向推理")])])])]),a("li",[a("a",{attrs:{href:"#_5-2-探索-owl-profile"}},[s._v("5.2 探索 OWL Profile")]),a("ul",[a("li",[a("a",{attrs:{href:"#_5-2-1-owl-full、dl-和-lite"}},[s._v("5.2.1 OWL Full、DL 和 Lite")])]),a("li",[a("a",{attrs:{href:"#_5-2-2-owl-profile"}},[s._v("5.2.2 OWL Profile")])])])]),a("li",[a("a",{attrs:{href:"#_5-3-owl-推理演示"}},[s._v("5.3 OWL 推理演示")]),a("ul",[a("li",[a("a",{attrs:{href:"#_5-3-1-本体"}},[s._v("5.3.1 本体")])]),a("li",[a("a",{attrs:{href:"#_5-3-2-示例应用程序"}},[s._v("5.3.2 示例应用程序")])]),a("li",[a("a",{attrs:{href:"#_5-3-3-运行结果"}},[s._v("5.3.3 运行结果")])])])])])]),a("p"),s._v(" "),a("h1",{attrs:{id:"chapter-5-现实世界中的知识建模"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#chapter-5-现实世界中的知识建模"}},[s._v("#")]),s._v(" chapter 5 现实世界中的知识建模")]),s._v(" "),a("blockquote",[a("p",[s._v("本章概览：本章将讲述如何在现实世界中使用本体，从中您可以学习到")]),s._v(" "),a("ul",[a("li",[s._v("本体如何与实际的应用程序融为一体")]),s._v(" "),a("li",[s._v("推理的概念以及它对实现 OWL 的语义有多重要")]),s._v(" "),a("li",[s._v("几种 OWL profile，它们的用途，以及如何借助它们为那些使用OWL的系统提供令人满意的计算特性")]),s._v(" "),a("li",[s._v("信息管理应用程序的重要设计原则")])])]),s._v(" "),a("h2",{attrs:{id:"_5-1-探究语义-web-的组件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-探究语义-web-的组件"}},[s._v("#")]),s._v(" 5.1 探究语义 Web 的组件")]),s._v(" "),a("p",[s._v("在下面这个例子中：")]),s._v(" "),a("div",{staticClass:"language-turtle line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-turtle"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Canine")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Daisy")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Canine.")])]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("显式的信息是知道了 Daisy 是 Canine 类型，但又由于 Canine 是 Mammal 的子类，所以 Daisy 又是一个哺乳动物的这个事实却"),a("strong",[s._v("是隐含的")]),s._v("。")]),s._v(" "),a("p",[s._v("OWL 仅仅是一种本体语言，而不是一个应用程序。因此，OWL 本身其实并不能完成任何工作。OWL 是描述语义和定义知识模型的"),a("u",[s._v("一种工具")]),s._v("。为了能够发挥OWL 的语义描述能力，很多语义 Web 应用程序都通过一个集成组件的框架来提供RDF 信息的存储和检索功能，以及对 OWL 语义的解释。"),a("strong",[s._v("知识库")]),s._v("是一种软件组件，用来表示一个在语义 Web 应用程序中基于本体描述的、处理和访问的信息集合。为了能够提供这样的功能，框架由一系列工具组成，"),a("u",[s._v("包括 RDF 存储（通常也被称作是三元组存储或者图存储）、一套访问 API 或者查询处理程序以及一个推理引擎（或者推理机）")]),s._v("。因为语义 Web 的组件建立在开放式标准接口、语言和协议的基础之上，所以在定制这些框架的时候，开发人员有大量的"),a("u",[s._v("组件可供选择")]),s._v("。")]),s._v(" "),a("h3",{attrs:{id:"_5-1-1-语义-web-框架"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-1-语义-web-框架"}},[s._v("#")]),s._v(" 5.1.1 语义 Web 框架")]),s._v(" "),a("p",[s._v("这些"),a("u",[s._v("框架通常由三种基础组件所组成：存储、访问和推理")]),s._v("。从根本上来讲，知识库是一个事实（陈述）的集合。语义Web 框架的组件用于存储这些事实，并且提供对这些事实的访问和推理。"),a("u",[s._v("事实既可以是显式的也可以是隐含的")]),s._v("。"),a("strong",[s._v("显式的事实")]),s._v("是指那些在知识库中直接进行了声明的事实，"),a("strong",[s._v("隐含的事实")]),s._v("则是蕴含，知识库中的显式事实本体语义和规则联合起来暗示了这种事实的存在。"),a("u",[s._v("蕴含由知识库的推理组件所驱动")]),s._v("。"),a("u",[s._v("根据实现的不同，蕴含既可以按照底层的存储机制直接存储，也可以根据需要当从知识库检索信息时推导生成")]),s._v("。")]),s._v(" "),a("p",[s._v("大多数语义 Web 框架的模块化设计都"),a("u",[s._v("允许开发人员对框架的各个方面进行定制，以便针对某个特定的需求集合来优化知识库")]),s._v("。例如，如果应用程序需要一种运行速度极快的系统，在只有少量 OWL 语义支持的前提下能够对大容量数据进行操作，则知识库应当将高伸缩性的持久性 RDF 存储和快速检索工具及小型推理组件集成到一起。如果需求中要求有完整的 OWL 推理功能，但是又没有提到可伸缩性和大数据量，那么应当将轻量级的内存 RDF 存储和强大的推理功能组合到一起使用。"),a("u",[s._v("在构建语义 Web 应用程序时进行上述这样的权衡是很常见的，因为日益增长的本体复杂度会对运算性能提出更高的要求，而这些运算开销大多来源于对蕴含的计算")]),s._v("。")]),s._v(" "),a("h3",{attrs:{id:"_5-1-2-存储和检索-rdf"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-2-存储和检索-rdf"}},[s._v("#")]),s._v(" 5.1.2 存储和检索 RDF")]),s._v(" "),a("p",[s._v("框架中的存储和访问机制有多种，既可以是带有检索 API 的小型 in-memory 模型，也可以是能够存储数十亿条陈述的基于服务器的RDF存储（带有能够并行处理数百条查询的查询处理器）。语义 Web 框架存储组件的具体实现对用户来说"),a("u",[s._v("通常是透明的")]),s._v("，因为用户通常仅仅通过访问组件来与其交互。")]),s._v(" "),a("p",[a("u",[a("strong",[s._v("基于图模型的 RDF 存储")]),s._v("是一种能够更加直接地对 RDF 数据的结构进行建模的数据结构")]),s._v("，它的出现缓解了基于关系模型存储的性能问题。给定一条特定的陈述，基于图的存储能够提供一种高效方式来定位与之共享相同资源（主语、谓语和宾语）的陈述，因为按照这种设计，它们会以"),a("strong",[s._v("高度的区域性")]),s._v("（这就是说它们的存储位置相互临近）进行存储。常见的基于图的 RDF 存储的实现使用了相互链接的陈述列表，这样每条共享相同资源（这些资源可能作为陈述主语、谓语或者宾语）的陈述就被安置到了一个连续的链接列表中，或者使用特殊的索引数据结构来链接在RDF图中相邻（连接）的陈述。"),a("u",[s._v("这样就提供了一种机制可以快速遍历包含某一特定资源（在陈述中作为主语、谓语或者宾语）的所有陈述")]),s._v("。")]),s._v(" "),a("p",[s._v("在知识库中访问信息最常用的方法是使用查询接口。"),a("strong",[s._v("SPARQL 协议与查询语言")]),s._v("是语义 Web 的推荐查询语言。查询处理器接收 SPARQL 查询并且将查询分发给底层知识库的RDF存储，进而以表或者 RDF 的形式生成结果集。")]),s._v(" "),a("h3",{attrs:{id:"_5-1-3-正向推理与反向推理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-3-正向推理与反向推理"}},[s._v("#")]),s._v(" 5.1.3 正向推理与反向推理")]),s._v(" "),a("p",[s._v("使用 OWL "),a("u",[s._v("最大的好处在于能够定义语义，而语义又充实了信息")]),s._v("。正如前面所提到的，知识库需要使用推理组件来解释语义并了解这些富语义的信息。执行推理的应用程序通常被称作"),a("strong",[s._v("推理引擎")]),s._v("或者推理机。推理引擎是这样一个系统，它能够基于知识库中已有的内容推理出新的信息。")]),s._v(" "),a("p",[s._v("很多语义 Web 框架都"),a("u",[s._v("使用基于规则的推理引擎来执行推理")]),s._v("。这些引擎通过将知识库中所包含的断言和一个逻辑规则集合组合起来推导断言或执行某些动作。规则包含两个部分，可以构建成一条 if-then 陈述。第1部分是规则的条件，而第2部分是规则的结论。规则可以用于表达 OWL 的大部分语义，并且"),a("u",[s._v("可以作为一种工具，供用户表达任意无法在 OWL 中建模的关系")]),s._v("。根据应用程序的不同，规则的种类也有很多种。"),a("strong",[s._v("一个规则确立了一个能够匹配规则条件的陈述集合，规则结论中的陈述在知识库中是隐含的")]),s._v("。")]),s._v(" "),a("p",[s._v("通常推理功能直接被集成到知识库中，而且对用户是透明的。在有些应用程序中，推理是作为外部组件实现的，以手工方式启动，而且蕴含是被手工添加到知识库中的。"),a("u",[s._v("在基于规则的推理机中执行推理主要有两种方式：正向链接推理和反向链接推理")]),s._v("。有些系统将两种方式组合到一起使用，也称作"),a("strong",[s._v("混合推理")]),s._v("。")]),s._v(" "),a("h4",{attrs:{id:"_1-理解正向链接推理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-理解正向链接推理"}},[s._v("#")]),s._v(" 1）理解"),a("mark",[s._v("正向链接推理")])]),s._v(" "),a("p",[a("u",[s._v("在"),a("strong",[s._v("正向链接推理")]),s._v("中，所有的蕴含（隐含事实）都直接在知识库中断言")]),s._v("。无论何时添加新的事实都会发生正向链接推理，而且作为同一操作的一部分，蕴含的陈述也会被立即添加到知识库中。"),a("strong",[s._v("结果是，知识库总是包含所有显式断言的事实和隐式断言的事实")]),s._v("。正向链接之所以得名，是因为推理的执行过程是从知识库中的数据和规则向着它们所隐含的蕴含进行的。下图演示了正向链接推理的过程。刚开始，事实 1 和事实 2 是知识库中唯一的显式事实。事实 1 蕴含了事实 3、事实 4 和事实 5 的存在。当加入了事实 6 之后，正向链接推理过程就会导出事实 7、事实 8 和事实 9 的蕴含，并且最终导出事实 10。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220112150847856.png",alt:"image-20220112150847856"}})]),s._v(" "),a("p",[a("strong",[s._v("每当添加一个新的显式事实之后，则新的蕴含就会被推导出来")]),s._v("。然而，正如这个例子所表明的那样，大量其他事实也被添加到了知识库中。如果您仅仅关注事实10的存在，那么您会发现：在正向链接推理过程中将使知识库变大，并且要在那些您并不需要的事实上花费额外的时间进行推理。正向链接推理方法"),a("strong",[s._v("增加了存储规模")]),s._v("，而且如果要提高知识库检索性能，就需要"),a("strong",[s._v("在插入和删除操作上花费过多的开销")]),s._v("。因为所有的蕴含都会被推导出来并作为数据存储起来，因此当进行检索操作的时候就不需要再进行额外推理，提高了检索速度。")]),s._v(" "),a("p",[a("strong",[s._v("如果您需要删除前面已经声明了的陈述，那么使用正向链接就有问题了")]),s._v("。删除以前声明的陈述"),a("u",[s._v("可能会导致出现以下这样的情况：尽管一条陈述不应当存在于知识库中，但是它实际上却依然存在")]),s._v("（也就是说，该陈述以前被声明为某一事实的蕴含，而该事实现在被删除了)。上面介绍的问题对于知识库中的“"),a("strong",[s._v("真值维护")]),s._v("”工作非常重要。真值维护问题是指当声明或者删除事实时仍然要确保所有蕴含事实的存在是合法的。不正确的真值维护会很快导致知识库不一致，使之包含不合法的蕴含或者矛盾的信息。"),a("u",[s._v("当删除事实时，真值维护过程会将原先由于它的加入而被推理出来的所有事实都删除")]),s._v("。多个事实可能会产生相同的蕴含，而被删除的事实本身也可能是蕴含，导致知识库中显式事实和隐含事实之间的相互关系非常复杂，因此，"),a("u",[s._v("要追踪某个事实并且保证该事实能够被正确删除是一件非常复杂的工作")]),s._v("。"),a("strong",[s._v("大多数知识库解决方案要么无法执行真值维护，要么采用了非常简单的处理方法")]),s._v("，即在删除一个或多个事实之后直接将所有蕴含事实全部清除，再重新执行争相链接推导。")]),s._v(" "),a("h4",{attrs:{id:"_2-理解反向链接推理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-理解反向链接推理"}},[s._v("#")]),s._v(" 2）理解"),a("mark",[s._v("反向链接推理")])]),s._v(" "),a("p",[s._v("反向链接是推理引擎执行推理的另一种主要方式。"),a("u",[s._v("在"),a("strong",[s._v("反向链接推理")]),s._v("中，推理的执行通过借助反向应用系统逻辑来导事实目标集合的条件（某条规则的条件或者某个查询的模式），直到知识库中的显式事实能够满足条件为止")]),s._v("。下图描述了这个过程。同样，我们的目标是确定知识库中是否含有事实10。反向链接推理要确定事实10是否能够由知识库中的显式事实推导得出，它是通过确定哪些事实会推导出事实10这一蕴含来完成这一目标的。在本例中，由于事实8蕴含了事实10的存在，所以推理过程必须确定事实8是否可以被推导出来。而事实8又是由事实2和事实7联合推导出来的。事实2已经存在，因此推理过程必须转而确定事实7是否可推导出来。事实7由事实3蕴含，而事实3又在知识库中显式存在。因此，可以确定知识库中包含事实1。如果在推理过程中这些事实中有任何一个缺失了，则意味着事实10不会包含在知识库中。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220112153521074.png",alt:"image-20220112153521074"}})]),s._v(" "),a("p",[a("strong",[s._v("反向链接推理是极具吸引力的，因为只有当有必要对某一事实是否存在进行验证时才会推导出蕴含")]),s._v("。这样一来就"),a("u",[s._v("避免了知识库中不必要的事实扩展，同时也没有为陈述的添加和删除带来额外的开销")]),s._v("。一旦事实通过反向链接推导出来，它们不会像正向链接那样在知识库中持久化（尽管为了提高性能可能会将它们存储在高速缓存中）。反向链接最主要的"),a("strong",[s._v("优点之一是极大地简化了真值维护")]),s._v("，因为只有显式事实才会在知识库中持久化，而且对已声明的陈述进行删除操作并不会影响到知识库中的其他陈述。\n反向链接同样"),a("strong",[s._v("也存在缺陷")]),s._v("，它"),a("strong",[s._v("将正向链接中插入和删除.上的开销转移到了访问上")]),s._v("。这意味着使用AP或者查询接口访问知识库中的信息会花费更多的计算和更高的代价。在很多知识库系统中，查询时间是最为关键的性能指标之一。如果不进行缓存，当需要重复多次地对某个查询进行应答时，则反向链接系统的效率就可能会非常低，因为在这个过程中将重复执行同一个蕴含过程。")]),s._v(" "),a("h4",{attrs:{id:"_3-选择正确的推理方法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-选择正确的推理方法"}},[s._v("#")]),s._v(" 3）选择正确的推理方法")]),s._v(" "),a("p",[s._v("选择正确的推理方法通常可以用这样一个问题来描述："),a("u",[s._v("评估需求和约束，并且确定哪一种方式最适用于给定的应用程序")]),s._v("。大多数框架都提供了正向链接知识库，因为这种知识库更加容易实现，而且在进行插入和删除操作的过程中知识库增加的规模和计算需求是可接受的。"),a("strong",[s._v("正向链接在执行查询操作上的性能远优于执行插入操作和删除操作的性能")]),s._v("，而且"),a("u",[s._v("在大多数应用程序中，查询是最经常执行的操作")]),s._v("。\n"),a("strong",[s._v("当本体经常变化或者知识库经常需要进行修改（包括陈述的删除）时，反向链接通常就成为很好的选择")]),s._v("。这是因为反向链接不会对底层存储的信息产生任何影响，而且对这些信息的任何修改都无需考虑推理方式所产生的影响。由于使用分布式推理系统时不存在集中式的知识库，所以此时采用反向链接方式就非常必要了。这种情况下，由于没有一个可用于执行正向链接并存储蕴含的知识库，因此必须使用一种基于反向链接的方式来扩展和分发查询。")]),s._v(" "),a("h2",{attrs:{id:"_5-2-探索-owl-profile"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-探索-owl-profile"}},[s._v("#")]),s._v(" 5.2 探索 OWL Profile")]),s._v(" "),a("h3",{attrs:{id:"_5-2-1-owl-full、dl-和-lite"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-1-owl-full、dl-和-lite"}},[s._v("#")]),s._v(" 5.2.1 OWL Full、DL 和 Lite")]),s._v(" "),a("p",[s._v("最初的 OWL 规范和 OWL 2 都提供了profile，也就是说 OWL 语言的子语言通过放弃某些表达能力换取了计算方面的效率。这些 profile 在使用OWL时引入了限定语法和非结构化的约束。"),a("u",[s._v("在原来的OWL规范中，有三种 profile 类型：OWL Full、OWL DL 和 OWL Lite")]),s._v("。其中，"),a("strong",[s._v("OWL Full")]),s._v(" 是完整的、不受限的 OWL 规范。"),a("strong",[s._v("OWL DL")]),s._v(" 在OWL Full 的基础上引入了很多约束，包括将类和个体分离开来。设计这些约束是为了使 OWL DL 可判定。"),a("strong",[s._v("OWL Lite")]),s._v(" 本质上是 OWL DL 语言元素的-一个子集。")]),s._v(" "),a("ul",[a("li",[s._v("引入OWL Lite 的目的是为应用程序和工具的开发人员提供开发目标，即提供一个能够支持 OWL 1 特性的起点。遗憾的是，人们认为 "),a("strong",[s._v("OWL Lite 在很大程度上是失败的")]),s._v("，因为它去除了 OWL 中太多有用的特性，同时又没有带来足够多的计算方面的好处，即没有在消减特性的同时变得更具吸引力。")]),s._v(" "),a("li",[a("strong",[s._v("OWL DL 则更为成功一些")]),s._v("，它提供了"),a("u",[s._v("描述逻辑")]),s._v("的很多功能，然而，当处理普通的知识库时，"),a("strong",[s._v("尽管它是可判定的，但是并不能保证只要正确地执行就能够得到所期望的性能")]),s._v("。从理论上讲，如果一种推理算法在“宇宙热寂”之前无法得到所希望的结果，那么即使最终完成了推理也是没有意义的。这并不是说 OWL DL 推理通常要花费数不清的年代才能完成，而是为了说明"),a("strong",[s._v("其判定性无法和现实需求同步")]),s._v("。\n"),a("ul",[a("li",[a("strong",[s._v("可判定性")]),s._v("规定，只有存在能够提供完备推理的算法才是可判定的。这并不对算法性能提出要求。")])])]),s._v(" "),a("li",[s._v("OWL Full 的引入主要是为了与 RDF 和 RDF Schema 相兼容。OWL Full 保留了描述任意事物所有特征的能力，但"),a("strong",[s._v("它是不可判定的，即目前尚没有出现能够基于复杂的 OWL Full 知识库推理出所有语义蕴含的算法")]),s._v("。")])]),s._v(" "),a("h3",{attrs:{id:"_5-2-2-owl-profile"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-2-owl-profile"}},[s._v("#")]),s._v(" 5.2.2 OWL Profile")]),s._v(" "),a("p",[s._v("OWL profile 的主要目的是生成几个 OWL 语言的子集，"),a("strong",[s._v("这些子集以牺牲某些表达能力换取更好的计算性能")]),s._v("。Profile 是为特殊的用户群体和实现技术而开发的。在本书撰写之际，存在3种标准的 OWL profile：OWL EL、OWL QL 和 OWL RL。每一种 profile 都是通过对 OWL DL 进行限定而得到的。")]),s._v(" "),a("blockquote",[a("p",[s._v("注意：理解OWL profile的内涵非常重要。您很少会用到OWL Full。"),a("strong",[s._v("OWL DL 和 OWL profile 才真正使 OWL 的应用变成了现实")]),s._v("。")])]),s._v(" "),a("p",[s._v("可以到 W3C 网站上下载 "),a("a",{attrs:{href:"https://www.w3.org/2007/OWL/wiki/Profiles",target:"_blank",rel:"noopener noreferrer"}},[s._v("OWL 2 的 Profile 文档"),a("OutboundLink")],1),s._v(" ，通过查阅该文档中的完整列表来查看详细的特性。")]),s._v(" "),a("h2",{attrs:{id:"_5-3-owl-推理演示"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-owl-推理演示"}},[s._v("#")]),s._v(" 5.3 OWL 推理演示")]),s._v(" "),a("p",[s._v("本节给出了一个实用的例子，在包含一个简单的 OWL 本体的知识库中实现了多个层次的推理。在本例中使用的知识库是一个 Jena 模型，而本体则是我们之前给出的人和犬科动物的例子。"),a("strong",[s._v("我们需要考虑 3 个层次的推理：无推理、RDFS 层面上的推理和 Pellet 提供的 OWL 层面上的推理")]),s._v("。在下面的例子中，我们将首先概述本体和应用程序，然后讲述在每个推理层次上运行应用程序的结果，并且揭示各种知识模型中信息的差异。")]),s._v(" "),a("h3",{attrs:{id:"_5-3-1-本体"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-1-本体"}},[s._v("#")]),s._v(" 5.3.1 本体")]),s._v(" "),a("p",[s._v("接下来会对本体每一部分给出说明，完整本体在最后给出。它不遵从哪一个特定的 Profile，但该本体仍然处在 OWL DL 范围之内。我们已经定义了一些类和属性，也定义了一些个体（但一般情况下个体都不包含在本体之内）。")]),s._v(" "),a("p",[a("strong",[s._v("首先")]),s._v("，我们给出了 ex:Mammal 和 ex:Human 的简单定义，且 ex:Human 是 ex:Mammal 的子类：")]),s._v(" "),a("div",{staticClass:"language-turtle line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-turtle"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Human")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal.")])]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[a("strong",[s._v("接着")]),s._v("，我们将类 ex:Canine 定义为类 ex:Mammal 的子类，并对其应用了一个值约束：它至少有一个 ex:breed 属性且属性值为类 ex:Breed 的实例：")]),s._v(" "),a("div",{staticClass:"language-turtle line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-turtle"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Canine")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("equivalentClass")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Restriction")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("onProperty")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("someValuesFrom")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed")])]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br")])]),a("p",[a("strong",[s._v("接下来")]),s._v("，使用 intersection-of 集合运算符定义 ex:PetOfRyan。这个类定义说明如果一个实例是类 ex:Mammal 的实例，并且他有一个 ex:hasOwner 属性且该属性值为 ex:Ryan，那么这个实例就是 ex:PetOfRyan 的一个实例：")]),s._v(" "),a("div",{staticClass:"language-turtle line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-turtle"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("PetOfRyan")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("intersectionOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Restriction")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("onProperty")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasOwner")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasValue")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Ryan")])]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("p",[a("strong",[s._v("然后")]),s._v("，我们定义了一个简单层次结构，该结构中包括品种类 ex:Breed 和它的两个子类 ex:LargeBreed 和ex:SmallBreed。然后我们定义了一个数据类型属性 ex:name 和三个对象属性 ex:breed、ex:hasOwner、和 ex:owns。在这里真正值得注意的一点是我们将 ex:registeredName 定义为了ex:name的一个子属性，而将 ex:owns 定义为了ex:hasOwner的逆属性：")]),s._v(" "),a("div",{staticClass:"language-turtle line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-turtle"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("LargeBreed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("SmallBreed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("DatatypeProperty.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("registeredName")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("DatatypeProperty")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subPropertyOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("ObjectProperty.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasOwner")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("ObjectProperty.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("owns")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("ObjectProperty")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("inverseOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasOwner.")])]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br")])]),a("p",[a("strong",[s._v("最后")]),s._v("定义了一些个体。前两个分别是 ex:GoldenRetriever（是 ex:LargeBreed 的一个实例）和 ex:Chihuahua（是ex:SmallBreed 的一个实例）。最后三个分别是 ex:Ryan、ex:Daisy 和 ex:Amber：")]),s._v(" "),a("div",{staticClass:"language-turtle line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-turtle"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("GoldenRetriever")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("LargeBreed.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Chihuahua")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("SmallBreed.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Ryan")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Human")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Ryan Blace"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("owns")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Daisy.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Daisy")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Canine")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Daisy"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("registeredName")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Morning Daisy Bathed in Sunshine"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("GoldenRetriever.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Amber")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Amber"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("GoldenRetriever.")])]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br")])]),a("details",{staticClass:"custom-block details"},[a("summary",[s._v("完整本体")]),s._v(" "),a("div",{staticClass:"language-turtle line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-turtle"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("@prefix")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token url"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("http://example.org#"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("@prefix")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token url"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("http://www.w3.org/1999/02/22-rdf-syntax-ns#"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("@prefix")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token url"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("http://www.w3.org/2000/01/rdf-schema#"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("@prefix")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token url"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("http://www.w3.org/2002/07/owl#"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Human")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Canine")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("equivalentClass")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Restriction")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("onProperty")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("someValuesFrom")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed")])]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("PetOfRyan")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("intersectionOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Restriction")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("onProperty")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasOwner")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasValue")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Ryan")])]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("LargeBreed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("SmallBreed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Class")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subClassOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Breed.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("DatatypeProperty.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("registeredName")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("DatatypeProperty")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                  "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("subPropertyOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("ObjectProperty.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasOwner")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("ObjectProperty.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("owns")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("ObjectProperty")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("owl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("inverseOf")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("hasOwner.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("GoldenRetriever")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("LargeBreed.")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Chihuahua")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("SmallBreed.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Ryan")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Human")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Ryan Blace"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("owns")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Daisy.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Daisy")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Canine")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Daisy"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("registeredName")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Morning Daisy Bathed in Sunshine"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("GoldenRetriever.")])]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Amber")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("type")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("Mammal")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("name")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Amber"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("breed")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[a("span",{pre:!0,attrs:{class:"token prefix"}},[s._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token local-name"}},[s._v("GoldenRetriever.")])]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br"),a("span",{staticClass:"line-number"},[s._v("44")]),a("br"),a("span",{staticClass:"line-number"},[s._v("45")]),a("br"),a("span",{staticClass:"line-number"},[s._v("46")]),a("br"),a("span",{staticClass:"line-number"},[s._v("47")]),a("br"),a("span",{staticClass:"line-number"},[s._v("48")]),a("br"),a("span",{staticClass:"line-number"},[s._v("49")]),a("br"),a("span",{staticClass:"line-number"},[s._v("50")]),a("br"),a("span",{staticClass:"line-number"},[s._v("51")]),a("br"),a("span",{staticClass:"line-number"},[s._v("52")]),a("br"),a("span",{staticClass:"line-number"},[s._v("53")]),a("br"),a("span",{staticClass:"line-number"},[s._v("54")]),a("br"),a("span",{staticClass:"line-number"},[s._v("55")]),a("br"),a("span",{staticClass:"line-number"},[s._v("56")]),a("br"),a("span",{staticClass:"line-number"},[s._v("57")]),a("br")])])]),s._v(" "),a("h3",{attrs:{id:"_5-3-2-示例应用程序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-2-示例应用程序"}},[s._v("#")]),s._v(" 5.3.2 示例应用程序")]),s._v(" "),a("p",[s._v("这里只对部分代码展开说明，完整代码在最后给出，程序运行环境与第二章的相同。")]),s._v(" "),a("p",[s._v("该应用程序用于演示在刚刚介绍的知识模型上进行多个层次的推理效果，该程序有 4 个命令行参数：输入文件、输入文件格式（N3、RDF/XML、Turtle 等）、输出文件和推理层次（none、rdfs 或 owl）。")]),s._v(" "),a("p",[a("strong",[s._v("首先")]),s._v("，应用会解析各个输入参数；")]),s._v(" "),a("p",[a("strong",[s._v("然后")]),s._v("，会创建一个 Jena 的 "),a("code",[s._v("model")]),s._v(" 用于存放各陈述，并根据推理模式的不同，采用不同的方式来创建出这个"),a("code",[s._v("OntModel")]),s._v(" 类型的 "),a("code",[s._v("model")]),s._v("：")]),s._v(" "),a("div",{staticClass:"language-java {3, 12, 21} line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModel")]),s._v(" model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// create the appropriate jena model")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("ul",[a("li",[s._v("如果设置无推理模式（“none”），则程序会使用 OntModelSpec.OWL_DL _MEM 创建了一个基本的本体模型。这规定了 Jena 应当载入 RDF、RDFS 和 OWL 本体，但是在模型上不进行推理操作：")])]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"none"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reasoningLevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("toLowerCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v('/*\n    * "none" is jena model with OWL_DL\n    * ontologies loaded and no inference enabled\n    */')]),s._v("\n   model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createOntologyModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModelSpec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OWL_DL_MEM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("ul",[a("li",[s._v("当运行在 RDFS 模式时，模型是使用 OntModelSpec.OWL_DL_MEM_RDFS_INF创建的。这个模型也将载入RDF、 RDFS 和 OWL 本体，然而，程序将使用 Jena 自带的内置推理引擎进行 RDFS 推理。这就意味着推理应当在所有 RDFS 词汇表元素（属性和类层次关系、定义域、值域等）之上进行：")])]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rdfs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reasoningLevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("toLowerCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v('/*\n    * "rdfs" is jena model with OWL_DL\n    * ontologies loaded and RDFS inference enabled \n    */')]),s._v("\n   model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createOntologyModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModelSpec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OWL_DL_MEM_RDFS_INF"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("ul",[a("li",[s._v("最后一种模式是关于 OWL 的，这种模式要比前两种进行更多设置。首先，我们使用 "),a("code",[s._v("PelletReasonerFactory")]),s._v(" 类创建一个新的 Reasoner 实例。然后，我们使用 Jena 的 "),a("code",[s._v("ModelFactory")]),s._v(" 类创建一个Jena推理模型，将参数设置为 Pellet 推理机和一个新创建的空 Jena 模型。最后，我们创建出自己真正的 Jena OntModel，该模型包装了我们刚刚创建的 Pellet 推理模型，而且同样载入了 RDF、RDFS 和 OWL 本体。这段代码的效果就是产生了一个能够使用 Pellet OWL 推理机来完成推理过程的 Jena 本体模型：")])]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"owl"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reasoningLevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("toLowerCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v('/*\n    * "owl" is jena model with OWL_DL ontologies\n    * wrapped around a pellet-based inference model\n    */')]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Reasoner")]),s._v(" reasoner "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PelletReasonerFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("theInstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Model")]),s._v(" infModel "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createInfModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      reasoner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createDefaultModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createOntologyModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModelSpec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OWL_DL_MEM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" infModel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br")])]),a("p",[a("strong",[s._v("之后")]),s._v("，当我们以上述 3 种方式之一创建模型之后，再使用 "),a("code",[s._v("model.read(…)")]),s._v(" 将本体装载到模型当中。"),a("u",[s._v("推理是自动进行的")]),s._v("，因此不需要进行显式的操作来保证所有的蕴含都能够正确导出：")]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("read")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputStream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" inputFileFormat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[a("strong",[s._v("最后一部分")]),s._v("将基于模型中"),a("u",[s._v("所有个体")]),s._v("组成的列表进行迭代，并且将所有以这些个体为主语的陈述都以摘要的形式打印到输出文件：")]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ExtendedIterator")]),s._v(" iIndividuals "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("listIndividuals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iIndividuals"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("hasNext")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Individual")]),s._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Individual")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("iIndividuals"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("next")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("printIndividual")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\niIndividuals"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      \nwriter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br")])]),a("details",{staticClass:"custom-block details"},[a("summary",[s._v("完整代码")]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("net"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("semwebprogramming"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("chapter5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PelletReasoning")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("io"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileInputStream")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("io"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileNotFoundException")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("io"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrintWriter")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Iterator")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mindswap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pellet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PelletReasonerFactory")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ontology"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Individual")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ontology"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModel")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ontology"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModelSpec")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Model")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Statement")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StmtIterator")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reasoner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Reasoner")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reasoner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ValidityReport")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("com"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hpl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("jena"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("iterator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ExtendedIterator")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InferenceExample")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/**\n    * This program takes 4 parameters an input file name \n    * an output file name an input file format a reasoning \n    * level {RDFS, OWL-DL}\n    */")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t   "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//validate the program arguments")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("   \n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("err"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Usage: java InferenceExample "')]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<input file> <input format> <output file> "')]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<none|rdfs|owl>"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" inputFileName "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" inputFileFormat "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" outputFileName "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" reasoningLevel "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//create an input stream for the input file")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileInputStream")]),s._v(" inputStream "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrintWriter")]),s._v(" writer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         inputStream "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileInputStream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputFileName"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("catch")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileNotFoundException")]),s._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("err"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"\'"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" inputFileName \n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"\' is an invalid input file."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//create an output print writer for the results")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         writer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrintWriter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outputFileName"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("catch")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileNotFoundException")]),s._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("err"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"\'"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" outputFileName \n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"\' is an invalid output file."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//create the appropriate jena model")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModel")]),s._v(" model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"none"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reasoningLevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("toLowerCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v('/*\n          * "none" is jena model with OWL_DL\n          * ontologies loaded and no inference enabled\n          */')]),s._v("\n         model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createOntologyModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModelSpec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OWL_DL_MEM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rdfs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reasoningLevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("toLowerCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v('/*\n          * "rdfs" is jena model with OWL_DL\n          * ontologies loaded and RDFS inference enabled \n          */')]),s._v("\n         model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createOntologyModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModelSpec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OWL_DL_MEM_RDFS_INF"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"owl"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reasoningLevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("toLowerCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v('/*\n          * "owl" is jena model with OWL_DL ontologies\n          * wrapped around a pellet-based inference model\n          */')]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Reasoner")]),s._v(" reasoner "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" \n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PelletReasonerFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("theInstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Model")]),s._v(" infModel "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createInfModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n            reasoner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createDefaultModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ModelFactory")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("createOntologyModel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OntModelSpec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OWL_DL_MEM"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" infModel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//invalid inference setting")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("err"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Invalid inference setting, "')]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"choose one of <none|rdfs|owl>."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//load the facts into the model")]),s._v("\n      model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("read")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputStream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" inputFileFormat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//validate the file")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ValidityReport")]),s._v(" validityReport "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("validate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validityReport "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),s._v("validityReport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("isValid")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Iterator")]),s._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validityReport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("getReports")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("hasNext")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("err"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n               "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ValidityReport"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Report")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("next")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("getDescription")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//Iterate over the individuals, print statements about them")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ExtendedIterator")]),s._v(" iIndividuals "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("listIndividuals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iIndividuals"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("hasNext")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Individual")]),s._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Individual")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("iIndividuals"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("next")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("printIndividual")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      iIndividuals"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      \n      writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   \n   "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/**\n    * Print information about the individual\n    * @param i The individual to output\n    * @param writer The writer to which to output\n    */")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("printIndividual")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Individual")]),s._v(" i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrintWriter")]),s._v(" writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//print the local name of the individual (to keep it terse)")]),s._v("\n      writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Individual: "')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("getLocalName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//print the statements about this individual")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StmtIterator")]),s._v(" iProperties "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("listProperties")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iProperties"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("hasNext")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Statement")]),s._v(" s "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Statement")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("iProperties"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("next")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"  "')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("getPredicate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("getLocalName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n            "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('" : "')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("getObject")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("toString")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      iProperties"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br"),a("span",{staticClass:"line-number"},[s._v("44")]),a("br"),a("span",{staticClass:"line-number"},[s._v("45")]),a("br"),a("span",{staticClass:"line-number"},[s._v("46")]),a("br"),a("span",{staticClass:"line-number"},[s._v("47")]),a("br"),a("span",{staticClass:"line-number"},[s._v("48")]),a("br"),a("span",{staticClass:"line-number"},[s._v("49")]),a("br"),a("span",{staticClass:"line-number"},[s._v("50")]),a("br"),a("span",{staticClass:"line-number"},[s._v("51")]),a("br"),a("span",{staticClass:"line-number"},[s._v("52")]),a("br"),a("span",{staticClass:"line-number"},[s._v("53")]),a("br"),a("span",{staticClass:"line-number"},[s._v("54")]),a("br"),a("span",{staticClass:"line-number"},[s._v("55")]),a("br"),a("span",{staticClass:"line-number"},[s._v("56")]),a("br"),a("span",{staticClass:"line-number"},[s._v("57")]),a("br"),a("span",{staticClass:"line-number"},[s._v("58")]),a("br"),a("span",{staticClass:"line-number"},[s._v("59")]),a("br"),a("span",{staticClass:"line-number"},[s._v("60")]),a("br"),a("span",{staticClass:"line-number"},[s._v("61")]),a("br"),a("span",{staticClass:"line-number"},[s._v("62")]),a("br"),a("span",{staticClass:"line-number"},[s._v("63")]),a("br"),a("span",{staticClass:"line-number"},[s._v("64")]),a("br"),a("span",{staticClass:"line-number"},[s._v("65")]),a("br"),a("span",{staticClass:"line-number"},[s._v("66")]),a("br"),a("span",{staticClass:"line-number"},[s._v("67")]),a("br"),a("span",{staticClass:"line-number"},[s._v("68")]),a("br"),a("span",{staticClass:"line-number"},[s._v("69")]),a("br"),a("span",{staticClass:"line-number"},[s._v("70")]),a("br"),a("span",{staticClass:"line-number"},[s._v("71")]),a("br"),a("span",{staticClass:"line-number"},[s._v("72")]),a("br"),a("span",{staticClass:"line-number"},[s._v("73")]),a("br"),a("span",{staticClass:"line-number"},[s._v("74")]),a("br"),a("span",{staticClass:"line-number"},[s._v("75")]),a("br"),a("span",{staticClass:"line-number"},[s._v("76")]),a("br"),a("span",{staticClass:"line-number"},[s._v("77")]),a("br"),a("span",{staticClass:"line-number"},[s._v("78")]),a("br"),a("span",{staticClass:"line-number"},[s._v("79")]),a("br"),a("span",{staticClass:"line-number"},[s._v("80")]),a("br"),a("span",{staticClass:"line-number"},[s._v("81")]),a("br"),a("span",{staticClass:"line-number"},[s._v("82")]),a("br"),a("span",{staticClass:"line-number"},[s._v("83")]),a("br"),a("span",{staticClass:"line-number"},[s._v("84")]),a("br"),a("span",{staticClass:"line-number"},[s._v("85")]),a("br"),a("span",{staticClass:"line-number"},[s._v("86")]),a("br"),a("span",{staticClass:"line-number"},[s._v("87")]),a("br"),a("span",{staticClass:"line-number"},[s._v("88")]),a("br"),a("span",{staticClass:"line-number"},[s._v("89")]),a("br"),a("span",{staticClass:"line-number"},[s._v("90")]),a("br"),a("span",{staticClass:"line-number"},[s._v("91")]),a("br"),a("span",{staticClass:"line-number"},[s._v("92")]),a("br"),a("span",{staticClass:"line-number"},[s._v("93")]),a("br"),a("span",{staticClass:"line-number"},[s._v("94")]),a("br"),a("span",{staticClass:"line-number"},[s._v("95")]),a("br"),a("span",{staticClass:"line-number"},[s._v("96")]),a("br"),a("span",{staticClass:"line-number"},[s._v("97")]),a("br"),a("span",{staticClass:"line-number"},[s._v("98")]),a("br"),a("span",{staticClass:"line-number"},[s._v("99")]),a("br"),a("span",{staticClass:"line-number"},[s._v("100")]),a("br"),a("span",{staticClass:"line-number"},[s._v("101")]),a("br"),a("span",{staticClass:"line-number"},[s._v("102")]),a("br"),a("span",{staticClass:"line-number"},[s._v("103")]),a("br"),a("span",{staticClass:"line-number"},[s._v("104")]),a("br"),a("span",{staticClass:"line-number"},[s._v("105")]),a("br"),a("span",{staticClass:"line-number"},[s._v("106")]),a("br"),a("span",{staticClass:"line-number"},[s._v("107")]),a("br"),a("span",{staticClass:"line-number"},[s._v("108")]),a("br"),a("span",{staticClass:"line-number"},[s._v("109")]),a("br"),a("span",{staticClass:"line-number"},[s._v("110")]),a("br"),a("span",{staticClass:"line-number"},[s._v("111")]),a("br"),a("span",{staticClass:"line-number"},[s._v("112")]),a("br"),a("span",{staticClass:"line-number"},[s._v("113")]),a("br"),a("span",{staticClass:"line-number"},[s._v("114")]),a("br"),a("span",{staticClass:"line-number"},[s._v("115")]),a("br"),a("span",{staticClass:"line-number"},[s._v("116")]),a("br"),a("span",{staticClass:"line-number"},[s._v("117")]),a("br"),a("span",{staticClass:"line-number"},[s._v("118")]),a("br"),a("span",{staticClass:"line-number"},[s._v("119")]),a("br"),a("span",{staticClass:"line-number"},[s._v("120")]),a("br"),a("span",{staticClass:"line-number"},[s._v("121")]),a("br"),a("span",{staticClass:"line-number"},[s._v("122")]),a("br"),a("span",{staticClass:"line-number"},[s._v("123")]),a("br"),a("span",{staticClass:"line-number"},[s._v("124")]),a("br"),a("span",{staticClass:"line-number"},[s._v("125")]),a("br"),a("span",{staticClass:"line-number"},[s._v("126")]),a("br"),a("span",{staticClass:"line-number"},[s._v("127")]),a("br"),a("span",{staticClass:"line-number"},[s._v("128")]),a("br"),a("span",{staticClass:"line-number"},[s._v("129")]),a("br"),a("span",{staticClass:"line-number"},[s._v("130")]),a("br"),a("span",{staticClass:"line-number"},[s._v("131")]),a("br"),a("span",{staticClass:"line-number"},[s._v("132")]),a("br"),a("span",{staticClass:"line-number"},[s._v("133")]),a("br"),a("span",{staticClass:"line-number"},[s._v("134")]),a("br"),a("span",{staticClass:"line-number"},[s._v("135")]),a("br"),a("span",{staticClass:"line-number"},[s._v("136")]),a("br"),a("span",{staticClass:"line-number"},[s._v("137")]),a("br"),a("span",{staticClass:"line-number"},[s._v("138")]),a("br"),a("span",{staticClass:"line-number"},[s._v("139")]),a("br"),a("span",{staticClass:"line-number"},[s._v("140")]),a("br"),a("span",{staticClass:"line-number"},[s._v("141")]),a("br"),a("span",{staticClass:"line-number"},[s._v("142")]),a("br"),a("span",{staticClass:"line-number"},[s._v("143")]),a("br"),a("span",{staticClass:"line-number"},[s._v("144")]),a("br"),a("span",{staticClass:"line-number"},[s._v("145")]),a("br"),a("span",{staticClass:"line-number"},[s._v("146")]),a("br"),a("span",{staticClass:"line-number"},[s._v("147")]),a("br"),a("span",{staticClass:"line-number"},[s._v("148")]),a("br"),a("span",{staticClass:"line-number"},[s._v("149")]),a("br"),a("span",{staticClass:"line-number"},[s._v("150")]),a("br"),a("span",{staticClass:"line-number"},[s._v("151")]),a("br"),a("span",{staticClass:"line-number"},[s._v("152")]),a("br"),a("span",{staticClass:"line-number"},[s._v("153")]),a("br"),a("span",{staticClass:"line-number"},[s._v("154")]),a("br"),a("span",{staticClass:"line-number"},[s._v("155")]),a("br"),a("span",{staticClass:"line-number"},[s._v("156")]),a("br"),a("span",{staticClass:"line-number"},[s._v("157")]),a("br"),a("span",{staticClass:"line-number"},[s._v("158")]),a("br")])])]),s._v(" "),a("h3",{attrs:{id:"_5-3-3-运行结果"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-3-运行结果"}},[s._v("#")]),s._v(" 5.3.3 运行结果")]),s._v(" "),a("h4",{attrs:{id:"_1-执行无推理模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-执行无推理模式"}},[s._v("#")]),s._v(" 1）执行无推理模式")]),s._v(" "),a("p",[s._v("在无推理模式下，我们希望看到的真正示例本体中表达的个体和陈述集合，输出结果没有给出额外的陈述，因为程序并没有"),a("strong",[s._v("推理出额外的陈述")]),s._v("：")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("Individual: Chihuahua\n  type : http://example.org#SmallBreed\n\nIndividual: GoldenRetriever\n  type : http://example.org#LargeBreed\n\nIndividual: Daisy\n  breed : http://example.org#GoldenRetriever\n  registeredName : Morning Daisy Bathed in Sunshine\n  name : Daisy\n  type : http://example.org#Canine\n\nIndividual: Ryan\n  owns : http://example.org#Daisy\n  name : Ryan Blace\n  type : http://example.org#Human\n\nIndividual: Amber\n  breed : http://example.org#GoldenRetriever\n  name : Amber\n  type : http://example.org#Mammal\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("h4",{attrs:{id:"_2-执行-rdfs-推理模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-执行-rdfs-推理模式"}},[s._v("#")]),s._v(" 2）执行 RDFS 推理模式")]),s._v(" "),a("p",[s._v("这种模式下可以看到 RDFS 语义能够推理出来的结果，在本例中，子类和子属性关系都会产生作用：")]),s._v(" "),a("div",{staticClass:"language-diff line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-diff"}},[a("code",[s._v("Individual: Chihuahua\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#SmallBreed\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://example.org#Breed\n")])]),s._v("\nIndividual: GoldenRetriever\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#LargeBreed\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://example.org#Breed\n")])]),s._v("\nIndividual: Daisy\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" breed : http://example.org#GoldenRetriever\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" registeredName : Morning Daisy Bathed in Sunshine\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" name : Daisy\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Canine\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  name: Morning Daisy Bathed in Sunshine\n")]),a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://example.org#Mammal\n")])]),s._v("\nIndividual: Ryan\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" owns : http://example.org#Daisy\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" name : Ryan Blace\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Human\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://example.org#Mammal\n")])]),s._v("\nIndividual: Amber\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" breed : http://example.org#GoldenRetriever\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" name : Amber\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Mammal\n")])])])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br")])]),a("p",[s._v("与无推理模式的输出结果的区别已被标出。该输出文件中"),a("strong",[s._v("包含一些由类和属性间的分类学关系推理出来的结果")]),s._v("。这些结果中含有的事实包括：")]),s._v(" "),a("ul",[a("li",[s._v("吉娃娃(Chihuahua)和金毛猎犬(Golden Retriever)都是品种")]),s._v(" "),a("li",[s._v("Daisy的注册名也是一个名称，Daisy不仅仅是一个犬科动物，而且还是一个哺乳动物。")])]),s._v(" "),a("p",[s._v("这些都是从 RDFS 名称空间中构造出来的语义的结果。"),a("u",[s._v("这其中有些蕴含的推导是因为子类关系导致某个实例成为了某个父类的成员。而另一些蕴含的导出则是因为子属性关系导致某个实例中添加了某个新属性")]),s._v("。因为我们仅仅提供了RDFS推理，因此我们仍然无法看到OWL语义所蕴含的新信息，这其中包括的事实有：Amber是一个犬科动物，ex:owns 和 ex:hasOwner 之间存在的逆属性关系意味着Daisy的主人是Ryan。")]),s._v(" "),a("h4",{attrs:{id:"_3-执行-owl-推理模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-执行-owl-推理模式"}},[s._v("#")]),s._v(" 3）执行 OWL 推理模式")]),s._v(" "),a("p",[s._v("在这个例子中，因为 Pallet 支持我们在示例本体中的使用的所有 OWL 和 RDFS 构造，所以我们应当在结果中看到所有的隐含陈述：")]),s._v(" "),a("div",{staticClass:"language-diff line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-diff"}},[a("code",[s._v("Individual: Ryan\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" owns : http://example.org#Daisy\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" name : Ryan Blace\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Human\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://www.w3.org/2002/07/owl#Thing\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Mammal\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  sameAs : http://example.org#Ryan\n")])]),s._v("\nIndividual: GoldenRetriever\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#LargeBreed\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://www.w3.org/2002/07/owl#Thing\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Breed\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  sameAs : http://example.org#GoldenRetriever\n")])]),s._v("\nIndividual: Chihuahua\n"),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://www.w3.org/2002/07/owl#Thing\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Breed\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#SmallBreed\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  sameAs : http://example.org#Chihuahua\n")])]),s._v("\nIndividual: Amber\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" breed : http://example.org#GoldenRetriever\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" name : Amber\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://www.w3.org/2002/07/owl#Thing\n")]),a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://example.org#Canine\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Mammal\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" sameAs : http://example.org#Amber\n")])]),s._v("\nIndividual: Daisy\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" registeredName : Morning Daisy Bathed in Sunshine\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" breed : http://example.org#GoldenRetriever\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  hasOwner : http://example.org#Ryan\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" name : Morning Daisy Bathed in Sunshine\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" name : Daisy\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://www.w3.org/2002/07/owl#Thing\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Canine\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  type : http://example.org#PetOfRyan\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v(" type : http://example.org#Mammal\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[s._v("  sameAs : http://example.org#Daisy\n")])])])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br")])]),a("p",[s._v("现在知识模型中有了很多新的陈述，所有从 RDFS 推理示例中得到的推理结果仍然位列其中。此外，所有的个体现在都是 owl:Thing 类的成员了。这是因为我们现在处于 OWL 语义的范畴之内，所以所有的实例都应当是 owl:Thing 类的成员。值得一提的是所有实例都和其自身是 owl.sameAs 的。依据推理引擎的具体实现的不同，您可能会发现类似这样的陈述"),a("u",[s._v("在技术上都是合理的，尽管它们并不一定很有用")]),s._v("。")]),s._v(" "),a("ul",[a("li",[s._v("Daisy确实有了主人Ryan。Daisy和Ryan之间已经正确地建立起了has-owner关系，类 ex:PetOfRyan 也得以正确解释，而且Daisy是该类的一个成员，因为它有 ex:hasOwner 属性，并且该属性的值为 ex:Ryan。")]),s._v(" "),a("li",[s._v("OWL 语义也得以正确解释，Amber 必然是一个犬科动物，因为她有一个 ex:breed 属性，而该属性指向ex:Breed类的一个实例。")])]),s._v(" "),a("p",[s._v("这个练习演示了 RDFS 和 OWL 语义的具体运作过程。"),a("strong",[s._v("RDFS 引入了属性和类的分类学结构，从而使您可以利用陈述和类成员的自动传播")]),s._v("。"),a("strong",[s._v("OWL 通过使用约束和高级类描述以及属性描述增加了更多的表达能力")]),s._v("。包含 OWL 构造的本体仍然可以在仅仅应用RDFS模式或无推理模式的应用程序中使用，不过，您将无法识别出所有的本体语义，除非您所使用的推理层次能够支持您在本体中所使用的构造。")])])}),[],!1,null,null,null);t.default=e.exports}}]);