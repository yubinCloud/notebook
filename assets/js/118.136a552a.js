(window.webpackJsonp=window.webpackJsonp||[]).push([[118],{871:function(t,s,a){"use strict";a.r(s);var m=a(22),c=Object(m.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"_1-统计学习方法的定义与分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-统计学习方法的定义与分类"}},[t._v("#")]),t._v(" 1. 统计学习方法的定义与分类")]),t._v(" "),a("h3",{attrs:{id:"_1-1-统计学习的概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-统计学习的概念"}},[t._v("#")]),t._v(" 1.1 统计学习的概念")]),t._v(" "),a("p",[t._v("统计学习已经应用到了生活中的众多领域，比如人工智能、模式识别、数据挖掘、自然语言处理、语音处理、计算视觉、信息检索、生物信息等。")]),t._v(" "),a("p",[a("mark",[t._v("统计学习")]),t._v("（"),a("strong",[t._v("Statistical Machine Learning")]),t._v("）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。它所研究对象就是数据，假设同类的数据具有一定的统计规律，那么就可以利用概率统计方法对其处理，从而达到一个对数据分析和预测的目的。")]),t._v(" "),a("ul",[a("li",[t._v("以计算机和网络为"),a("u",[t._v("平台")])]),t._v(" "),a("li",[t._v("以数据为"),a("u",[t._v("研究对象")])]),t._v(" "),a("li",[t._v("以预测和分析数据为"),a("u",[t._v("目的")])]),t._v(" "),a("li",[t._v("以方法为"),a("u",[t._v("中心")])]),t._v(" "),a("li",[t._v("是多领域交叉的"),a("u",[t._v("学科")])])]),t._v(" "),a("p",[t._v("简而言之，统计学习实现了一个从已知到未知的过程，利用已知数据和各种学科理论来对未知的新数据进行一个预测和分析。")]),t._v(" "),a("h3",{attrs:{id:"_1-2-统计学习的步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-统计学习的步骤"}},[t._v("#")]),t._v(" 1.2 统计学习的步骤")]),t._v(" "),a("div",{staticClass:"custom-block theorem"},[a("p",{staticClass:"title"},[t._v("Procedures")]),a("ol",[a("li",[t._v("得到一个有限的训练数据集合")]),t._v(" "),a("li",[t._v("确定学习模型的集合【模型】")]),t._v(" "),a("li",[t._v("确定模型选择的准则【策略】")]),t._v(" "),a("li",[t._v("实现求解最优模型的算法【算法】")]),t._v(" "),a("li",[t._v("通过学习方法选择最优模型")]),t._v(" "),a("li",[t._v("利用学习的最优模型对新数据进行预测或分析")])])]),a("p",[t._v("第一步是要得到一个有限的训练数据集合，也就是用来训练模型的。接下来，确定学习模型的集合，这个集合称之为"),a("strong",[t._v("假设空间")]),t._v("。然后，选择模型，而选择模型需要一定的评价准则，这就是第三步中确定模型选择的准则，我们称之为"),a("strong",[t._v("策略")]),t._v("。第四步是实现求解最优模型的算法，也就是根据第三步的策略，通过算法实现模型的选择。最后，通过学习方法也就是第 2-4 步，选择出一个最优模型，再将用以预测的数据代入到最优模型中，进行一个预测和分析。")]),t._v(" "),a("p",[t._v("这里注意一下，第二步中的模型，第三步里的策略，还有第四步的算法，是统计学习的三要素，这三个要素一起构成了学习系统：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727110435742.png",alt:"image-20220727110435742"}})]),t._v(" "),a("p",[t._v("如上图所示，首先给定一个训练集，这里面假设包含N个样本，然后放入到学习系统里面，学习系统就包含了模型、策略和算法，然后通过学习系统对于训练集中信息的不断学习，得到了一个最优模型，也就是对应了之前第五步。最后，输入一个新的实例，代入到最优模型中，通过预测系统得到了一个新的输出，也就是对于新数据进行的预测和分析。这就是统计学习方法的一个大概步骤。")]),t._v(" "),a("h3",{attrs:{id:"_1-3-统计学习方法的分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-统计学习方法的分类"}},[t._v("#")]),t._v(" 1.3 统计学习方法的分类")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/640",alt:"图片"}})]),t._v(" "),a("p",[t._v("从模型角度来进行分类，可以分为概率模型与非概率模型，线性模型与非线性模型，参数化模型与非参数化模型。")]),t._v(" "),a("ul",[a("li",[t._v("关于概率模型与非概率模型，概率模型就是用条件概率分布的形式表达的模型 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" ，而非概率模型，则是用函数形式表达的 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("。常见的决策树、朴素贝叶斯都属于概率模型，而感知机、支持向量机、神经网络，这些就属于非概率模型了。")],1),t._v(" "),a("li",[t._v("关于线性模型与非线性模型，如果模型函数是线性的，那么就是线性模型，反之，是非线性模型。")]),t._v(" "),a("li",[t._v("参数化模型，就是说模型的参数维度是固定的，可以由有限为的参数来刻画。那么非参数化模型就对应着参数维度不固定，所以参数化模型它更适用于简单问题，而非参数化模型，更适用于比较复杂的现实问题。")]),t._v(" "),a("li",[t._v("从算法的角度来分类，分为在线学习和批量学习。在线学习也就是大家熟知的Online Learning。每次接受一个样本，然后预测学习模型，之后不断重复这个步骤。批量学习就是Batch Learning，一次接受所有的数据，然后学习模型进行预测。")]),t._v(" "),a("li",[t._v("按技巧分类，按技巧它分为贝叶斯学习和核方法，贝叶斯学习就是基于贝叶斯定理的一个学习方法，而核方法则是基于核函数的。")])]),t._v(" "),a("h2",{attrs:{id:"_2-统计学习方法的基本分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-统计学习方法的基本分类"}},[t._v("#")]),t._v(" 2. 统计学习方法的基本分类")]),t._v(" "),a("p",[t._v("监督学习、无监督学习、半监督学习，是根据学习的数据中数据所包含的标记信息来区分的。")]),t._v(" "),a("ul",[a("li",[t._v("所学习的数据具有标注信息——监督学习；")]),t._v(" "),a("li",[t._v("所学习的数据不具有标注信息——无监督学习；")]),t._v(" "),a("li",[t._v("所学习的数据，只含有少量标注信息，大多数没有——半监督学习；")])]),t._v(" "),a("p",[t._v("这一篇中，我们主要讲解一下监督学习和无监督学习，强化学习这一部分，带着大家简单了解一下。")]),t._v(" "),a("h3",{attrs:{id:"_2-1-监督学习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-监督学习"}},[t._v("#")]),t._v(" 2.1 监督学习")]),t._v(" "),a("p",[a("mark",[t._v("监督学习")]),t._v("（"),a("strong",[t._v("Supervised Learning")]),t._v("）是指从标注数据中学习预测模型的机器学习问题，其本质是学习输入到输出的映射的统计规律。")]),t._v(" "),a("p",[t._v("几个概念：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("输入空间")]),t._v("（Input Space）：输入的所有可能取值的集合")]),t._v(" "),a("li",[a("strong",[t._v("实例")]),t._v("（Instance）：每一个具体的输入，通常由特征向量（Feature Vector）表示")]),t._v(" "),a("li",[a("strong",[t._v("特征空间")]),t._v("（Feature Space）：所有特征向量存在的空间")]),t._v(" "),a("li",[a("strong",[t._v("输出空间")]),t._v("（Output Space）：输出的所有可能取值的集合")])]),t._v(" "),a("p",[t._v("大多时候，输入空间和特征空间是相同的。既然说到大多时候，那就肯定存在不同的时候了，比如支持向量机中，核技巧的基本思想，就是通过一个非线性变换，将输入空间对应到特征空间上。")]),t._v(" "),a("p",[t._v("根据变量的不同类型，要解决的问题可以分为回归问题、分类问题和标注问题：")]),t._v(" "),a("ul",[a("li",[t._v("输入变量与输出变量均为连续变量的预测问题——"),a("strong",[t._v("回归问题")])]),t._v(" "),a("li",[t._v("输出变量为有限个离散变量的预测问题——"),a("strong",[t._v("分类问题")])]),t._v(" "),a("li",[t._v("输入变量与输出变量均为变量序列的预测问题—— "),a("strong",[t._v("标注问题")])])]),t._v(" "),a("p",[t._v("以下是相应的"),a("strong",[t._v("符号表示")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("输入变量 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1)],1)],1),t._v("；输入变量的取值 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("输出变量 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1)],1)],1),t._v("；输出变量的取值 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("输入实例 x 的 feature vector 表示："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"2"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"n"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),a("mjx-msup",[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"T"}})],1)],1)],1)],1)],1)],1),t._v(" "),a("li",[t._v("以 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1)],1)],1),t._v(" 表示多个输入变量中的第 i 个变量："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.294em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msubsup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.294em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"2"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msubsup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.294em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"n"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-msup",[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"T"}})],1)],1)],1)],1)],1)],1),t._v(" "),a("li",[t._v("样本容量为 N 的训练集："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1)]),t._v(" "),a("p",[t._v("对于监督学习，主要就是研究输入到输出之间的统计规律，所以要有关于输入和输出的基本假设：")]),t._v(" "),a("ul",[a("li",[t._v("监督学习的基本假设：X 和 Y 具有联合概率分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("监督学习的目的：学习一个输入到输出的映射，这一映射以模型表示")]),t._v(" "),a("li",[t._v("模型的形式：条件概率分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 或决策函数 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("假设空间（Hypothesis Space）：所有这些可能模型的集合")])]),t._v(" "),a("p",[a("strong",[t._v("映射关系以模型来表示的话，主要有两种，一种是条件概率分布的形式，一种是决策函数的形式")]),t._v("。条件概率分布的形式其实就是概率模型，而决策函数的形式就是非概率模型。对具体的输入进行相应的输出预测时，表达为：")]),t._v(" "),a("p"),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mtext",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"A0"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-utext",{staticStyle:{"font-family":"serif"},attrs:{variant:"normal"}},[t._v("或")])],1),a("mjx-mtext",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"A0"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),a("p"),t._v(" "),a("p",[t._v("流程图如下：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727142802263.png",alt:"image-20220727142802263"}})]),t._v(" "),a("p",[t._v("通过学习系统学习到的模型用加一个帽子表示，即 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1)],1)],1),t._v(" 或 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.291em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1)],1)],1)],1)],1)],1),t._v("。然后，给一个新的实例，这个输出也可以表达成决策函数或者条件概率分布预测值的形式，之所以通过 argmax，选择使条件概率分布最大的y值，就是因为"),a("strong",[t._v("我们预测的思想就是想找到出现的可能性最大的值")]),t._v("。")],1),t._v(" "),a("h3",{attrs:{id:"_2-2-无监督学习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-无监督学习"}},[t._v("#")]),t._v(" 2.2 无监督学习")]),t._v(" "),a("p",[a("mark",[t._v("无监督学习")]),t._v("（"),a("strong",[t._v("Unsupervised Learning")]),t._v("）是指从无标注数据中学习预测模型的机器学习问题，其本质是学习数据中统计规律或潜在结构。")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727143255267.png",alt:"image-20220727143255267"}})]),t._v(" "),a("p",[t._v("对于无监督学习，无标注数据，自然直接得到的数据只有输入，输出是隐含的潜在内容。")]),t._v(" "),a("p",[t._v("几个概念：")]),t._v(" "),a("ul",[a("li",[t._v("输入空间："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"X"}})],1)],1)],1)],1)],1),t._v(" "),a("li",[t._v("隐式结构空间："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"Z"}})],1)],1)],1)],1)],1),t._v(" "),a("li",[t._v("模型：函数 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"z"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"g"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" "),a("strong",[t._v("或")]),t._v("条件概率分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"z"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" "),a("strong",[t._v("或")]),t._v("条件概率分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"z"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("假设空间（Hypothesis Space）：所有这些可能模型的集合")]),t._v(" "),a("li",[t._v("目的：选出在给定评价标准下的最优模型")]),t._v(" "),a("li",[t._v("样本容量为 N 的训练集："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"U"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-TeXAtom",{attrs:{space:"4"}},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1)],1)],1)],1)],1)]),t._v(" "),a("p",[t._v("因为无监督学习，本质是研究数据中的潜在结构内容，也就是需要学习隐含在数据结构内部的信息，所以无监督学习对应的不是输出空间，而是隐式结构空间。")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727143737519.png",alt:"image-20220727143737519"}})]),t._v(" "),a("h3",{attrs:{id:"_2-3-强化学习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-强化学习"}},[t._v("#")]),t._v(" 2.3 强化学习")]),t._v(" "),a("p",[t._v("强化学习其实要强调一个互动，互动是指的是智能系统与环境之间的一个连续互动，通过这个互动，学习一个最优的行为策略。可以参见李宏毅讲解的一章。")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727144002687.png",alt:"image-20220727144002687"}})]),t._v(" "),a("p",[t._v("强化学习可以基于策略，也可以基于价值，基于策略的则是选择最优策略，基于价值是选择最优价值，都可以得到一个最优模型。")]),t._v(" "),a("h2",{attrs:{id:"_3-统计学习方法的三要素"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-统计学习方法的三要素"}},[t._v("#")]),t._v(" 3. 统计学习方法的三要素")]),t._v(" "),a("p",[t._v("构成统计学习方法的三要素——"),a("strong",[t._v("模型、策略、算法")]),t._v("。对于监督学习、无监督学习、强化学习，这三要素都是必备的，只不过形式不同。")]),t._v(" "),a("p",[t._v("对于监督学习，处理的是有标注的数据，数据中输出空间的类型已知，所以相应的模型、策略以及算法都是比较具体的。但对于无监督学习，处理的数据是无标注信息的，我们希望找到隐含在数据内部的结构信息，这时候的三要素——模型、策略、算法就不那么具体了。")]),t._v(" "),a("h3",{attrs:{id:"_3-1-监督学习的三要素"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-监督学习的三要素"}},[t._v("#")]),t._v(" 3.1 监督学习的三要素")]),t._v(" "),a("h4",{attrs:{id:"_3-1-1-监督学习的模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-1-监督学习的模型"}},[t._v("#")]),t._v(" 3.1.1 监督学习的模型")]),t._v(" "),a("p",[t._v("对于监督学习，模型主要可以表达成两种形式，一个是条件概率分布的形式，一个是决策函数的形式。条件概率分布的形式，即概率模型；而决策函数的形式则是非概率模型。")]),t._v(" "),a("p",[a("mark",[t._v("假设空间")]),t._v("（Hypothesis Space）是所有可能的条件概率分布或决策函数，用 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1)],1)],1),t._v(" 表示。")],1),t._v(" "),a("p",[a("strong",[t._v("如果模型是由决策函数组成的集合")]),t._v("，那么假设空间将是所有可能决策函数的集合。每一个决策函数由一个参数向量决定，而假设空间是由参数向量所决定的函数组构成。我们称所有可能的参数向量组成的空间为"),a("strong",[t._v("参数空间")]),t._v("，那么这个假设空间就应该是由参数空间决定的了。")]),t._v(" "),a("ul",[a("li",[t._v("若 Hypothesis Space 是决策函数的集合："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1),t._v(" "),a("li",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1)],1)],1),t._v(" 由一个参数向量决定的函数族构成："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-msub",{attrs:{space:"4"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"3B8"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"3B8"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"2208"}})],1),a("mjx-msup",[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-b"},[a("mjx-c",{attrs:{c:"R"}})],1)],1),a("mjx-script",{staticStyle:{"vertical-align":"0.413em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"n"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("参数空间："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"398"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"3B8"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"3B8"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"2208"}})],1),a("mjx-msup",[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-b"},[a("mjx-c",{attrs:{c:"R"}})],1)],1),a("mjx-script",{staticStyle:{"vertical-align":"0.413em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"n"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1)]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727145646811.png",alt:"image-20220727145646811"}})]),t._v(" "),a("p",[a("strong",[t._v("如果模型表示为条件概率分布的形式")]),t._v("，那么假设空间就是由所有可能的条件概率分布组成的集合。对于每一个条件概率分布，它由一个参数向量来决定的，所以假设空间也可以说成是由一个参数向量决定的条件概率分布族构成的。此处，所有可能的参数构成参数空间。")]),t._v(" "),a("ul",[a("li",[t._v("若 Hypothesis Space 是决策函数的集合："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1),t._v(" "),a("li",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1)],1)],1),t._v(" 由一个参数向量决定的条件概率分布族构成："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"3B8"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"3B8"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"2208"}})],1),a("mjx-msup",[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-b"},[a("mjx-c",{attrs:{c:"R"}})],1)],1),a("mjx-script",{staticStyle:{"vertical-align":"0.413em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"n"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1)]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727150023099.png",alt:"image-20220727150023099"}})]),t._v(" "),a("h4",{attrs:{id:"_3-1-2-监督学习的策略"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-2-监督学习的策略"}},[t._v("#")]),t._v(" 3.1.2 监督学习的策略")]),t._v(" "),a("p",[t._v("如何在 Hypothesis Space 里面选择一个最优模型呢？这里就需要用到第二个要素策略。策略其实就是一种学习准则，用来选择最优模型的。想要选择模型，那么一定要知道如何度量模型的好坏。所以，这里先要引入几个概念。")]),t._v(" "),a("ul",[a("li",[a("mark",[t._v("损失函数")]),t._v("：度量模型一次预测的好坏，记作 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，这里的 Y 是 label")],1),t._v(" "),a("li",[a("mark",[t._v("风险函数")]),t._v("：度量平均意义下模型预测的好坏")])]),t._v(" "),a("p"),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-msub",{attrs:{space:"4"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"E"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"P"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"["}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"]"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-msub",{attrs:{space:"4"}},[a("mjx-mo",{staticClass:"mjx-lop",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"222B"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.896em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"X"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"D7"}})],1),a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"Y"}})],1)],1)],1)],1)],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"d"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"d"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1)],1)],1)],1),a("p"),t._v(" "),a("blockquote",[a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 中 exp 表示 expectation，R 表示 Risk，f 表示模型，其计算就是对损失函数求了一下概率期望。如果对于假设空间中的每一个模型，我们都求一下风险函数值，选择一个最小的风险函数值所对应的模型就是我们想要的最优模型了。但是联合分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 并不是已知的，因此风险函数也就不能直接求出，所以我们需要一个经验值（估计值）来替代这个函数，也就引出了“经验风险”。")],1)]),t._v(" "),a("ul",[a("li",[a("mark",[t._v("经验风险")]),t._v("：模型 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 关于训练集的平均损失 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"m"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1)],1)],1)],1)],1),a("mjx-munderover",{attrs:{space:"2",limits:"false"}},[a("mjx-mo",{staticClass:"mjx-sop"},[a("mjx-c",{attrs:{c:"2211"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.291em"}}),a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，其中训练集 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1)]),t._v(" "),a("blockquote",[a("p",[t._v("emp 表示 empirical")])]),t._v(" "),a("p",[t._v("下面我们看几种常见的损失函数：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727152000844.png",alt:"image-20220727152000844"}})]),t._v(" "),a("p",[a("strong",[t._v("根据大数定律，当样本容量 N 趋于无穷大的时候，经验损失就会趋于风险函数")]),t._v("。所以，在一定程度上用经验损失作为风险函数的估计值是合理的。公式如下：")]),t._v(" "),a("p"),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"m"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"2192"}})],1),a("mjx-msub",{attrs:{space:"4"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mstyle",{attrs:{space:"2"}},[a("mjx-mspace",{staticStyle:{width:"2em"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"2192"}})],1),a("mjx-mi",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"221E"}})],1)],1)],1)],1),a("p"),t._v(" "),a("p",[t._v("可是在现实生活中，样本容量N一般是有限的，有的时候甚至会很小。因此，"),a("strong",[t._v("仅仅用经验风险来估计风险函数效果并不理想，需要对其进行一定的矫正")]),t._v("。这里就涉及到监督学习的两个基本策略，一个是经验风险最小化策略，一个是结构风险最小化策略：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"90%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727152419887.png",alt:"image-20220727152419887"}})]),t._v(" "),a("p",[a("u",[t._v("当样本容量 N 足够大的时候")]),t._v("，可以认为经验风险是风险函数的一个估计值，此时，只需选取使经验风险最小的模型即可。"),a("u",[t._v("但当样本容量 N 比较小的时候")]),t._v("，仅仅经验风险最小化，容易造成过拟合的现象，于是引入结构风险的概念。结构风险是在经验风险的基础上加了一个惩罚项，惩罚项针对的是模型的复杂度，也就是这里的模型越复杂，J(f) 就越大，当然模型越简单，J(f) 就越小。"),a("strong",[t._v("结构风险的惩罚系数，可以平衡经验风险和模型的复杂度")]),t._v("。结构风险最小化，则是选取一个使结构风险最小的模型。")]),t._v(" "),a("p",[t._v("关于监督学习的策略，追根究底，就是选取一个目标函数，可以是经验风险，或者是结构风险，然后通过优化这个目标函数，达到学习模型的目的。")]),t._v(" "),a("h4",{attrs:{id:"_3-1-3-监督学习的算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-3-监督学习的算法"}},[t._v("#")]),t._v(" 3.1.3 监督学习的算法")]),t._v(" "),a("p",[t._v("在假设空间里面，根据策略去选择最优模型，需要一个具体的操作方案，操作方案也就是算法，是用来求解最优模型的。")]),t._v(" "),a("p",[t._v("如果这个最优模型存在显式解析解，那么简单了，直接把这个结果写出来即可。但是往往这个显式解是不存在的，所以需要一定的数值计算方法，比如梯度下降法。")]),t._v(" "),a("h3",{attrs:{id:"_3-2-无监督学习的三要素"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-无监督学习的三要素"}},[t._v("#")]),t._v(" 3.2 无监督学习的三要素")]),t._v(" "),a("p",[t._v("无监督学习处理的是无标注的数据，所以我们希望在数据内部找到隐含的结构信息。")]),t._v(" "),a("ul",[a("li",[t._v("模型：函数 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"z"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-msub",{attrs:{space:"4"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"g"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"3B8"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" "),a("strong",[t._v("或")]),t._v("条件概率分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"3B8"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"z"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" "),a("strong",[t._v("或")]),t._v("条件概率分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"3B8"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"z"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("策略：优化目标函数")]),t._v(" "),a("li",[t._v("算法：通常是迭代算法")])]),t._v(" "),a("p",[t._v("模型中涉及到的 z 来自于隐式结构空间，此时模型有三种表达方式，一种是函数形式，另外两种是条件概率分布的形式。")]),t._v(" "),a("p",[t._v("假设空间：")]),t._v(" "),a("ul",[a("li",[t._v("所有可能的函数所组成的集合")]),t._v(" "),a("li",[t._v("给定 x 的条件下，所有可能的 z 的条件概率分布组成的集合")]),t._v(" "),a("li",[t._v("给定 z 的情况下，所有可能的 x 的条件概率分布组成的集合")])]),t._v(" "),a("p",[t._v("参数空间，则是由所有可能的参数组成的。")]),t._v(" "),a("p",[t._v("对于无监督学习，策略同样是优化目标函数。当然，因为无监督学习处理的数据是无标注信息的，更具有多变性，相应的目标函数会根据数据的不同而发生变化。")]),t._v(" "),a("h2",{attrs:{id:"_4-模型的评估与选择"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-模型的评估与选择"}},[t._v("#")]),t._v(" 4. 模型的评估与选择")]),t._v(" "),a("p",[t._v("对模型进行评估时，我们主要从模型对已知数据和未知数据的预测能力来看，需要用到训练误差与测试误差。对于一个模型而言，如果训练误差低，测试误差高，那么容易出现过拟合的现象，与之相对的是欠拟合，这是训练误差高，测试误差低时容易出现的情况。本节将对这部分进行讲解。")]),t._v(" "),a("h3",{attrs:{id:"_4-1-evaluation-training-error-test-error"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-evaluation-training-error-test-error"}},[t._v("#")]),t._v(" 4.1 Evaluation: Training Error & Test Error")]),t._v(" "),a("p",[t._v("关于模型拟合的好坏，我们可以通过训练集计算训练误差来度量。以训练集代表已知数据，"),a("strong",[t._v("训练误差就反映了模型对已知数据的拟合能力")]),t._v("。")]),t._v(" "),a("p",[t._v("关于模型的预测效果，可以通过测试集来度量。我们以测试集代表未知数据。假如存在一个样本容量为N'的测试集，我们将测试集中所有的实例都放到预测系统里面，根据之前训练出的模型，就可以计算出一系列的预测值。这些预测值与真实值之间的差异，就是测试误差，通常"),a("strong",[t._v("以测试误差来度量模型对未知数据的预测效果")]),t._v("。")]),t._v(" "),a("h4",{attrs:{id:"_4-1-1-training-error"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-1-training-error"}},[t._v("#")]),t._v(" 4.1.1 Training Error")]),t._v(" "),a("ul",[a("li",[t._v("学习到的模型："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-TeXAtom",{attrs:{space:"4"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("Training Set："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("Training Error："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"m"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-TeXAtom",[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1)],1)],1)],1)],1),a("mjx-munderover",{attrs:{space:"2",limits:"false"}},[a("mjx-mo",{staticClass:"mjx-sop"},[a("mjx-c",{attrs:{c:"2211"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.291em"}}),a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-TeXAtom",{attrs:{space:"2"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1)]),t._v(" "),a("p",[a("mark",[t._v("训练误差")]),t._v("是训练数据集的平均损失，具体来说就是先计算出训练集上每个样本的损失，然后再计算平均值。")]),t._v(" "),a("h4",{attrs:{id:"_4-1-2-test-error"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-2-test-error"}},[t._v("#")]),t._v(" 4.1.2 Test Error")]),t._v(" "),a("ul",[a("li",[t._v("学习到的模型："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-TeXAtom",{attrs:{space:"4"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("Test Set："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.074em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.258em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msubsup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.258em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.258em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msubsup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.258em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.27em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msubsup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.27em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1)],1),t._v(" "),a("li",[t._v("Test Error："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"s"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-msup",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.067em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1)],1)],1)],1)],1)],1)],1),a("mjx-munderover",{attrs:{space:"2",limits:"false"}},[a("mjx-mo",{staticClass:"mjx-sop"},[a("mjx-c",{attrs:{c:"2211"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.067em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1)],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.291em"}}),a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.254em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-TeXAtom",{attrs:{space:"2"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.254em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1)]),t._v(" "),a("p",[a("mark",[t._v("测试误差")]),t._v("是根据测试数据集所得。具体来说，就是计算测试集中每个样本点的损失，再求平均值。")]),t._v(" "),a("h4",{attrs:{id:"_4-1-3-误差率与准确率"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-3-误差率与准确率"}},[t._v("#")]),t._v(" 4.1.3 误差率与准确率")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727161921023.png",alt:"image-20220727161921023"}})]),t._v(" "),a("p",[t._v("注："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"r"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"s"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-msub",{attrs:{space:"3"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"s"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1),t._v(" "),a("p",[t._v("当计算测试误差时，选取的损失函数是一个 0-1 示性函数，那么就可以得到误差率。所以说，误差率与准确率其实是测试误差的两个特例。")]),t._v(" "),a("p",[t._v("具体解释一下这里所用的示性函数：")]),t._v(" "),a("ul",[a("li",[t._v("通过训练出来的模型所得到的预测值，不等于真实值的时候，记损失为 1;")]),t._v(" "),a("li",[t._v("通过训练出来的模型所得到的预测值，等于真实值的时候，记损失为 0.")])]),t._v(" "),a("p",[t._v("这就可以看出，"),a("strong",[t._v("误差率体现的是在测试集中预测错误的样本点的个数占测试集样本总个数的比例")]),t._v("，"),a("strong",[t._v("准确率则是预测正确的样本点个数占测试集样本总个数的比例")]),t._v("。很明显，误差率和准确率之和为 1。")]),t._v(" "),a("h3",{attrs:{id:"_4-2-model-selection"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-model-selection"}},[t._v("#")]),t._v(" 4.2 Model Selection")]),t._v(" "),a("p",[t._v("在模型选择时，我们当然希望训练误差和测试误差都很小，但是当训练误差很小的时候，测试误差并不一定小，因此需要二者的一个平衡。")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727163304309.png",alt:"image-20220727163304309"}})]),t._v(" "),a("p",[t._v("以 M 代表模型的复杂度，M 越大模型越复杂。橙色的这条折线代表的是测试误差，度量模型对于未知数据的预测能力。蓝色的折线代表的是训练误差，度量模型对已知数据的预测能力。")]),t._v(" "),a("p",[t._v("选择模型的时候，一定要注意：防止过拟合的现象出现。即遵循奥卡姆剃刀原理，选择的模型既要有良好的拟合效果，复杂度又适当，或者说选择使训练误差和测试误差同时达到比较小的模型。")]),t._v(" "),a("h2",{attrs:{id:"_5-正则化与交叉验证"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-正则化与交叉验证"}},[t._v("#")]),t._v(" 5. 正则化与交叉验证")]),t._v(" "),a("h3",{attrs:{id:"_5-1-regularization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-regularization"}},[t._v("#")]),t._v(" 5.1 Regularization")]),t._v(" "),a("h4",{attrs:{id:"_5-1-1-正则化项"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-1-正则化项"}},[t._v("#")]),t._v(" 5.1.1 正则化项")]),t._v(" "),a("p",[t._v("追溯到模型结构上，过拟合往往由于模型结构太过复杂而导致，欠拟合则是由于模型结构太简单。")]),t._v(" "),a("p",[t._v("为了平衡模型的对已知数据和未知数据的预测能力，我们在原来的经验风险上加上了"),a("strong",[t._v("正则化项")]),t._v("，以此度量模型复杂度。"),a("strong",[t._v("经验风险与正则化项一起构成结构风险函数")]),t._v("。")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727164034447.png",alt:"image-20220727164034447"}})]),t._v(" "),a("p",[a("mark",[t._v("正则化")]),t._v("，就是通过使结构风险最小化来实现的。在正则化的一般形式中，目标函数为结构风险。其中**，第一部分是经验风险**，用以度量模型在训练集中的平均损失，"),a("strong",[t._v("第二部分被称为正则化项或惩罚项")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"J"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 度量模型的复杂度")],1),t._v("，一般模型参数越多，模型越复杂，"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"J"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 就越大。")],1),t._v(" "),a("li",[a("strong",[t._v("系数 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"3BB"}})],1)],1)],1),t._v(" 用以调整经验风险和模型复杂度之间的关系")],1),t._v("。 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"3BB"}})],1)],1)],1),t._v(" 越大，模型选择时越重视泛化能力，选出来最优模型参数越少；与之相对地，系数越小，越重视拟合能力，选出来的最优模型可能会出现过拟合。")],1)]),t._v(" "),a("blockquote",[a("p",[t._v("这是因为，如果 λ 很大，J(f) 的微小变化都能引发结构风险的一个很大的变化，那么，通过正则化就会压缩模型复杂度，则会避免过拟合的现象出现。但是，如果 λ 非常小，J(f) 的巨大变化才能引发结构风险的一个很小的变化，那么，此时通过正则化就无法降低模型复杂度了。因此，系数 λ 的选择是个关键。")])]),t._v(" "),a("p",[t._v("我们的目的是选择拟合能力和泛化能力都很强的模型。")]),t._v(" "),a("h4",{attrs:{id:"_5-1-2-l1-与-l2-范数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-2-l1-与-l2-范数"}},[t._v("#")]),t._v(" 5.1.2 L1 与 L2 范数")]),t._v(" "),a("p",[t._v("正则化项有很多种形式，最常见的就是 L1 与 L2 范数：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727164609905.png",alt:"image-20220727164609905"}})]),t._v(" "),a("p",[a("mark",[t._v("L1 范数")]),t._v("即参数绝对值之和，更适用于特征筛选。它倾向于选择出一个稀疏的模型。稀疏模型指的是非零参数个数很少的模型。")]),t._v(" "),a("p",[a("mark",[t._v("L2 范数")]),t._v("即参数的平方和，主要用以防止过拟合现象的出现。L2 正则化项的构成，使得在正则化的时候，参数可以无限的接近于 0，但是与 L1 范数不同，这里参数只是接近于 0，很难出现直接等于 0 的情况。所以，这一类正则化项可以使得模型越来越简单，防止过拟合现象的出现，但无法起到特征筛选的作用。")]),t._v(" "),a("blockquote",[a("p",[t._v("再说一下，为什么 L2 范数这里有一个 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mfrac",[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1)],1)],1)],1)],1)],1)],1),t._v("？这主要是出于数学运算的方便。求极值时，如果使用求导的方法，那么 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mfrac",[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1)],1)],1)],1)],1)],1)],1),t._v(" 恰好可以约去。")],1)]),t._v(" "),a("p",[t._v("正则化，就用来选择经验风险和模型复杂度同时都很小的模型。这种思想非常符合奥卡姆剃刀原理。")]),t._v(" "),a("div",{staticClass:"custom-block note"},[a("p",{staticClass:"custom-block-title"},[t._v("奥卡姆剃刀原理")]),t._v(" "),a("p",[t._v("在模型选择时，选择所有可能模型中，能很好解释已知数据并且十分简单的模型。")])]),t._v(" "),a("h3",{attrs:{id:"_5-2-cross-validation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-cross-validation"}},[t._v("#")]),t._v(" 5.2 Cross Validation")]),t._v(" "),a("p",[t._v("在样本的数据量足够充足的情况下，通常可以将数据集随机地"),a("strong",[t._v("分为训练集、验证集和测试集")]),t._v("三部分：")]),t._v(" "),a("ul",[a("li",[t._v("Training Set：用于训练模型")]),t._v(" "),a("li",[t._v("Validation Set：用于选择模型")]),t._v(" "),a("li",[t._v("Test Set：用于最终对学习方法的评估")])]),t._v(" "),a("p",[t._v("通常，我们假设验证集中有足够多的数据，这样，通过 training set 所得到的模型放入 validation set 里，选择预测误差最小的那个模型，就是最优模型了。")]),t._v(" "),a("p",[t._v("但现实情况中，样本数据通常是不充足的。那么，为了选择一个好的模型，可以采用交叉验证的方法。"),a("strong",[t._v("交叉验证的基本思想就是：重复使用数据，以解决数据不足的这种问题")]),t._v("。")]),t._v(" "),a("p",[t._v("这里我们介绍三种交叉验证法，简单交叉验证，S折交叉验证，还有留一交叉验证：")]),t._v(" "),a("h4",{attrs:{id:"_5-2-1-简单交叉验证"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-1-简单交叉验证"}},[t._v("#")]),t._v(" 5.2.1 简单交叉验证")]),t._v(" "),a("p",[a("mark",[t._v("简单交叉验证法")]),t._v("是将数据集随机的分为两个部分，一个作为训练集，一个作为测试集。")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727194443900.png",alt:"image-20220727194443900"}})]),t._v(" "),a("p",[t._v("举个例子，假如我们将样本的 70% 作为训练集，30% 作为测试集，那么在不同的情况下，可以通过训练集得到不同的学习模型，将学习训练得到的不同模型放到测试集上，计算测试误差，测试误差最小的模型则是最优模型。")]),t._v(" "),a("h4",{attrs:{id:"_5-2-2-s-折交叉验证"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-2-s-折交叉验证"}},[t._v("#")]),t._v(" 5.2.2 S 折交叉验证")]),t._v(" "),a("p",[a("mark",[t._v("S 折交叉验证")]),t._v("，随机将数据分为 S 个互不相交、大小相同的子集，其中以 S-1 个子集作为训练集，余下的子集作为测试集。")]),t._v(" "),a("p",[t._v("下面通过一个例子来说明。假如 S=10，我们可以将数据集均匀的分为 T1，T2，......  T10 这十个子集，那么可以将其中九个子集的并集作为训练集，剩余的那个子集作为测试集：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727195047677.png",alt:"image-20220727195047677"}})]),t._v(" "),a("p",[t._v("比如将 T1-T9 的并集作为训练集，用于训练模型，所得模型记做 M1。通过类似的方法，我们还可以得到模型 M2，M3，...... M10。分别在每个模型相应的测试集中计算测试误差，并进行比较，测试误差最小的模型，就是最优模型。")]),t._v(" "),a("h4",{attrs:{id:"_5-2-3-留一交叉验证"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-3-留一交叉验证"}},[t._v("#")]),t._v(" 5.2.3 留一交叉验证")]),t._v(" "),a("p",[a("mark",[t._v("留一交叉验证")]),t._v("，可以认为是S折交叉验证的特殊情况，即 S=N 的情况，这里的 N 指的是数据集的样本容量。留一交叉验证，leave-one-out cross validation，也就是每次用N-1个样本训练模型，余下的那个样本测试模型。这是在数据非常缺乏的情况下才使用的方法。")]),t._v(" "),a("h2",{attrs:{id:"_6-泛化能力"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-泛化能力"}},[t._v("#")]),t._v(" 6. 泛化能力")]),t._v(" "),a("p",[t._v("泛化能力，指的是通过某一学习方法训练所得模型，对未知数据的预测能力。")]),t._v(" "),a("p",[t._v("通常，测试数据集用以评价训练所得模型的泛化能力。由于测试数据集包含的样本有限，仅仅通过测试数据集去评价泛化能力，有时并不可靠，此时需要我们从理论出发，对模型的泛化能力进行评价。")]),t._v(" "),a("h3",{attrs:{id:"_6-1-泛化误差"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-泛化误差"}},[t._v("#")]),t._v(" 6.1 泛化误差")]),t._v(" "),a("p",[t._v("在介绍泛化误差之前，回顾一下之前学过的测试误差。测试误差是通过测试数据集计算得到的："),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"s"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-msup",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.067em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1)],1)],1)],1)],1)],1)],1),a("mjx-munderover",{attrs:{space:"2",limits:"false"}},[a("mjx-mo",{staticClass:"mjx-sop"},[a("mjx-c",{attrs:{c:"2211"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.067em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1)],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.291em"}}),a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.254em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-TeXAtom",{attrs:{space:"2"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.254em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("。")],1),t._v(" "),a("p",[t._v("而"),a("mark",[t._v("泛化误差")]),t._v("（"),a("strong",[t._v("Generalization Error")]),t._v("）是基于整个样本空间的：")]),t._v(" "),a("p"),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-TeXAtom",[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-msub",{attrs:{space:"4"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"E"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"P"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"["}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-TeXAtom",{attrs:{space:"2"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"]"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-msub",{attrs:{space:"4"}},[a("mjx-mo",{staticClass:"mjx-lop",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"222B"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.896em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"X"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"D7"}})],1),a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"Y"}})],1)],1)],1)],1)],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-TeXAtom",{attrs:{space:"2"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"d"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"d"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"y"}})],1)],1)],1)],1),a("p"),t._v(" "),a("p",[t._v("所以"),a("strong",[t._v("泛化误差是度量对未知数据预测能力的理论值，测试误差则是经验值")]),t._v("。")]),t._v(" "),a("p",[t._v("如果通过学习系统，得到两个模型，两个模型的对已知数据的预测能力相近，那么哪一个模型的泛化误差小就选择哪个。")]),t._v(" "),a("h3",{attrs:{id:"_6-2-泛化误差上界"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-泛化误差上界"}},[t._v("#")]),t._v(" 6.2 泛化误差上界")]),t._v(" "),a("p",[a("mark",[t._v("泛化误差上界")]),t._v("（"),a("strong",[t._v("Generalization Error Bound")]),t._v("）对应的是泛化误差的概率上界。在理论上比较两种学习方法所得模型的优劣时，可通过比较两者的泛化误差上界来进行。")]),t._v(" "),a("p",[t._v("关于泛化误差上界具有两条性质：")]),t._v(" "),a("ul",[a("li",[t._v("它是样本容量的函数：当样本容量 N 增加时，泛化误差上界趋于 0")]),t._v(" "),a("li",[t._v("它是假设空间容量的函数：假设空间容量越大，模型就越难学，泛化误差上界就越大")])]),t._v(" "),a("blockquote",[a("p",[t._v("第一条性质，可以从泛化误差的概念出发辅助理解。泛化误差定义为一个期望值，那么经验表达就是以全样本空间作为测试集，计算所得的测试误差，它表示为一个平均值。在平均值中，样本量位于分母的位置，那么随着样本量的增加，平均值则趋于零。")]),t._v(" "),a("p",[t._v("第二条性质，泛化误差上界是假设空间容量的函数，不同的模型，对应不同的泛化误差上界。假设空间是所有可能的模型的集合，那么假设空间容量越大，所有可能的模型类型就会越多，模型也就愈加难以学习，与之对应的泛化误差上界就会越大。")])]),t._v(" "),a("p",[t._v("单纯的理解这两条性质，可能会比较难，下面我们通过一个关于二分类问题的例子来说明。")]),t._v(" "),a("h4",{attrs:{id:"_6-2-1-以二分类问题为例解释泛化误差上界"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-1-以二分类问题为例解释泛化误差上界"}},[t._v("#")]),t._v(" 6.2.1 以二分类问题为例解释泛化误差上界")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727205642024.png",alt:"image-20220727205642024"}})]),t._v(" "),a("p",[t._v("由于是一个二分类问题，我们不妨假设输出空间中包含两个元素，正类记作+1，负类记作-1。f 为假设空间中的一个函数。对于二分类问题，损失函数采用一般采用0-1损失，那么关于 f 的风险函数就可以表示出来：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727205726022.png",alt:"image-20220727205726022"}})]),t._v(" "),a("p",[a("strong",[t._v("期望风险")]),t._v("是函数 f 的损失函数 L 的期望。经验风险则是训练集中样本损失的平均值。训练模型可以通过经验风险最小化的策略来实现。选出经验风险最小的模型，那么该模型的泛化能力可以表示为该模型对应的期望风险。")]),t._v(" "),a("p",[t._v("下面讨论从有限集合 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"F"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"{"}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"22EF"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"d"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"}"}})],1)],1)],1),t._v(" 中任意选出的函数 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1),t._v(" 的泛化误差上界：")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727210512360.png",alt:"image-20220727210512360"}})]),t._v(" "),a("ul",[a("li",[t._v("不等式的左边 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 是泛化误差，右边是泛化误差上界。")],1),t._v(" "),a("li",[t._v("右边第一项代表的是训练误差，而第二项是与假设空间的容量 d，样本个数 N，以及 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"3B4"}})],1)],1)],1),t._v(" 有关的量。")],1),t._v(" "),a("li",[t._v("不等式右边第一项，训练误差是一个平均值，分子为训练样本损失之和，分母为 N，在 N 趋于无穷大时，训练误差趋于零。")]),t._v(" "),a("li",[t._v("再看不等式右边第二项，从具体的表达式可以看出，如果 N 趋于无穷大，它明显趋于 0。这说明，随着样本量的增加，泛化误差上界趋于 0，这也验证了之前所讲的第一条性质。继续观察它，可以看出它是 d 的增函数，即随着 d 的增大，泛化误差上界也会增大。而 d 的增大，就代表着假设空间越来越复杂。这验证了之前所讲的第二条性质。")])]),t._v(" "),a("p",[t._v("证明过程暂略。")]),t._v(" "),a("h3",{attrs:{id:"_6-3-损失函数、风险函数、泛化误差傻傻分不清怎么办"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-3-损失函数、风险函数、泛化误差傻傻分不清怎么办"}},[t._v("#")]),t._v(" 6.3 损失函数、风险函数、泛化误差傻傻分不清怎么办？")]),t._v(" "),a("p",[t._v("损失函数、风险函数、经验风险、训练误差、测试误差、泛化误差，是大家很容易混淆的几个概念。这一节将专门进行辨析。")]),t._v(" "),a("h4",{attrs:{id:"_6-3-1-foundation-损失函数、风险函数、经验风险"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-3-1-foundation-损失函数、风险函数、经验风险"}},[t._v("#")]),t._v(" 6.3.1 Foundation：损失函数、风险函数、经验风险")]),t._v(" "),a("p",[t._v("对模型而言，如何定义这个模型做一次预测的好坏呢？"),a("strong",[t._v("损失函数")]),t._v("！对于一个模型而言，一个样本点，就可以计算出一个损失来，而计算这个损失，用的就是损失函数。")]),t._v(" "),a("p",[t._v("一个点或几个样本点的损失，那只是一个小局部的损失情况，如果我们想知道某模型在数据总体上的损失，怎么办呢？"),a("strong",[t._v("风险函数")]),t._v("！风险函数是损失函数在样本空间的概率期望，所以又名期望损失。因为不同样本点的概率可能不同，那么不同样本点带来的损失也可能不一样，风险函数就相当于样本空间中所有样本点带来的损失的加权平均。即，风险函数表示的是总体的平均损失。")]),t._v(" "),a("p",[t._v("但是用以计算风险函数的概率分布很难获悉，这是因为我们不知道上帝创造这个世界到底用的是什么模型，那么从我们人类来看，这时候如何得到平均损失呢？"),a("strong",[t._v("经验风险")]),t._v("！总体分布无法得到，我们可以用样本来推断呀。所以风险函数就相当于一个总体平均损失的理论值，经验风险就是样本平均损失，作为风险函数的经验值而出现的。")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}}),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("不指定特定的模型")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("损失函数")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("计算"),a("strong",[t._v("一个")]),t._v("样本点的损失")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("风险函数")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("计算总体的"),a("strong",[t._v("平均")]),t._v("损失")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("经验风险")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("计算样本的"),a("strong",[t._v("平均")]),t._v("损失")])])])]),t._v(" "),a("p",[t._v("这三个都是一般性的概念，并不是对应于某个特定模型的，可以用以制定学习方法的策略，进而在学习系统中训练模型。下面分别从拟合能力和泛化能力来讲解本文开始提到的训练误差、测试误差等，这些都是对应于训练出来的某一特定模型而言的。")]),t._v(" "),a("h4",{attrs:{id:"_6-3-2-拟合能力-fitting-ability"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-3-2-拟合能力-fitting-ability"}},[t._v("#")]),t._v(" 6.3.2 拟合能力（Fitting Ability）")]),t._v(" "),a("p",[a("strong",[t._v("拟合能力")]),t._v("（Fitting Ability）指的是以训练出来的某模型"),a("strong",[t._v("对已知数据")]),t._v("的预测能力。可以用拟合误差来度量，即已知数据的平均损失。")]),t._v(" "),a("p",[t._v("如果我们拥有总体数据，根据总体或许就能揭晓上帝创造世界的秘密了。这时候构建模型，自然是拟合地越接近越好，越接近就越靠近真相。那么怎么来度量接近程度呢？理论上其实就是通过风险函数，实际操作则用的经验风险。经验风险越小越好。这时候也就无所谓过拟合了，因为总体都是已知的了，不存在未知数据。")]),t._v(" "),a("p",[t._v("当然，之前所讲的是一种极端情况。“总体”显然是难以获得，可以得到的一般是“样本”。假如这时候我们把训练数据集作为已知数据看待，平均损失的经验值就被称为训练误差。")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}}),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("对已训练所得模型而言")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("拟合能力")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("对"),a("strong",[t._v("已知数据")]),t._v("的预测能力")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("拟合误差")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("度量拟合能力的"),a("strong",[t._v("理论值")]),t._v("，是所有"),a("strong",[t._v("已知")]),t._v("数据的平均损失")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("训练误差")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("度量拟合能力的"),a("strong",[t._v("经验值")]),t._v("，"),a("strong",[t._v("训练数据集")]),t._v("的平均损失")])])])]),t._v(" "),a("h4",{attrs:{id:"_6-3-3-泛化能力-generalization-ability"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-3-3-泛化能力-generalization-ability"}},[t._v("#")]),t._v(" 6.3.3 泛化能力（Generalization Ability）")]),t._v(" "),a("p",[a("strong",[t._v("泛化能力")]),t._v("（Generalization Ability）指的是训练出来的某模型对未知数据的预测能力。可以用泛化误差来度量，即未知数据的平均损失。")]),t._v(" "),a("p",[t._v("假如现在总体数据都是未知数据，那我们对于整个样本空间计算的平均损失，就是泛化误差。这反映模型的对总体数据的广泛适应能力，往往模型越简单越容易适应全部数据，这时候也无所谓欠拟合问题了，因为不存在已知数据呀。")]),t._v(" "),a("p",[t._v("从极端情况回到实际中，我们一般是把收集到的样本分出一部分来，将测试数据集看成未知数据，对其计算平均损失，就得到测试误差，可以认为是泛化误差的经验值。")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}}),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("对已训练所得模型而言")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("泛化能力")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("对"),a("strong",[t._v("未知数据")]),t._v("的预测能力")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("泛化误差")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("度量泛化能力的"),a("strong",[t._v("理论值")]),t._v("，是所有"),a("strong",[t._v("未知")]),t._v("数据的平均损失")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("测试误差")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("度量泛化能力的"),a("strong",[t._v("经验值")]),t._v("，"),a("strong",[t._v("测试数据集")]),t._v("的平均损失")])])])]),t._v(" "),a("p",[t._v("最后要强调的是，拟合能力和泛化能力不能分开来看，因为模型既需要对已知数据有一个好的拟合效果，也需要具有对未知数据有较强的适应能力，所以"),a("u",[t._v("两者都很重要，需要找到一个平衡点")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"_7-生成模型与判别模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-生成模型与判别模型"}},[t._v("#")]),t._v(" 7. 生成模型与判别模型")]),t._v(" "),a("p",[t._v("通过训练集学习出一个模型，这个模型一般有两种形式：条件概率的形式和决策函数的形式。通过学习获得模型的方法，又可以分为生成方法和判别方法，与之相对应的模型则是生成模型和判别模型。")]),t._v(" "),a("h3",{attrs:{id:"_7-1-生成模型-generative-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-1-生成模型-generative-model"}},[t._v("#")]),t._v(" 7.1 生成模型（Generative Model）")]),t._v(" "),a("div",{staticClass:"custom-block theorem"},[a("p",{staticClass:"title"},[t._v("生成模型")]),a("p",[t._v("由数据学习联合分布概率 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，然后求出 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 作为预测模型，即"),a("mark",[t._v("生成模型")]),t._v("（Generative Model）：\n")],1),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",{attrs:{type:"d"}},[a("mjx-num",[a("mjx-nstrut",{attrs:{type:"d"}}),a("mjx-mrow",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line",{attrs:{type:"d"}}),a("mjx-row",[a("mjx-den",[a("mjx-dstrut",{attrs:{type:"d"}}),a("mjx-mrow",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),a("p")]),a("p",[t._v("这里，需要理解的就是条件概率分布，它等于联合概率分布函数与边际分布的比。")]),t._v(" "),a("p",[t._v("之所以称为生成模型，是因为每给定一个输入变量 X，就可以根据分布函数生成一个输出变量 Y。需要注意的是，生成模型中的输入变量和输出变量，都为随机变量。典型的生成模型有朴素贝叶斯法和隐马可夫模型。")]),t._v(" "),a("h3",{attrs:{id:"_7-2-判别模型-discriminative-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-2-判别模型-discriminative-model"}},[t._v("#")]),t._v(" 7.2 判别模型（Discriminative Model）")]),t._v(" "),a("div",{staticClass:"custom-block theorem"},[a("p",{staticClass:"title"},[t._v("判别模型")]),a("p",[t._v("由数据直接学习决策函数 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 或者条件概率分布 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"Y"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"|"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 作为预测模型，即"),a("mark",[t._v("判别模型")]),t._v("（Discriminative Model）。")],1)]),a("p",[t._v("判别模型，与生成模型不同，可以通过数据直接学习得到决策函数，不需要考虑 X 和 Y 的联合分布。所以说，判别方法是有针对性的，研究的是对于特定的输入，应该预测得到一个什么样的输出。")]),t._v(" "),a("p",[t._v("对于判别模型，并不要求输入变量和输出变量均为随机变量。典型的判别模型有 k 近邻法、感知机和决策树。")]),t._v(" "),a("h3",{attrs:{id:"_7-3-generative-v-s-discriminative"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-3-generative-v-s-discriminative"}},[t._v("#")]),t._v(" 7.3 Generative v.s. Discriminative")]),t._v(" "),a("p",[t._v("本节我们详细对比一下生成模型和判定模型。")]),t._v(" "),a("h4",{attrs:{id:"_7-3-1-从一个小例子来看"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-3-1-从一个小例子来看"}},[t._v("#")]),t._v(" 7.3.1 从一个小例子来看")]),t._v(" "),a("p",[t._v("先看一个比较形象的小例子，假如现在的目标是对图中的小狗，还有大象进行分类：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727221446876.png",alt:"image-20220727221446876"}})]),t._v(" "),a("p",[t._v("两种动物之间存在很明显的一个差异，即鼻子的长度，小狗的鼻子比较短，而大象的鼻子很长。那么，判别方法就可以通过动物鼻子长短来决定它的类别。如果出现一个新的图像，我们只需要判断新图像中动物鼻子的长度就可以了。给定某个阈值，如果长度大于该阈值，就判断这个动物为大象，否则就判定为小狗。")]),t._v(" "),a("p",[t._v("如果采用生成方法，则需要分别构建小狗和大象的特征模型，这里不只包含鼻子，还有耳朵、嘴巴、眼睛、四肢等等。当出现一个新图像的时候，我们将新图像中的动物，分别与小狗，还有大象的特征模型进行比较。如果该动物与小狗的相似度更高，则判断为小狗，否则判断为大象。当然，构建具体的特征模型，需要大量数据。")]),t._v(" "),a("p",[t._v("简单来讲，生成模型，希望从大量的数据中寻找规律，通过学习知晓数据是如何生成的，然后再对数据进行分类，而判别模型侧重点只在于利用这个差别去分类就可以了，十分具有针对性。")]),t._v(" "),a("h4",{attrs:{id:"_7-3-2-具体来看"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-3-2-具体来看"}},[t._v("#")]),t._v(" 7.3.2 具体来看")]),t._v(" "),a("p",[t._v("接下来，看一下生成模型与判别模型之间的"),a("strong",[t._v("具体差异")]),t._v("：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727221711131.png",alt:"image-20220727221711131"}})]),t._v(" "),a("p",[a("u",[t._v("从样本量上来比较")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("生成模型所需要的数据量较大，因为只有在大数据量的情况下，才能够更好地估计联合概率分布，也就是所有变量的一个全概率模型；")]),t._v(" "),a("li",[t._v("判别模型是针对性地学习，只需要得到条件概率分布或者决策函数即可，所以不需要像生成模型的那样必须配备足够多的样本，因此判别模型所需的样本量要少于生成模型。")])]),t._v(" "),a("p",[a("u",[t._v("从目的来比较")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("生成模型可以还原联合概率分布，借此可以计算出边际分布和条件概率分布，所以可以提供更多的信息；")]),t._v(" "),a("li",[t._v("判别模型的目的就是预测，所以准确率往往比生成模型会更高一些。")])]),t._v(" "),a("p",[a("u",[t._v("从过程来比较")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("对生成模型而言，样本容量越多，学习到的模型就能够更快地收敛到真实模型上，所以生成模型的收敛速度较之判别模型更快；")]),t._v(" "),a("li",[t._v("判别模型是直接学习的过程，所以不需要面面俱到，因此可以简化学习问题。")])]),t._v(" "),a("p",[a("u",[t._v("从反映数据特征来比较")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("生成模型学习到的模型更接近于真实模型，所以能够反映同类数据本身的相似度；")]),t._v(" "),a("li",[t._v("判别模型并不考虑数据的各项特征，所以并不能像生成模型那样反映数据本身的特性。")])]),t._v(" "),a("p",[t._v("最后一条是关于隐变量的，生成模型可以很好地应对具有隐变量的情况，比如混合高斯模型。")]),t._v(" "),a("h2",{attrs:{id:"_8-监督学习的应用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-监督学习的应用"}},[t._v("#")]),t._v(" 8. 监督学习的应用")]),t._v(" "),a("p",[t._v("这一篇我们主要从分类问题、标注问题和回归问题这三方面来讲解监督学习的应用。")]),t._v(" "),a("p",[t._v("根据输入和输出数据的不同类型，可以对监督学习进行一个简单分类：")]),t._v(" "),a("ul",[a("li",[t._v("分类问题：输出变量为有限个离散变量")]),t._v(" "),a("li",[t._v("标注问题：输入和输出变量均为变量序列")]),t._v(" "),a("li",[t._v("回归问题：输入和输出变量为连续变量")])]),t._v(" "),a("h3",{attrs:{id:"_8-1-分类问题-classification"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-1-分类问题-classification"}},[t._v("#")]),t._v(" 8.1 分类问题（Classification）")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220727224148260.png",alt:"image-20220727224148260"}})]),t._v(" "),a("p",[t._v("学习到的分类模型或者分类决策函数，称为分类器，相应的预测系统称为分类系统，预测所得到的输出称为类别。有多个类别的时候，是多分类问题。为简单起见，我们以二分类问题为主进行讲解。")]),t._v(" "),a("div",{staticClass:"custom-block theorem"},[a("p",{staticClass:"title"},[t._v("分类准确率")]),a("p",[t._v("对于给定的测试数据集，分类器正确分类的样本数与总样本数之比称为分类准确率：\n")]),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"r"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"r"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"s"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",{attrs:{type:"d"}},[a("mjx-num",[a("mjx-nstrut",{attrs:{type:"d"}}),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line",{attrs:{type:"d"}}),a("mjx-row",[a("mjx-den",[a("mjx-dstrut",{attrs:{type:"d"}}),a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.067em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1)],1)],1)],1)],1)],1)],1),a("mjx-munderover",{attrs:{space:"2"}},[a("mjx-over",{staticStyle:{"padding-bottom":"0.2em","padding-left":"0.298em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.067em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1)],1)],1),a("mjx-box",[a("mjx-munder",[a("mjx-row",[a("mjx-base",[a("mjx-mo",{staticClass:"mjx-lop"},[a("mjx-c",{attrs:{c:"2211"}})],1)],1)],1),a("mjx-row",[a("mjx-under",{staticStyle:{"padding-top":"0.167em","padding-left":"0.062em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1)],1)],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"I"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"y"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.247em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.223em"}}),a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-TeXAtom",{attrs:{space:"4"}},[a("mjx-mover",[a("mjx-over",{staticStyle:{"padding-bottom":"0.06em","padding-left":"0.237em","margin-bottom":"-0.531em"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"^"}})],1)],1),a("mjx-base",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.247em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.223em"}}),a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),a("p")]),a("p",[t._v("准确率代表在测试集中正确分类的样本占比，这是一个一般的分类器评价指标。")]),t._v(" "),a("p",[t._v("此外，还有将精确率和召回率作为二分类问题的评价指标：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("精确率")]),t._v("：表示预测为正类的样本中有多少样本真正属于正类，这是针对预测结果而言的一个指标，"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mrow",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1)],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-mrow",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"F"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),t._v(" "),a("li",[a("strong",[t._v("召回率")]),t._v("：表示正类样本有多少被正确预测了，这是针对样本本身而言的一个指标，"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"R"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",[a("mjx-num",[a("mjx-nstrut"),a("mjx-mrow",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1)],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line"),a("mjx-row",[a("mjx-den",[a("mjx-dstrut"),a("mjx-mrow",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"F"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"N"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)]),t._v(" "),a("p",[t._v("对于二分类问题，当然希望精确率和召回率越高越好。随之而来，就有了一个综合指标——"),a("strong",[t._v("调和值")]),t._v("：")]),t._v(" "),a("p"),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-mfrac",[a("mjx-frac",{attrs:{type:"d"}},[a("mjx-num",[a("mjx-nstrut",{attrs:{type:"d"}}),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"2"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line",{attrs:{type:"d"}}),a("mjx-row",[a("mjx-den",[a("mjx-dstrut",{attrs:{type:"d"}}),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"F"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1)],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mfrac",{attrs:{space:"4"}},[a("mjx-frac",{attrs:{type:"d"}},[a("mjx-num",[a("mjx-nstrut",{attrs:{type:"d"}}),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line",{attrs:{type:"d"}}),a("mjx-row",[a("mjx-den",[a("mjx-dstrut",{attrs:{type:"d"}}),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"P"}})],1)],1)],1)],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mfrac",{attrs:{space:"3"}},[a("mjx-frac",{attrs:{type:"d"}},[a("mjx-num",[a("mjx-nstrut",{attrs:{type:"d"}}),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line",{attrs:{type:"d"}}),a("mjx-row",[a("mjx-den",[a("mjx-dstrut",{attrs:{type:"d"}}),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"R"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),a("p"),t._v(" "),a("p",[t._v("当精确率与召回率都很高的时候，调和值就会很高。")]),t._v(" "),a("p",[t._v("下面给大家列出几种常见的分类方法和分类的应用领域：")]),t._v(" "),a("img",{staticStyle:{zoom:"72%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220728082851309.png",alt:"image-20220728082851309"}}),t._v(" "),a("h3",{attrs:{id:"_8-2-标注问题-tagging"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-2-标注问题-tagging"}},[t._v("#")]),t._v(" 8.2 标注问题（Tagging）")]),t._v(" "),a("p",[t._v("标注问题，可以认为是分类问题的一个推广，不过更加复杂一些，所以将其单列出来讲解。")]),t._v(" "),a("p",[t._v("标注问题要求输入和输出变量均为变量序列，而且序列的长度相同，即输入一个维度为 n 的观察的序列，那么相应的要输出一个维度为 n 的标记序列。")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220728083155597.png",alt:"image-20220728083155597"}})]),t._v(" "),a("p",[t._v("当然，不同的样本可以有不同的长度，也就是说某一个样本的输入和输出维度都为 n，另一个样本的输入和输出为 m，m 可以与 n 相同也可以不同。")]),t._v(" "),a("p",[t._v("标注问题的评价指标与分类问题一样，即准确率、精确率和召回率。")]),t._v(" "),a("p",[t._v("下面给大家列出几种常见的标注方法和应用领域：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220728083307660.png",alt:"image-20220728083307660"}})]),t._v(" "),a("p",[t._v("举个例子，从文章中抽取基本名词短语。比如 Microsoft research，然后对其进行标注：")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220728083432160.png",alt:"image-20220728083432160"}})]),t._v(" "),a("p",[t._v("这个句子包含了 22 个单词，那么输入观测序列长度就为 22。现在对每个单词进行标记，这个单词为一个基本短语：")]),t._v(" "),a("ul",[a("li",[t._v("如果代表开始，标为 B（Begin）；")]),t._v(" "),a("li",[t._v("如果代表结束，标为 E（End）；")]),t._v(" "),a("li",[t._v("如果既不是表示开始也不是表示结束，标为 O（Others）。")])]),t._v(" "),a("p",[t._v("标为色的那些，就是输出的部分，也是长度为22的序列，和输入的序列长度一致。")]),t._v(" "),a("h3",{attrs:{id:"_8-3-回归问题-regression"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-3-回归问题-regression"}},[t._v("#")]),t._v(" 8.3 回归问题（Regression）")]),t._v(" "),a("p",[t._v("回归问题，是监督学习中非常重要的一部分，反映输入和输出变量之间的映射关系。所以，相应的学习过程就等价于进行一个函数拟合。具体的流程和之前类似。")]),t._v(" "),a("ul",[a("li",[t._v("按照输入的变量的个数分类：一元回归（只有一个变量）、多元回归（有多个变量）")]),t._v(" "),a("li",[t._v("按照输入和输出变量之间的关系分类：线性回归、非线性回归")])]),t._v(" "),a("p",[t._v("回归模型中，损失函数一般采用平方损失，而求解损失函数最常用的则是最小二乘法（OLS）。")]),t._v(" "),a("p",[t._v("回归问题可以应用在商务领域。举一个例子，比如在股票预测问题中，我们可以通过某公司历史数据中进行股价的预测，股票价格作为因变量，而该公司其他的数据。比如营业额，基本资产，董事会决策等作为自变量，构建回归模型，进行模型学习，然后通过训练所得模型预测一个未来股票价格。")])],1)}),[],!1,null,null,null);s.default=c.exports}}]);