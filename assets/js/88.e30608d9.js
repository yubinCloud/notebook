(window.webpackJsonp=window.webpackJsonp||[]).push([[88],{841:function(t,e,a){"use strict";a.r(e);var i=a(22),s=Object(i.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"_1-background-pre-trained-language-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-background-pre-trained-language-models"}},[t._v("#")]),t._v(" 1. Background: Pre-trained Language Models")]),t._v(" "),a("h3",{attrs:{id:"_1-1-ä»€ä¹ˆæ˜¯-language-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-ä»€ä¹ˆæ˜¯-language-model"}},[t._v("#")]),t._v(" 1.1 ä»€ä¹ˆæ˜¯ Language Modelï¼Ÿ")]),t._v(" "),a("p",[a("mark",[t._v("Neural Language Models")]),t._v(": A neural network that defines the probability over sequences of words.")]),t._v(" "),a("img",{staticStyle:{zoom:"90%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029210149304.png",alt:"image-20221029210149304"}}),t._v(" "),a("h3",{attrs:{id:"_1-2-æ€æ ·è®­ç»ƒçš„è¿™äº›-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-æ€æ ·è®­ç»ƒçš„è¿™äº›-model"}},[t._v("#")]),t._v(" 1.2 æ€æ ·è®­ç»ƒçš„è¿™äº› modelï¼Ÿ")]),t._v(" "),a("p",[t._v("Given an incomplete sentence, predict the rest of the sentence.")]),t._v(" "),a("img",{staticStyle:{zoom:"90%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029210325093.png",alt:"image-20221029210325093"}}),t._v(" "),a("p",[t._v("ä¸å®Œæ•´çš„å¥å­æ€ä¹ˆæ„é€ å‘¢ï¼Ÿæ ¹æ®ä¸å®Œæ•´çš„å¥å­çš„æ„é€ æ–¹å¼ï¼Œå¯ä»¥å°† Language Model çš„è®­ç»ƒåˆ†æˆä¸¤ç§ï¼š")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Autoregressive Language Model")]),t._v("ï¼ˆ"),a("mark",[t._v("ALMs")]),t._v("ï¼‰: Complete the sentence given its prefix.")])]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029210716452.png",alt:"image-20221029210716452"}}),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029210806588.png",alt:"image-20221029210806588"}}),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029210806588.png",alt:"image-20221029210806588"}}),t._v(" "),a("p",[t._v("æˆ‘ä»¬çœ‹ä¸€ä¸‹ Transformer-based PLM é•¿ä»€ä¹ˆæ ·å­ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"90%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029211126556.png",alt:"image-20221029211126556"}})]),t._v(" "),a("p",[t._v("ä¸Šå›¾ä¸­ï¼Œâ€œæ°”â€è¿™ä¸ªå­—ç»è¿‡ä¸€ç³»åˆ— layerï¼Œå¾—åˆ°äº†å®ƒçš„ embeddingï¼Œç„¶åæŠŠè¿™ä¸ª embedding è¾“å…¥åˆ°ä¸€ä¸ª LM Head ä¸­ï¼Œå¯ä»¥å¾—åˆ°é¢„æµ‹ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡ã€‚")]),t._v(" "),a("p",[t._v("è®­ç»ƒä¸€ä¸ª Language Model çš„æ–¹å¼å°±æ˜¯ self-supervised learningï¼Œä½†å®ƒæ²¡æœ‰ä¸€ä¸ªæ˜ç¡®çš„å®šä¹‰ï¼Œè¿™é‡Œæˆ‘ä»¬è¯´ï¼š")]),t._v(" "),a("p",[a("mark",[t._v("Self-supervised learning")]),t._v(": Predicting any part of the input from any other part.")]),t._v(" "),a("p",[t._v("è¿˜å­˜åœ¨å¦å¤–ä¸€ç§ Language Modelï¼Œå³ Masked Language Modelsï¼ˆMLMsï¼‰ï¼š")]),t._v(" "),a("p",[a("strong",[t._v("Masked Language Models")]),t._v("ï¼ˆ"),a("mark",[t._v("MLMs")]),t._v("ï¼‰: Use the unmarked words to predict the masked word.")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029211842262.png",alt:"image-20221029211842262"}}),t._v(" "),a("h3",{attrs:{id:"_1-3-pre-trained-language-models-plms"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-pre-trained-language-models-plms"}},[t._v("#")]),t._v(" 1.3 Pre-trained Language Modelsï¼ˆPLMsï¼‰")]),t._v(" "),a("p",[a("strong",[t._v("Pre")]),t._v("-training: Using a large corpora to train a neural language model.")]),t._v(" "),a("ul",[a("li",[t._v("Autoregressive pre-trained: GPT ç³»åˆ—ï¼ˆGPT, GPT-2, GPT-3ï¼‰")]),t._v(" "),a("li",[t._v("MLM-based pre-trained: BERT ç³»åˆ—ï¼ˆBERT, RoBERTa, ALBERTï¼‰")])]),t._v(" "),a("p",[t._v("ä¸ºä»€ä¹ˆè¦è¿™æ ·åšå‘¢ï¼ŸWe believe that after pre-training, the PLM learns some knowledge, encoded in its hidden representations, that can transfer to downstream tasks.")]),t._v(" "),a("img",{staticStyle:{zoom:"72%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029214502721.png",alt:"image-20221029214502721"}}),t._v(" "),a("p",[a("strong",[t._v("fine-tuning")]),t._v(": Using the pre-trained weights of the PLM to initialize a model for a downstream task.")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221029214742084.png",alt:"image-20221029214742084"}}),t._v(" "),a("p",[t._v("PLMs has shown great success on a variety of benchmark datasets in NLP. "),a("strong",[t._v("The next goal is to make PLMs fit in real-life use case")]),t._v(". ä½†æˆ‘ä»¬å°† PLMs ç”¨åˆ°ç°å®æƒ…å†µæ—¶ï¼Œå´ä¼šé‡åˆ°å„ç§é—®é¢˜ã€‚")]),t._v(" "),a("h2",{attrs:{id:"_2-the-problem-of-plms"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-the-problem-of-plms"}},[t._v("#")]),t._v(" 2. The problem of PLMs")]),t._v(" "),a("h3",{attrs:{id:"_2-1-problem-1-data-scarcity-in-downstream-tasks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-problem-1-data-scarcity-in-downstream-tasks"}},[t._v("#")]),t._v(" 2.1 Problem 1: "),a("mark",[t._v("Data scarcity")]),t._v(" in downstream tasks")]),t._v(" "),a("p",[t._v("A large amount of labeled data is not easy to obtain for each downstream task. ä¸‹é¢æ˜¯ä¸€ä¸ªè®­ç»ƒ BERT æ‰€ç”¨çš„ datasetï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030161440398.png",alt:"image-20221030161440398"}}),t._v(" "),a("p",[t._v("è¿™é‡Œé¢çš„æ•°æ®é›†æœ€å°‘éƒ½æ˜¯å‡ åƒçº§çš„ï¼Œä½†åœ¨ç°å®ä¸­æƒ³è¦å¼„åˆ°è¿™ä¹ˆå¤šçš„æ•°æ®è¿˜æ˜¯éå¸¸å›°éš¾çš„ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_2-2-problem-2-the-plm-is-too-big"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-problem-2-the-plm-is-too-big"}},[t._v("#")]),t._v(" 2.2 Problem 2: The PLM is too big")]),t._v(" "),a("p",[t._v("The PLM is too big, and they are still getting bigger:")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030161617975.png",alt:"image-20221030161617975"}}),t._v(" "),a("p",[t._v("åœ¨å®é™…åº”ç”¨æ—¶ï¼Œè¿™ä¹ˆå¤§çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ª downstream éƒ½å¼„ä¸€ä»½ copyï¼Œè¿™ä¼šç‰¹åˆ«å æ®ç©ºé—´ï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030161959783.png",alt:"image-20221030161959783"}}),t._v(" "),a("p",[t._v("è€Œä¸”è¿™ä¹ˆå¤šå±‚çš„æ¨¡å‹ï¼Œè®¡ç®—ä¸€æ¬¡ inference éƒ½éœ€è¦èŠ±è´¹ç‰¹åˆ«å¤šçš„æ—¶é—´ã€‚")]),t._v(" "),a("p",[t._v("å› æ­¤ï¼Œæ¨¡å‹è¶Šæ¥è¶Šå¤§çš„é—®é¢˜å¯ä»¥æ€»ç»“ä¸ºä¸¤ä¸ªï¼š")]),t._v(" "),a("ul",[a("li",[t._v("Inference takes too long.")]),t._v(" "),a("li",[t._v("Consume too much space.")])]),t._v(" "),a("h2",{attrs:{id:"_3-labeled-data-scarcity-data-efficient-fine-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-labeled-data-scarcity-data-efficient-fine-tuning"}},[t._v("#")]),t._v(" 3. Labeled Data Scarcity -> Data-Efficient Fine-tuning")]),t._v(" "),a("h3",{attrs:{id:"_3-1-prompt-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-prompt-tuning"}},[t._v("#")]),t._v(" 3.1 Prompt Tuning")]),t._v(" "),a("h4",{attrs:{id:"_3-1-1-ä»€ä¹ˆæ˜¯-prompt-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-1-ä»€ä¹ˆæ˜¯-prompt-tuning"}},[t._v("#")]),t._v(" 3.1.1 ä»€ä¹ˆæ˜¯ Prompt Tuningï¼Ÿ")]),t._v(" "),a("p",[t._v("ä»¥å¾€åœ¨åš natural language inference æ—¶ï¼Œæˆ‘ä»¬å¾€å¾€ä¼šè¿™ä¹ˆåšï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030165310825.png",alt:"image-20221030165310825"}}),t._v(" "),a("p",[t._v("ä½†å¦‚æœ training data è¾ƒå°‘çš„è¯ï¼Œè¿™å¾€å¾€æ˜¯éš¾ä»¥åšå‡ºæ¥çš„ï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030165458079.png",alt:"image-20221030165458079"}}),t._v(" "),a("p",[t._v("æ­¤æ—¶ä¸€ç§æ–¹æ³•æ˜¯ï¼Œéƒ½åŠ ä¸Šä¸€å¥ â€œIs is true thatâ€ æ¥è¡¨ç¤ºè¯¢é—®åé¢è¿™ä¸ªå¥å­ä¸å‰é¢å¥å­çš„å…³ç³»ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030165701921.png",alt:"image-20221030165701921"}}),t._v(" "),a("p",[t._v("è¿™ä¸ªä¸œè¥¿å°±æ˜¯ "),a("mark",[t._v("Prompt Tuning")]),t._v(" çš„æ ¸å¿ƒæ¦‚å¿µï¼Œä¹Ÿå°±æ˜¯è®¾ç½®ä¸€äº›ä¸œè¥¿å‘Šè¯‰ model æˆ‘ä»¬åœ¨åšä»€ä¹ˆã€‚æ‰€ä»¥è¯´ï¼ŒBy converting the data points in the dataset into natural language prompts, the model may be easier to know what it should do.")]),t._v(" "),a("p",[t._v("ä»€ä¹ˆæ˜¯ Prompt Tuning å‘¢ï¼Ÿ"),a("u",[t._v("Format the downstream task as a language modelling task with predefined")]),t._v(" "),a("u",[t._v("templates into natural language "),a("strong",[t._v("prompts")])]),t._v(".")]),t._v(" "),a("h4",{attrs:{id:"_3-1-2-prompt-tuning-éœ€è¦ä»€ä¹ˆ"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-2-prompt-tuning-éœ€è¦ä»€ä¹ˆ"}},[t._v("#")]),t._v(" 3.1.2 Prompt Tuning éœ€è¦ä»€ä¹ˆ")]),t._v(" "),a("p",[t._v("What you need in prompt tuning:")]),t._v(" "),a("ol",[a("li",[t._v("A prompt template")]),t._v(" "),a("li",[t._v("A PLM")]),t._v(" "),a("li",[t._v("A verbalizer")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030171916101.png",alt:"image-20221030171916101"}})]),t._v(" "),a("h5",{attrs:{id:"_1-a-prompt-template"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-a-prompt-template"}},[t._v("#")]),t._v(" 1ï¼‰A prompt template")]),t._v(" "),a("p",[t._v("A "),a("mark",[t._v("prompt template")]),t._v(": convert data points into a natural language prompt.")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030172215732.png",alt:"image-20221030172215732"}}),t._v(" "),a("p",[t._v("åœ¨å¾—åˆ° natural language prompt åï¼Œå°±å¯ä»¥å°†å®ƒè¾“å…¥åˆ° PLM ä¸­ï¼Œæ¥é¢„æµ‹ [MASK] çš„éƒ¨åˆ†æ˜¯ä»€ä¹ˆã€‚")]),t._v(" "),a("h5",{attrs:{id:"_2-a-plm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-a-plm"}},[t._v("#")]),t._v(" 2ï¼‰A PLM")]),t._v(" "),a("p",[t._v("A "),a("mark",[t._v("PLM")]),t._v(": perform language modeling.")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030172527863.png",alt:"image-20221030172527863"}}),t._v(" "),a("h5",{attrs:{id:"_3-a-verbalizer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-a-verbalizer"}},[t._v("#")]),t._v(" 3ï¼‰A verbalizer")]),t._v(" "),a("p",[t._v("A "),a("mark",[t._v("verbalizer")]),t._v(": A mapping between the label and the vocabulary. For example, which vocabulary should represents the class â€œentailmentâ€:")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030172809882.png",alt:"image-20221030172809882"}}),t._v(" "),a("p",[t._v("ç„¶ååœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿™ä¹ˆå¹²äº†ï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030172845084.png",alt:"image-20221030172845084"}}),t._v(" "),a("h4",{attrs:{id:"_3-1-3-prompt-tuning-v-s-standard-fine-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-3-prompt-tuning-v-s-standard-fine-tuning"}},[t._v("#")]),t._v(" 3.1.3 Prompt tuning v.s. Standard fine-tuning")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221030173244999.png",alt:"image-20221030173244999"}})]),t._v(" "),a("ul",[a("li",[t._v("åœ¨ standard fine-tuning ä¸­ï¼Œæˆ‘ä»¬ä¼šä¸¢æ‰ LM Head å¹¶é‡æ–° initialize ä¸€ä¸ª Classifier Headï¼›")]),t._v(" "),a("li",[t._v("è€Œåœ¨ prompt tuning ä¸­ï¼Œæˆ‘ä»¬å°±æ˜¯è¦åˆ©ç”¨ language model çš„èƒ½åŠ›ï¼Œå› æ­¤ä¸ä¼šä¸¢å¼ƒè¿™ä¸ª language model çš„ headã€‚")])]),t._v(" "),a("p",[t._v("Prompt tuning has better performance under data scarcity "),a("strong",[t._v("because")]),t._v("ï¼š")]),t._v(" "),a("ul",[a("li",[t._v("It incorporates human knowledgeï¼ˆå› ä¸º prompt template çš„è®¾è®¡æœ¬èº«å°±èå…¥äº† human knowledgeï¼‰")]),t._v(" "),a("li",[t._v("It introduces no new parameters")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"73%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221102201439206.png",alt:"image-20221102201439206"}})]),t._v(" "),a("p",[t._v("ä¸‹é¢ï¼ŒLets see how prompts can help us under different level of data scarcity.")]),t._v(" "),a("h3",{attrs:{id:"_3-2-few-shot-learning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-few-shot-learning"}},[t._v("#")]),t._v(" 3.2 Few-shot Learning")]),t._v(" "),a("p",[a("mark",[t._v("Few-shot Learning")]),t._v(": We have "),a("strong",[t._v("some")]),t._v(" labeled training data.")]),t._v(" "),a("p",[t._v("ä½† Few-shot Learning ä¹Ÿæ˜¯ä¸€ä¸ªæ²¡æœ‰æ˜ç¡®å®šä¹‰çš„è¯ï¼Œå…·ä½“å¤šå°‘æ˜¯ few-shotï¼Œå¹¶æ²¡æœ‰å…·ä½“çš„èŒƒå›´ï¼Œåœ¨è¿™é‡Œå‡è®¾ few-shot æ˜¯æŒ‡çš„ â€œSome â‰ˆ 10GB training dataâ€ã€‚")]),t._v(" "),a("p",[t._v("Good News æ˜¯ GPT-3 å¯ä»¥è¢«ç”¨äºåš few-shot learningï¼Œä½† bad news æ˜¯ï¼šGPT-3 is not freely available and contains 175B parameters.")]),t._v(" "),a("p",[t._v("Can we use smaller PLMs and make them to perform well in few-shot learning?")]),t._v(" "),a("p",[a("mark",[t._v("LM-BFF")]),t._v(": "),a("strong",[t._v("b")]),t._v("etter "),a("strong",[t._v("f")]),t._v("ew-shot "),a("strong",[t._v("f")]),t._v("ine-tuning of "),a("strong",[t._v("l")]),t._v("anguage "),a("strong",[t._v("m")]),t._v("odels. å®ƒçš„æ ¸å¿ƒæ¦‚å¿µï¼š"),a("strong",[t._v("prompt")]),t._v(" + "),a("strong",[t._v("demonstration")]),t._v("ã€‚")]),t._v(" "),a("p",[t._v("prompt æ˜¯æŒ‡ä¸‹é¢è¿™ä¸ªæ ·å­ï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221102203929560.png",alt:"image-20221102203929560"}}),t._v(" "),a("p",[t._v("è€Œ "),a("mark",[t._v("demonstration")]),t._v(" æ˜¯è¯´ï¼Œæˆ‘è¦è®© model çŸ¥é“ï¼Œå½“å®ƒçœ‹åˆ°è¿™æ ·çš„ prompt ä¹‹åï¼Œå®ƒè¯¥å»æ€ä¹ˆåšã€‚æ‰€ä»¥ demonstration çš„åšæ³•å°±æ˜¯ï¼Œåœ¨ prompt çš„éƒ¨åˆ†åé¢åŠ äº†ä¸¤ä¸ª demonstration çš„å¥å­ï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221102204222689.png",alt:"image-20221102204222689"}}),t._v(" "),a("p",[t._v("ç»™ä»–ä¸€ä¸ªæ­£é¢çš„ reviewï¼Œå½“ model çœ‹åˆ°æ­£é¢çš„ review ä¹‹åï¼Œå®ƒåº”è¯¥çŸ¥é“åé¢ â€œIt was ___â€ è¿™é‡Œåº”è¯¥å¡« â€œgreatâ€ï¼Œç±»ä¼¼çš„ï¼Œå½“ä»–çœ‹åˆ°è´Ÿé¢çš„ review ä¹‹åï¼Œå®ƒåº”è¯¥çŸ¥é“åé¢çš„ â€œIt was ___â€ è¿™é‡Œåº”è¯¥å¡« â€œterribleâ€ã€‚ è¿™æ ·çš„å½¢å¼å°±å¯ä»¥æ›´åŠ å¸®åŠ© language model åœ¨ few-shot learning ä¸Šé¢çš„è¡¨ç°ã€‚")]),t._v(" "),a("p",[t._v("å…¶ performance å¦‚ä¸‹ï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221102210720916.png",alt:"image-20221102210720916"}}),t._v(" "),a("h3",{attrs:{id:"_3-3-semi-supervised-learning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-semi-supervised-learning"}},[t._v("#")]),t._v(" 3.3 Semi-supervised Learning")]),t._v(" "),a("p",[a("mark",[t._v("Semi-supervised Learning")]),t._v(": We have some labeled training data and a large amount of unlabeled data.")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221102212710576.png",alt:"image-20221102212710576"}}),t._v(" "),a("p",[t._v("è¿™é‡Œä¸»è¦çœ‹ä¸€ä¸‹ï¼š"),a("a",{attrs:{href:"https://aclanthology.org/2021.naacl-main.185/?utm_campaign=%E6%AF%8E%E9%80%B1%20NLP%20%E8%AB%96%E6%96%87&utm_medium=email&utm_source=Revue%20newsletter",target:"_blank",rel:"noopener noreferrer"}},[t._v("Itâ€™s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"),a("OutboundLink")],1),t._v("ï¼Œå› ä¸º GPT-3 çš„è®ºæ–‡å°±æ˜¯ "),a("a",{attrs:{href:"https://arxiv.org/abs/2005.14165",target:"_blank",rel:"noopener noreferrer"}},[t._v("Language Models are Few-Shot Learners"),a("OutboundLink")],1),t._v("ï¼Œæ‰€ä»¥å‰è€…å°±åƒæœ‰ç‚¹åœ¨æ‰“è„¸ GPT-3 çš„æ ·å­ã€‚")]),t._v(" "),a("p",[t._v("å®ƒæå‡ºçš„æ–¹æ³•å«åš "),a("strong",[t._v("Pattern-Exploiting Training")]),t._v(" ("),a("mark",[t._v("PET")]),t._v(")ï¼Œå…·ä½“åˆ†æˆäº†ä¸‰ä¸ªæ­¥éª¤ï¼š")]),t._v(" "),a("ul",[a("li",[t._v("Step 1: Use different prompts and verbalizer to prompt-tune different PLMs on the labeled dataset.")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221104221640334.png",alt:"image-20221104221640334"}})]),t._v(" "),a("ul",[a("li",[t._v("Step 2: Predict the unlabeled dataset and combine the predictions from different models.")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221104222639420.png",alt:"image-20221104222639420"}})]),t._v(" "),a("p",[t._v("å¯¹åŒä¸€ç¬”æ•°æ®ï¼Œä¸åŒ prompt-tune å¾—åˆ°çš„ model ç»™å‡ºçš„ prediction ä¹Ÿè®¸æ˜¯ä¸ä¸€æ ·çš„ï¼Œæˆ‘ä»¬æ‹¿åˆ°è¿™äº› prediction åå†å°†ä»–ä»¬ combine åˆ°ä¸€èµ·ï¼Œåœ¨è¿™é‡Œå¯ä»¥åªæ˜¯ç®€å•åœ°ç›¸åŠ ã€‚")]),t._v(" "),a("ul",[a("li",[t._v("Step 3: Use a PLM with classifier head to train on the soft-labeled data set.")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221104223312301.png",alt:"image-20221104223312301"}})]),t._v(" "),a("p",[t._v("è¿™ä¸€æ­¥æ˜¯åœ¨æ‰€æœ‰çš„ dataset è¿›è¡Œ fine-tuningï¼Œå¯¹äº labeled data åˆ™æ˜¯ç”¨çš„åŸ labelï¼Œè€Œå¯¹äº unlabeled dataï¼Œåˆ™ç”¨çš„æ˜¯ soft labelï¼Œå³æˆ‘ä»¬åœ¨ step 2 ä¸­å¾—åˆ°çš„ labelï¼Œç„¶åè¿›è¡Œ standard fine-tuningï¼Œä¹Ÿå°±æ˜¯æ‹¿æ‰ LM Head å†åŠ ä¸€ä¸ª Classifier Head è¿›è¡Œ fine-tuningã€‚")]),t._v(" "),a("h3",{attrs:{id:"_3-4-zero-shot-learning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-zero-shot-learning"}},[t._v("#")]),t._v(" 3.4 Zero-shot Learning")]),t._v(" "),a("h4",{attrs:{id:"_3-4-1-ä»€ä¹ˆæ˜¯-zero-shot"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-1-ä»€ä¹ˆæ˜¯-zero-shot"}},[t._v("#")]),t._v(" 3.4.1 ä»€ä¹ˆæ˜¯ zero-shotï¼Ÿ")]),t._v(" "),a("p",[a("mark",[t._v("Zero-shot inference")]),t._v(": inference on the downstream task without any training data. If you donâ€™t have training data, then we need a model that can zero-shot inference on downstream tasks.")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106190303964.png",alt:"image-20221106190303964"}})]),t._v(" "),a("p",[t._v("ä»€ä¹ˆæ ·çš„ model å¯ä»¥åš zero-shot inference å‘¢ï¼ŸGPT-3 å¯ä»¥ï¼GPT-3 çš„å¯ä»¥å‘Šè¯‰äº†æˆ‘ä»¬ä¸€ä»¶äº‹æƒ…ï¼šOnly if your model is large enough.")]),t._v(" "),a("p",[a("mark",[t._v("Zero-shot")]),t._v(": The model predicts the answer given only a natural language description of the task. No gradient updates are performed. æ¯”å¦‚å¦‚ä¸‹é¢æ‰€ç¤ºï¼Œä½ å‘Šè¯‰è¦åšçš„ task descriptionï¼Œç„¶åå†ç»™ä¸€ä¸ª promptï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"90%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106191126794.png",alt:"image-20221106191126794"}}),t._v(" "),a("p",[t._v("å®ƒçš„ performance å¦‚ä¸‹å›¾ï¼Œå¯ä»¥çœ‹åˆ°éšç€å‚æ•°é‡è¶Šæ¥è¶Šå¤šï¼Œperformance ä¼šè¶Šè€è¶Šå¥½ï¼Œä½† zero-shot å…¶å®ä¹Ÿæ²¡æœ‰ç‰¹åˆ«å¥½ï¼Œè¿˜æ˜¯æœ‰å¾ˆå¤šçš„æå‡ç©ºé—´ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106191256438.png",alt:"image-20221106191256438"}})]),t._v(" "),a("h4",{attrs:{id:"_3-4-2-where-does-this-zero-shot-ability-spring-from"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-2-where-does-this-zero-shot-ability-spring-from"}},[t._v("#")]),t._v(" 3.4.2 Where does this zero-shot ability spring from?")]),t._v(" "),a("p",[t._v("ğŸ’¡ "),a("strong",[t._v("Hypothesis")]),t._v(": during pre-training, the training datasets implicitly contains a mixture of different tasks.")]),t._v(" "),a("p",[t._v("ä¸ºä»€ä¹ˆ GPT-3 å¯ä»¥åšåˆ° zero-shot inference å‘¢ï¼Ÿä¸€ä¸ªå‡è¯´è®¤ä¸ºï¼Œæˆ‘ä»¬ pre-training çš„è¿‡ç¨‹å°±å¾ˆåƒæ˜¯ä¸€ä¸ª multi-task learning çš„ç¯å¢ƒï¼Œpre-training data é‡Œé¢æœ‰å„ç§å„æ ·çš„ taskï¼Œå› æ­¤èƒ½è®©ä»–å­¦åˆ° multi-task learning çš„èƒ½åŠ›ã€‚")]),t._v(" "),a("p",[t._v("æ¯”å¦‚è¯´å®ƒå¯èƒ½ä¼šçœ‹åˆ° QA çš„æ–‡æœ¬ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œä¸€ä¸ª Q å¼€å¤´ï¼Œä¸€ä¸ª A å¼€å¤´ï¼Œè¿™å…¶ä¸­å°±æš—ç¤ºäº† QA task äº†ï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106192401111.png",alt:"image-20221106192401111"}}),t._v(" "),a("p",[t._v("åˆæ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼Œå½“ä»–çœ‹åˆ° one-sentence summary æ—¶ï¼Œä»–å°±çŸ¥é“ä¸Šé¢çš„ abstract çš„é‚£ä¸€å¤§æ®µè¯ç”¨ä¸€å¥è¯æ¥è¡¨è¿°çš„è¯ï¼Œå°±æ˜¯åé¢è¿™å¥è¯çš„æ ·å­ï¼Œå› æ­¤è¿™ä¹Ÿæš—ç¤ºäº† summarization çš„ taskï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"90%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106192900248.png",alt:"image-20221106192900248"}}),t._v(" "),a("p",[t._v("æ‰€ä»¥è¯´ï¼Œ"),a("strong",[t._v("during pre-training, the training datasets implicitly contains a mixture of different tasks.")])]),t._v(" "),a("p",[t._v("åˆ°äº†è¿™é‡Œï¼Œæœ‰äººå°±æƒ³åˆ°è¯´ï¼Œä¸å…¶è®©ä»– implicitly å­¦ä¹ è¿™ç§èƒ½åŠ›ï¼Œä¸å¦‚è®©ä»– explicitly å­¦ä¹ è¿™ç§èƒ½åŠ›ã€‚")]),t._v(" "),a("p",[t._v("ğŸ’¡ "),a("strong",[t._v("Hypothesis")]),t._v(": multi-task training enables zero-shot generalization.")]),t._v(" "),a("p",[t._v("æœ‰äººå°±å¯¹ T5 æ¨¡å‹ç”¨ multi-task learning çš„æ–¹å¼è¿›è¡Œ fine-tuningï¼Œç„¶åæµ‹è¯•çœ‹åœ¨ fine-tuning ä¹‹åï¼Œè¿™ä¸ª model æœ‰æ²¡æœ‰èƒ½åŠ›åš zero-shot learning:")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"95%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106194527011.png",alt:"image-20221106194527011"}})]),t._v(" "),a("p",[t._v("å…·ä½“çš„åšæ³•ä¸ä¹‹å‰æ˜¯ä¸€æ ·çš„ï¼Œå°±æ˜¯å°†éå¸¸å¤šçš„ dataset è½¬æ¢æˆå¤šç§ç±»å‹çš„ prompts çš„å½¢å¼ï¼Œç„¶åç»™ä»–çœ‹å¾ˆå¤šçš„ promptã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­å°±æ˜¯åœ¨åš Natural Language Inference ("),a("strong",[t._v("NLI")]),t._v(") æ—¶ï¼Œå°† NLI dataset è½¬æ¢æˆ Natural language prompt çš„ç¤ºä¾‹ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106195058586.png",alt:"image-20221106195058586"}})]),t._v(" "),a("p",[t._v("æˆ‘ä»¬è¦ train çš„ task æœ‰å¾ˆå¤šä¸åŒç§ç±»ï¼Œæˆ‘ä»¬å°†è¿™äº› tasks åˆ†æˆä¸¤ç±»ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé»„è‰²çš„ä¸€ç±» tasks ä¼šç”¨äº fine-tuning è¿‡ç¨‹ï¼Œç„¶åå‰©ä¸‹çš„ç»¿è‰²çš„ä¸€ç±» tasks ä¼šç”¨äº zero-shot inference çš„æµ‹è¯•ã€‚")]),t._v(" "),a("p",[t._v("ä¸Šé¢æ‰€è®²çš„è¿™ç§åšæ³•ï¼Œsometimes achieves performance better than GPT-3 (175B parameters) with "),a("em",[a("strong",[t._v("only 11B")])]),t._v(" parameters. æ•ˆæœè¿˜æ˜¯å¾ˆä¸é”™çš„ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_3-5-summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-summary"}},[t._v("#")]),t._v(" 3.5 Summary")]),t._v(" "),a("p",[t._v("æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹åšäº†ä»€ä¹ˆï¼Œåœ¨ dataset æ¯”è¾ƒå°‘çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥ use natural language prompts and add scenario-specific designsï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106200118470.png",alt:"image-20221106200118470"}})]),t._v(" "),a("h2",{attrs:{id:"_4-plms-are-gigantic-reducing-the-number-of-parameters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-plms-are-gigantic-reducing-the-number-of-parameters"}},[t._v("#")]),t._v(" 4. PLMs Are Gigantic -> Reducing the Number of Parameters")]),t._v(" "),a("p",[t._v("è¿™ä¸€ç« å°±æ˜¯è®²å½“ PLM å¤ªå¤§çš„æ—¶å€™ï¼Œåº”è¯¥æ€ä¹ˆæ ·è®©ä»–å°ä¸€ç‚¹ã€‚")]),t._v(" "),a("p",[t._v("æœ€ç›´æ¥çš„æƒ³æ³•å°±æ˜¯è®© PLM æ›´åŠ å°ä¸€ç‚¹ï¼Œä½†æ˜¯è¿™å…¶å®æ˜¯æœ‰é—®é¢˜çš„ï¼Œå› ä¸ºç›´æ¥å¯¹å°çš„ PLM è¿›è¡Œ pre-training åï¼Œå…¶å®ä½ è¿˜æ˜¯ç”¨çš„åŒæ ·çš„ corpusã€åŒæ ·çš„æ—¶é—´æ¥é¢„è®­ç»ƒï¼Œæœ€ç»ˆç»“æœçš„ performance ç›¸æ¯”äºå¤§çš„ model ç›¸å·®äº†å¾ˆå¤§ä¸€æˆªï¼Œ"),a("strong",[t._v("æ‰€ä»¥ç›´æ¥ç”¨å°çš„ PLM æ¥åš pre-training æ˜¯ä¸å¤ªå¯è¡Œçš„")]),t._v("ã€‚")]),t._v(" "),a("p",[t._v("æ¯”è¾ƒå¯è¡Œçš„ä¸€ä¸ªæ–¹æ³•æ˜¯å‡å°‘æˆ‘ä»¬åœ¨ fine-tuning æ—¶æ‰€éœ€è¦ç”¨åˆ°çš„å‚æ•°çš„é‡ã€‚è¿™å…¶å®å°±æœ‰å¾ˆå¤šä¸åŒçš„æ–¹å¼äº†ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_4-1-pre-train-a-large-model-but-use-a-smaller-model-for-the-downstream-tasks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-pre-train-a-large-model-but-use-a-smaller-model-for-the-downstream-tasks"}},[t._v("#")]),t._v(" 4.1 Pre-train a large model, but use a smaller model for the downstream tasks.")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106211227014.png",alt:"image-20221106211227014"}})]),t._v(" "),a("p",[t._v("ä¸‹é¢è¿™ä¸ª pruning çš„åšæ³•å¾—åˆ°çš„ BERT-base è™½ç„¶ç»“æ„è¿˜æ˜¯æ¯”è¾ƒå¤§ï¼Œä½†æ˜¯ç”±äºå®ƒçš„ sparsity æ¯”è¾ƒé«˜ï¼Œå› æ­¤å ç”¨çš„ç©ºé—´å°±å°äº†å¾ˆå¤šäº†ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_4-2-share-the-parameters-among-the-transformer-layers-albert"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-share-the-parameters-among-the-transformer-layers-albert"}},[t._v("#")]),t._v(" 4.2 Share the parameters among the transformer layers: ALBERT")]),t._v(" "),a("p",[t._v("ä»¥å¾€çš„ä¸åŒ Transformer Layer çš„å‚æ•°æ˜¯ä¸ä¸€æ ·çš„ï¼Œä½†åœ¨ "),a("mark",[t._v("ALBERT")]),t._v(" ä¸­ï¼Œæ¯ä¸€å±‚çš„å‚æ•°éƒ½æ˜¯ä¸€æ ·çš„ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106211559280.png",alt:"image-20221106211559280"}})]),t._v(" "),a("h3",{attrs:{id:"_4-3-parameter-efficient-fine-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-parameter-efficient-fine-tuning"}},[t._v("#")]),t._v(" 4.3 Parameter-Efficient Fine-tuning")]),t._v(" "),a("p",[t._v("è¿™ç§æ–¹æ³•å°±æ˜¯å¸Œæœ›åœ¨ fine-tuning çš„æ—¶å€™ï¼Œæ€æ ·ç”¨å°‘ä¸€ç‚¹çš„ parametersã€‚ä¸€ç§æ–¹æ³•æ˜¯ä¸‹é¢è¿™ç§ï¼š")]),t._v(" "),a("p",[t._v("ğŸš€ "),a("strong",[t._v("Use a small amount of parameters for each downstream task")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106212201920.png",alt:"image-20221106212201920"}})]),t._v(" "),a("p",[t._v("è¿™æ ·æˆ‘ä»¬å°±åªéœ€è¦ä¸€ä¸ª BERT çš„å‚æ•°ï¼Œå†åŠ ä¸Šå¯¹æ¯ä¸ª task æœ‰ä¸€ä¸ªä¸“å±çš„ parametersï¼Œä»è€Œå¤§å¤§é™ä½æˆ‘ä»¬æ‰€éœ€è¦çš„ç©ºé—´ã€‚")]),t._v(" "),a("p",[t._v("è¿™ä»¶äº‹æƒ…æ€ä¹ˆåšå‘¢ï¼Ÿ")]),t._v(" "),a("p",[t._v("è¦åšè¿™ä»¶äº‹æƒ…ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆçœ‹ä¸€ä¸‹ standard fine-tuning çœŸæ­£åšäº†ä»€ä¹ˆã€‚standard fine-tuning çœŸæ­£åšçš„äº‹æƒ…æ˜¯ï¼šModify the "),a("em",[a("u",[t._v("hidden representation")])]),t._v(" ("),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1)],1)],1),t._v(") of the PLM such that it can perform well on downstream task. åœ¨ fine-tuning ä¹‹å‰ï¼ŒPLM å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106212649354.png",alt:"image-20221106212649354"}})]),t._v(" "),a("p",[t._v("ç»è¿‡äº†å¾®è°ƒä¹‹åï¼ŒPLM å†…éƒ¨çš„ "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1)],1)],1),t._v(" å‘ç”Ÿäº†æ”¹å˜ï¼š")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106213453467.png",alt:"image-20221106213453467"}})]),t._v(" "),a("p",[t._v("è¿™ä¸ªå¾®è°ƒåçš„ hidden representation èƒ½å¤Ÿè¢« classifier head å¾ˆå¥½åœ°åˆ©ç”¨ã€‚ä»¥ä¸Šå°±æ˜¯ standard fine-tuning æ‰€åšçš„äº‹æƒ…ã€‚")]),t._v(" "),a("p",[t._v("æ‰€ä»¥è¯´ï¼Œ"),a("strong",[t._v("standard fine-tuning = modifying the hidden representation based on PLM")]),t._v(". ä¹Ÿå°±æ˜¯å°† hidden representation ä» "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1)],1)],1),t._v(" æ”¹å˜åˆ°äº† "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mi",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"394"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1)],1)],1),t._v("ï¼š")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"72%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106215144810.png",alt:"image-20221106215144810"}})]),t._v(" "),a("p",[t._v("ä½†ç°åœ¨æˆ‘ä»¬æƒ³é—®çš„æ˜¯ï¼Œ"),a("strong",[t._v("æˆ‘ä»¬æœ‰æ²¡æœ‰åŠæ³•ä¸è¦è°ƒæ•´æ•´ä¸ª model çš„å‚æ•°ï¼Œè€Œæ˜¯åªè¦æ”¹å˜å°‘éƒ¨åˆ†çš„å‚æ•°å°±å¯ä»¥è¾¾åˆ°æ”¹å˜ hidden representation çš„ç›®æ ‡å‘¢")]),t._v("ï¼Ÿè¿™é‡Œ parameter-efficient fine-tuning æ‰€è¦åšçš„å°±æ˜¯è¿™ä»¶äº‹æƒ…ã€‚ä¸‹é¢å°±çœ‹ä¸€ä¸‹ä¸åŒçš„ parameter-efficient fine-tuning æ˜¯æ€ä¹ˆåšçš„ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_4-4-parameter-efficient-fine-tuning-adapter"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-parameter-efficient-fine-tuning-adapter"}},[t._v("#")]),t._v(" 4.4 Parameter-Efficient Fine-tuning: Adapter")]),t._v(" "),a("p",[t._v("Adapter å°±æ˜¯ use special submodules to modify hidden representationsï¼š")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106220651389.png",alt:"image-20221106220651389"}}),t._v(" "),a("p",[a("mark",[t._v("Adapters")]),t._v(": small trainable submodules inserted in transformers.")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106220902149.png",alt:"image-20221106220902149"}})]),t._v(" "),a("p",[t._v("è¿™é‡Œçš„ Adapter é•¿ä»€ä¹ˆæ ·å‘¢ï¼Ÿå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œhidden representation "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1)],1)],1),t._v(" é¦–å…ˆç»è¿‡ä¸€ä¸ª MLP è¿›è¡Œé™ç»´ï¼Œå†ç»è¿‡éçº¿æ€§è½¬åŒ–å±‚å¾—åˆ°ä¸€ä¸ªè¾ƒä½ç»´åº¦çš„ vectorï¼Œå†ç„¶åç»è¿‡ MLP å˜æˆä¸åŸæ¥ç›¸åŒç»´åº¦çš„ "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"394"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1)],1)],1),t._v("ï¼š")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221106221255363.png",alt:"image-20221106221255363"}})]),t._v(" "),a("p",[t._v("æ‰€ä»¥åœ¨è¿™ä¸ªæŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬ fine-tuning çš„åªéœ€è¦å» update æˆ‘ä»¬çš„ adapters å’Œ classifier head å°±å¯ä»¥äº†ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_4-5-parameter-efficient-fine-tuning-lora"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-parameter-efficient-fine-tuning-lora"}},[t._v("#")]),t._v(" 4.5 Parameter-Efficient Fine-tuning: LoRA")]),t._v(" "),a("p",[t._v("ä»æ•´ä½“ä¸Šçœ‹ï¼ŒLoRA æ‰€è¦åšçš„äº‹æƒ…ä¸åˆšåˆšæ˜¯ä¸€æ ·çš„ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107200646345.png",alt:"image-20221107200646345"}})]),t._v(" "),a("p",[a("mark",[t._v("LoRA")]),t._v(": Low-Rank Adaptation of Large Language Models. å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ"),a("strong",[t._v("å®ƒæ‰€åšçš„å°±æ˜¯åœ¨ Feed-forward éƒ¨åˆ†ä¸Šå¹³è¡Œåœ°åŠ ä¸Šäº†ä¸€ä¸ª submodule")]),t._v("ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107201122582.png",alt:"image-20221107201122582"}})]),t._v(" "),a("p",[t._v("Feed-forward éƒ¨åˆ†åŸæ¥å°±æ˜¯ä¸€ä¸ªä¸¤å±‚çš„ MLPï¼Œç°åœ¨åŠ ä¸Š LoRA åï¼Œç»“æ„å¦‚ä¸‹å›¾ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107201450844.png",alt:"image-20221107201450844"}})]),t._v(" "),a("p",[t._v("LoRA çš„ submodule ä¼šåŠ ä¸ŠåŸæ¥çš„ MLP çš„è¾“å‡ºï¼Œä»è€Œå…±åŒæ„æˆè¾“å‡ºã€‚å¦‚æœæˆ‘ä»¬æ”¾å¤§çº¢è‰²æ–¹æ¡†çš„éƒ¨åˆ†ï¼Œå¯ä»¥çœ‹åˆ°å…·ä½“åšæ³•å¦‚ä¸‹ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"72%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107201840192.png",alt:"image-20221107201840192"}})]),t._v(" "),a("p",[t._v("åŸæ¥çš„ "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"d"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"m"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"o"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"d"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"l"}})],1)],1)],1)],1)],1)],1),t._v(" å…ˆæŠ•å½±æˆä¸€ä¸ªç»´åº¦å¾ˆä½çš„ vectorï¼Œå†ç»è¿‡æŠ•å½±è¿˜åŸä¸º "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"d"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"F"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"F"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"W"}})],1)],1)],1)],1)],1)],1),t._v("ã€‚")],1),t._v(" "),a("p",[t._v("è¿™æ ·çš„è¯ï¼Œæ‰€æœ‰çš„ downstream tasks å…±äº«ä¸€ä¸ª PLMï¼Œç„¶åæ¯ä¸€å±‚çš„ LoRA submodule å’Œ classifier head æ‰æ˜¯ task-specific modulesã€‚")]),t._v(" "),a("p",[t._v("LoRA çš„å–ç‚¹ä¹‹ä¸€æ˜¯ï¼Œå®ƒçš„ submodule æ˜¯å¹³è¡Œåœ°æ’åœ¨ feed-forward éƒ¨åˆ†ä¸Šï¼Œè¿™æ ·ä¸ä¼šå¢åŠ  inference çš„æ—¶é—´ï¼Œè€Œ Adapter æŠ€æœ¯åˆ™æ˜¯åŠ æ·±äº†ç½‘ç»œçš„æ·±åº¦ï¼Œè¿™å¯¼è‡´äº† inference æ—¶é—´çš„å¢åŠ ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_4-6-parameter-efficient-fine-tuning-prefix-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-6-parameter-efficient-fine-tuning-prefix-tuning"}},[t._v("#")]),t._v(" 4.6 Parameter-Efficient Fine-tuning: Prefix Tuning")]),t._v(" "),a("p",[t._v("Prefix Tuning æ‰€åšçš„äº‹æƒ…ä¹Ÿæ˜¯ä¸€æ ·ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107203116951.png",alt:"image-20221107203116951"}})]),t._v(" "),a("p",[a("mark",[t._v("Prefix Tuning")]),t._v(": Insert trainable prefix in each layer.")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"72%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107203332817.png",alt:"image-20221107203332817"}})]),t._v(" "),a("p",[t._v("ä¸ºäº†è®² prefix tuningï¼Œæˆ‘ä»¬å…ˆå›é¡¾ä¸€ä¸‹ standard self-attention çš„æ“ä½œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸ºäº†è®¡ç®— "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v(" çš„å¯¹åº”è¾“å‡º "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msubsup",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.288em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-n"}),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1)],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.18em"}}),a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v("ï¼Œ"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"q"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v(" ä¼šä¾æ¬¡å» query å…¶ä»–äººæ¥å¾—åˆ°ç›¸ä¼¼åº¦ï¼š")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107204721625.png",alt:"image-20221107204721625"}})]),t._v(" "),a("p",[t._v("è€Œ prefix tuning åˆ™æ˜¯åœ¨ standard self-attention çš„åŸºç¡€ä¸ŠåŠ äº†ä¸€äº›ä¸œè¥¿ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ‰€å¢åŠ  prefix "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"p"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"."}})],1)],1)],1)],1)],1),t._v(" éƒ¨åˆ†åªä¼šè¢«å…¶ä»–äººæ‰€ queryï¼Œè€Œä¸ä¼šå» query å…¶ä»–äººï¼š")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107205217541.png",alt:"image-20221107205217541"}})]),t._v(" "),a("p",[t._v("åœ¨ prefix tuning ä¸­ï¼Œ"),a("strong",[t._v("Only the prefix (key and value) are updated during fine-tuning")]),t._v(". åœ¨æœ€åï¼Œæˆ‘ä»¬åªéœ€è¦ä¿ç•™ k v å°±å¥½ï¼Œå¯ä»¥æŠŠ prefix "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"p"}})],1)],1)],1),t._v(" ç»™æŠ›å¼ƒæ‰ï¼Œå› æ­¤æœ€åæ¯ä¸€å±‚ Transformer éƒ½ä¼šæœ‰è‡ªå·±çš„ prefix çš„ key å’Œ valueï¼š")],1),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107210224329.png",alt:"image-20221107210224329"}})]),t._v(" "),a("h3",{attrs:{id:"_4-7-parameter-efficient-fine-tuning-soft-prompting"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-parameter-efficient-fine-tuning-soft-prompting"}},[t._v("#")]),t._v(" 4.7 Parameter-Efficient Fine-tuning: Soft Prompting")]),t._v(" "),a("p",[t._v("è¿™ä¸ª "),a("mark",[t._v("Soft Prompting")]),t._v(" å¯ä»¥çœ‹æˆæ˜¯ä¸€ä¸ª prefix tuning çš„ä¸€ä¸ªç®€åŒ–ç‰ˆï¼Œå®ƒå°±æ˜¯åªåœ¨ input layer ä¸Šæ’å…¥äº†å‡ ä¸ª prefix embeddingï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107211927837.png",alt:"image-20221107211927837"}})]),t._v(" "),a("p",[t._v("ä¸ºä»€ä¹ˆè¿™å«åš soft prompt å‘¢ï¼Ÿä¹‹å‰çš„ prompt æ–¹å¼æ˜¯ "),a("strong",[t._v("Hard Prompting")]),t._v("ï¼šadd words in the input sentence (fine-tune the model while fixing the prompts)ï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107212311262.png",alt:"image-20221107212311262"}})]),t._v(" "),a("p",[t._v("åœ¨è¿™ç§ hard prompting ä¸­ï¼Œä½ æ˜¯æ²¡æœ‰åŠæ³•ç›´æ¥è°ƒè¿™ä¸ª prompt çš„å­—ï¼Œå› ä¸ºå®ƒä»¬åˆä¸æ˜¯å¯ä»¥å¾®åˆ†çš„ï¼Œå› æ­¤æ¯”è¾ƒ hardã€‚è€Œ "),a("strong",[t._v("soft prompting can be considered as the soften version of prompting")]),t._v(".")]),t._v(" "),a("div",{staticClass:"custom-block note"},[a("p",{staticClass:"custom-block-title"},[t._v("Soft Prompt v.s. Hard Prompt")]),t._v(" "),a("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107214024042.png",alt:"image-20221107214024042"}})]),t._v(" "),a("h3",{attrs:{id:"_4-8-æ€»ç»“-parameter-efficient-fine-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-8-æ€»ç»“-parameter-efficient-fine-tuning"}},[t._v("#")]),t._v(" 4.8 æ€»ç»“ Parameter-Efficient Fine-tuning")]),t._v(" "),a("ul",[a("li",[t._v("ğŸ¨ Benefit 1ï¼š"),a("strong",[t._v("Drastically decreases the task-specific parameters")]),t._v(".")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107214433435.png",alt:"image-20221107214433435"}})]),t._v(" "),a("p",[t._v("Adapter å’Œ LoRA çš„ percent trainable å·®è·å¾ˆå¤§çš„åŸå› åœ¨äº "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"r"}})],1)],1)],1),t._v(" çš„é€‰æ‹©èŒƒå›´ä¸å¤ªä¸€æ ·ï¼ŒAdapter å¾€å¾€é€‰ 16ã€32ã€64 è¿™ç§ï¼Œè€Œ LoRA å¾€å¾€é€‰ 1 æˆ–è€… 2ã€‚")],1),t._v(" "),a("p",[t._v("Soft Prompt å¾€å¾€éœ€è¦åœ¨ model å¾ˆå¤§çš„æ—¶å€™ï¼Œæ•ˆæœæ‰ä¼šæ¯”è¾ƒå¥½ï¼Œè€Œå…¶ä½™çš„åˆ™æ²¡æœ‰è¦æ±‚ model å¾ˆå¤§ã€‚")]),t._v(" "),a("ul",[a("li",[t._v("ğŸ¨ Benefit 2: "),a("strong",[t._v("Less easier to overfit on training data; better out-of-domain performance")]),t._v(".")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107215121305.png",alt:"image-20221107215121305"}})]),t._v(" "),a("p",[t._v("å¯ä»¥çœ‹åˆ°ï¼Œsoft prompt è™½ç„¶å‚æ•°æ¯”è¾ƒå°‘ï¼Œä½†æ˜¯æ•ˆæœè¿˜æ˜¯å¾ˆå¥½çš„ï¼Œå°½ç®¡åœ¨åé¢ä¸¤ä¸ª dataset ä¸Š performance ç•¥æœ‰é™ä½ï¼Œä½†ä¹Ÿæ²¡æœ‰é™ä½å¾ˆå¤šäº†ã€‚")]),t._v(" "),a("ul",[a("li",[t._v("ğŸ¨ Benefit 3: "),a("strong",[t._v("Fewer parameters to fine-tune; a good candidate when training with small dataset")]),t._v(".")])]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107215416800.png",alt:"image-20221107215416800"}})]),t._v(" "),a("p",[t._v("å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ low-resource çš„æƒ…å†µä¸‹å¯ä»¥è¡¨ç°æ›´å¥½ï¼Œè€Œåœ¨ high-resource çš„æƒ…å†µä¸‹ï¼Œå³ä½¿ç”¨äº†è¾ƒå°‘çš„å‚æ•°ï¼Œä½† performance ä¹Ÿæ²¡æœ‰æ‰å¤ªå¤šã€‚")]),t._v(" "),a("h3",{attrs:{id:"_4-9-early-exit"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-9-early-exit"}},[t._v("#")]),t._v(" 4.9 Early Exit")]),t._v(" "),a("p",[t._v("è¿™ä¸ªä¸»é¢˜çš„ç›®çš„ä¹Ÿæ˜¯æƒ³è¦å‡å°‘ downstream task çš„ parameters æ•°é‡ï¼Œä¸è¿‡å®ƒæ˜¯"),a("strong",[t._v("åŠ¨æ€å‡å°‘")]),t._v("çš„ã€‚")]),t._v(" "),a("p",[t._v("ä¼ ç»Ÿçš„ PLM æ˜¯ç”¨æœ€åä¸€å±‚çš„ hidden representation æ¥è®­ç»ƒä¸€ä¸ª classifierï¼Œè€Œ"),a("strong",[t._v("é—®é¢˜æ˜¯ä½¿ç”¨æ•´ä¸ªæ¨¡å‹æ¥åš inference å¤ªèŠ±æ—¶é—´äº†")]),t._v("ï¼Œäºæ˜¯æœ‰äººæå‡º Simpler data may require less effort to obtain the answer. äºæ˜¯æœ‰äº†è¿™ä¹ˆä¸€ä¸ªæƒ³æ³•ï¼š"),a("u",[t._v("Reduce the number of layers used during inference")]),t._v("ã€‚")]),t._v(" "),a("p",[t._v("è¿™æ ·çš„åšæ³•å°±æ˜¯åœ¨æ¯ä¸€å±‚ä¸ŠåŠ ä¸€ä¸ª classifierï¼š")]),t._v(" "),a("center",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107220211972.png",alt:"image-20221107220211972"}})]),t._v(" "),a("p",[t._v("ä½†è¿™æ ·çš„è¯ï¼Œç°åœ¨çš„é—®é¢˜å°±æ˜¯ï¼šHow do we know which classifier to use? è¿™å…¶å®æœ‰å¾ˆå¤šä¸åŒçš„åšæ³•ï¼Œè¿™é‡Œè®²ä¸€ä¸ªæœ€æ–°çš„åšæ³•ï¼š")]),t._v(" "),a("p",[t._v("æˆ‘ä»¬é¢å¤–åˆè®­ç»ƒä¸€ä¸ªå«åš "),a("strong",[t._v("Confidence predictor")]),t._v(" çš„ submoduleï¼Œè¿™ä¸ª predictor ä¼šæ ¹æ® classifier å’Œ hidden representation æ¥ predict è¯´è¿™ä¸ª classifier çš„ç»“æœå¤Ÿä¸å¤Ÿæœ‰ä¿¡å¿ƒï¼š")]),t._v(" "),a("p",[a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221107220613232.png",alt:"image-20221107220613232"}}),t._v("****")]),t._v(" "),a("p",[t._v("æ¯”å¦‚ä¸Šå›¾ä¸­ï¼Œåœ¨ç¬¬ä¸€å±‚çš„ classifier è¢«è®¤ä¸ºæ˜¯ä¸å¤Ÿæœ‰ä¿¡å¿ƒçš„ï¼Œäºæ˜¯ä¼šæ¥åˆ° classifier 2ï¼Œè¿™æ—¶ predictor è®¤ä¸ºæœ‰è¶³å¤Ÿä¿¡å¿ƒäº†ï¼Œäºæ˜¯å°±å¯ä»¥ç›´æ¥æ‹¿è¿™ä¸ª classifier çš„ output å½“åšæœ€ç»ˆçš„ outputï¼Œè€Œä¸éœ€è¦å†å»çœ‹åé¢çš„éƒ¨åˆ†äº†ã€‚")]),t._v(" "),a("p",[t._v("æ‰€ä»¥ "),a("strong",[t._v("Early exit reduces the inference time while keeping the performance")]),t._v("ã€‚")]),t._v(" "),a("h3",{attrs:{id:"_4-10-summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-10-summary"}},[t._v("#")]),t._v(" 4.10 Summary")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Parameter-efficient fine-tuning")]),t._v(": Reduce the task-specific parameters in downstream task.")]),t._v(" "),a("li",[a("strong",[t._v("Early exit")]),t._v(": Reduce the models that are involved during inference.")])]),t._v(" "),a("h2",{attrs:{id:"_5-closing-remarks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-closing-remarks"}},[t._v("#")]),t._v(" 5. Closing Remarks")]),t._v(" "),a("p",[t._v("What we address in this lecture:")]),t._v(" "),a("ul",[a("li",[t._v("Making PLM smaller, faster, and more parameter-efficient")]),t._v(" "),a("li",[t._v("Deploying PLMs when the labeled data in the downstream task is scarce")])]),t._v(" "),a("p",[t._v("The problems we discuss are just a small part of problems of PLMs, and the problems are not completely solved yet:")]),t._v(" "),a("ul",[a("li",[t._v("Why does self-supervised pre-training work")]),t._v(" "),a("li",[t._v("Interpretability of the model's prediction")]),t._v(" "),a("li",[t._v("Domain adaptation")]),t._v(" "),a("li",[t._v("Continual learning/lifelong learning")]),t._v(" "),a("li",[t._v("Security and privacy")])])],1)}),[],!1,null,null,null);e.default=s.exports}}]);