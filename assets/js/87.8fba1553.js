(window.webpackJsonp=window.webpackJsonp||[]).push([[87],{840:function(t,a,e){"use strict";e.r(a);var s=e(22),i=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h2",{attrs:{id:"_1-what-is-pre-train-model"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-what-is-pre-train-model"}},[t._v("#")]),t._v(" 1. What is pre-train model?")]),t._v(" "),e("h3",{attrs:{id:"_1-1-pre-train-model-的历史"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-pre-train-model-的历史"}},[t._v("#")]),t._v(" 1.1 Pre-train Model 的历史")]),t._v(" "),e("p",[t._v("以前，Pre-train Model 想要做的是：Represent each token by a embedding vector. 如下图所示：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910092744562.png",alt:"image-20220910092744562"}})]),t._v(" "),e("p",[t._v("以前所做的往往是 simply a table look-up，也就是静态查表，这有一个问题：The token with the same type has the same embedding.")]),t._v(" "),e("p",[t._v("上面所说的技术就有知名的 "),e("mark",[t._v("Word2vec")]),t._v(" [Mikolov,er al., NIPS’13]、"),e("mark",[t._v("Glove")]),t._v(" [Pennington, et al., EMNLP’14]。")]),t._v(" "),e("p",[t._v("除此之外还有什么技术呢？")]),t._v(" "),e("p",[t._v("如果你考虑的是英文，如果将 English word 作为 token 的话，英文单词实在太多了，这样静态查表总会有找不到的词汇。也许我们可以把 model 改成将英文 character 作为 input，输出就是一个 vector，这就是 "),e("mark",[t._v("FastText")]),t._v(" 做的：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"72%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910093518145.png",alt:"image-20220910093518145"}})]),t._v(" "),e("p",[t._v("如果考虑中文，那每一个中文其实也可以看做一个 image，然后丢到 CNN 里从而输出对应的 vector，这也许也是可以的：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910093735265.png",alt:"image-20220910093735265"}})]),t._v(" "),e("p",[t._v("上面所说的技术不会考虑到 context，比如同一个“狗”出现在“圈养狗”和“单身狗”中意思不是一样的。")]),t._v(" "),e("h3",{attrs:{id:"_1-2-contextualized-word-embedding"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-contextualized-word-embedding"}},[t._v("#")]),t._v(" 1.2 Contextualized Word Embedding")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910094424787.png",alt:"image-20220910094424787"}})]),t._v(" "),e("ul",[e("li",[t._v("Tree-based model 好像没有特别强，所以目前也用的不多。")])]),t._v(" "),e("h3",{attrs:{id:"_1-3-bigger-model"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-bigger-model"}},[t._v("#")]),t._v(" 1.3 Bigger Model")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"40%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/1365470-20211026224307862-217905674.png",alt:"1365470-20211026224307862-217905674"}})]),t._v(" "),e("h3",{attrs:{id:"_1-4-smaller-model"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-smaller-model"}},[t._v("#")]),t._v(" 1.4 Smaller Model")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910095704359.png",alt:"image-20220910095704359"}})]),t._v(" "),e("ul",[e("li",[t._v("这里面很出名的是 ALBERT")])]),t._v(" "),e("p",[t._v("这些让 BERT 变小的技术是 Network Compression。")]),t._v(" "),e("p",[t._v("还有一些在这些模型的 Network Architecture 上也有很多的突破：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910095915587.png",alt:"image-20220910095915587"}})]),t._v(" "),e("ul",[e("li",[t._v("Transformer-XL 解决了 BERT 一次只能读 512 个 token 的问题")]),t._v(" "),e("li",[t._v("Reformer 和 Longformer 是为了减少 self-attention 过程中的运算复杂度")])]),t._v(" "),e("h2",{attrs:{id:"_2-how-to-fine-tune"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-how-to-fine-tune"}},[t._v("#")]),t._v(" 2. How to fine-tune?")]),t._v(" "),e("h3",{attrs:{id:"_2-1-nlp-tasks"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-nlp-tasks"}},[t._v("#")]),t._v(" 2.1 NLP tasks")]),t._v(" "),e("p",[t._v("可以根据 input 和 output 的类型进行一个分类：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910100216657.png",alt:"image-20220910100216657"}})]),t._v(" "),e("h4",{attrs:{id:"_2-1-1-input"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-1-input"}},[t._v("#")]),t._v(" 2.1.1 Input")]),t._v(" "),e("p",[t._v("对于 multiple sentences 的情况，假如有两种不同类型的 sentence，可以在两者之间加一个特殊分隔符 "),e("code",[t._v("[SEP]")]),t._v("：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910100807708.png",alt:"image-20220910100807708"}})]),t._v(" "),e("p",[t._v("然后把它们丢到 model 里面就可以了。")]),t._v(" "),e("h4",{attrs:{id:"_2-1-2-output"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-2-output"}},[t._v("#")]),t._v(" 2.1.2 Output")]),t._v(" "),e("p",[t._v("output 有多个类型，我们逐一看一下。")]),t._v(" "),e("h5",{attrs:{id:"_1-one-class"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-one-class"}},[t._v("#")]),t._v(" 1）one class")]),t._v(" "),e("p",[t._v("一种做法如下图所示：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910101027092.png",alt:"image-20220910101027092"}})]),t._v(" "),e("ul",[e("li",[t._v("输入的时候加一个特别的 token："),e("code",[t._v("[CLS]")]),t._v("，pretrain 的时候就要告诉 model 当看到 [CLS] 就要产生一个与整个句子有关的 Embedding")]),t._v(" "),e("li",[t._v("然后把这个与整个句子有关的 Embedding 丢到一个 task specific model 中得到一个 class，这个 model 什么样要看任务有多复杂，但很多情况下直接是一个 linear transform 就可以了，或者多叠几层 linear transform。")])]),t._v(" "),e("p",[t._v("还有另外一种做法是将整个句子的 Embedding 都进行处理得到一个 class：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910101447795.png",alt:"image-20220910101447795"}})]),t._v(" "),e("h5",{attrs:{id:"_2-class-for-each-token"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-class-for-each-token"}},[t._v("#")]),t._v(" 2）class for each token")]),t._v(" "),e("p",[t._v("这种就是对每个 token 都给一个 class，做法如下图：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910101645179.png",alt:"image-20220910101645179"}})]),t._v(" "),e("ul",[e("li",[t._v("这里的 task specific model 可以是一个 LSTM，也可以是其他的。")])]),t._v(" "),e("h5",{attrs:{id:"_3-copy-from-input"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-copy-from-input"}},[t._v("#")]),t._v(" 3）copy from input")]),t._v(" "),e("p",[t._v("完全从 input 做 copy，这种类型的任务也没有很多，其中最经典的就是 Extraction-based QA，这个任务是：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910101915337.png",alt:"image-20220910101915337"}})]),t._v(" "),e("p",[t._v("原始的 BERT 的 paper 里提供了这种任务的解决方法，可以参考论文。")]),t._v(" "),e("h5",{attrs:{id:"_4-general-sequence"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-general-sequence"}},[t._v("#")]),t._v(" 4）general sequence")]),t._v(" "),e("p",[t._v("按照 seq2seq model 的设计，可以这样做：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910102404705.png",alt:"image-20220910102404705"}})]),t._v(" "),e("p",[t._v("但问题是，作为 decoder 的 task specific model 是完全没有 pretrain 过的，所以这样做也许不是最好的。")]),t._v(" "),e("p",[t._v("来看第二种版本：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910102738639.png",alt:"image-20220910102738639"}})]),t._v(" "),e("ul",[e("li",[t._v("这种做法就是输入 input sequence 后再输入一个 [SEP]，这时 Model 会输出与 [SEP] 相对应的 Embedding Vector，把这个 vector 输入到 task specific model 得到输出 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"3"}})],1)],1)],1)],1)],1),t._v("，然后接着把 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"3"}})],1)],1)],1)],1)],1),t._v(" 当做 input 得到 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"4"}})],1)],1)],1)],1)],1),t._v("，一直如此直到得到 "),e("code",[t._v("<EOS>")]),t._v("。")],1)]),t._v(" "),e("h3",{attrs:{id:"_2-2-how-to-fine-tune"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-how-to-fine-tune"}},[t._v("#")]),t._v(" 2.2 How to fine-tune")]),t._v(" "),e("p",[t._v("假设你有一些 task specific data，该怎样去 fine-tune 呢？这里有两种做法。")]),t._v(" "),e("p",[e("strong",[t._v("第一种做法")]),t._v("，固定住 pre-trained model 从而变成一个 feature extractor，然后我们只 fine-tune 那些 task specific 的部分：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910103323315.png",alt:"image-20220910103323315"}})]),t._v(" "),e("p",[e("strong",[t._v("第二种做法")]),t._v("，把 pre-trained model 和 task-specific model 合在一起 fine-tune，当成一个巨大的 model 来解这个 down-stream task：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910103554759.png",alt:"image-20220910103554759"}})]),t._v(" "),e("p",[t._v("在以前，巨大 model 在 train 时很容易 overfitting，但第二种做法由于只有 task-specific 的 param 是随机初始化的，pre-trained model 的 param 并不是随机初始化的，所以也许这种方式并没有那么容易 overfitting。在一些文献中指出，"),e("u",[t._v("第二种做法的 performance 往往比第一种要好一些")]),t._v("。")]),t._v(" "),e("h3",{attrs:{id:"_2-3-adaptor"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-adaptor"}},[t._v("#")]),t._v(" 2.3 Adaptor")]),t._v(" "),e("p",[t._v("刚刚讲的第二种 fine-tune 方法有一个问题，对每一个 task specific 进行 fine-tune 后，pretrained model 会变得不一样：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910105412511.png",alt:"image-20220910105412511"}})]),t._v(" "),e("p",[t._v("这样每个任务都需要存一个新的 model，而这些 model 往往非常巨大，所以这可能行不通的，因此有了 Adaptor 的概念。也就是说，我们能不能只能调 pretrained model 的一部分就好了，于是我们在 pretrained model 里面加了一个很小的 layer，这些 layer 就叫做 "),e("mark",[t._v("Adaptor")]),t._v("，下图用 Apt 来简称。这样 fine-tune 时只调整 Pretrained Model 的 Adaptor 部分，这样存储时就只需要存一份 pretrained model 的主体部分，从而减小存储压力：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910105923387.png",alt:"image-20220910105923387"}})]),t._v(" "),e("p",[t._v("这边举一个使用 Adaptor 的例子，当然还有很多其他做法：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910110135189.png",alt:"image-20220910110135189"}})]),t._v(" "),e("ul",[e("li",[t._v("pretrain 的时候是没有 Adaptor 的，而是在准备 fine-tune 时才加入并只调整 Adaptor 的参数。")])]),t._v(" "),e("p",[t._v("这个例子的表现结果如下：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910110516588.png",alt:"image-20220910110516588"}})]),t._v(" "),e("ul",[e("li",[t._v("Accuracy delta 中的 0 代表当我们 fine-tune 整个 model 时的 performance")]),t._v(" "),e("li",[t._v("蓝色这条线表示越往右边微调参数越多")])]),t._v(" "),e("h3",{attrs:{id:"_2-4-weighted-features"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-weighted-features"}},[t._v("#")]),t._v(" 2.4 Weighted Features")]),t._v(" "),e("p",[t._v("我们之前是把 input sequence 后扔进整个 model 后，拿到最后的 Embedding 输给 down-stream task layer 中。但还有一种做法，因为每一层他所抽取的资讯是不一样的，所以一种做法是"),e("strong",[t._v("把不同层的 feature 给 weighted sum 起来得到一个新的 embedding")]),t._v("，这个 embedding vector 同时综合了多层抽取的资讯，然后再把它丢到 down-stream 中：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910111338745.png",alt:"image-20220910111338745"}})]),t._v(" "),e("p",[t._v("这里的 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msup",[e("mjx-mi",{staticClass:"mjx-i"},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1),e("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[e("mjx-utext",{staticStyle:{"font-family":"serif"},attrs:{variant:"normal"}},[t._v("、")])],1),e("mjx-msup",{attrs:{space:"4"}},[e("mjx-mi",{staticClass:"mjx-i"},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"2"}})],1)],1)],1),e("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[e("mjx-c",{attrs:{c:"2026"}})],1)],1)],1),t._v(" 该设为多少呢？它们可以被视为 task specific layer 的参数的一部分从而一起 learn 出来。")],1),t._v(" "),e("h2",{attrs:{id:"_3-why-pre-train-models"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-why-pre-train-models"}},[t._v("#")]),t._v(" 3. Why Pre-train Models?")]),t._v(" "),e("p",[t._v("GLUE 是检测一个模型了解人类语言的能力：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910135932970.png",alt:"image-20220910135932970"}})]),t._v(" "),e("ul",[e("li",[t._v("黑色的这条线表示人类理解这个数据集的能力，可以看到后面提出的 pretrain model 都至少可以在这个 corpus 上超越人类的 performance 了。")])]),t._v(" "),e("p",[t._v("有很多 paper 讨论了为什么 pretrain model 是有效的，这里选其中一篇来讲解。这里选了 arxiv 上 1908.05620 这一篇，分析其中的两个结果")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"75%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910140557668.png",alt:"image-20220910140557668"}})]),t._v(" "),e("ul",[e("li",[t._v("虚线代表没有 pretrain 的 model，实线代表有 pretrain 的 model，它们的 model 大小是一样的。")]),t._v(" "),e("li",[t._v("可以看到，有 pretrain 的 model 在 training 时 training loss 下降的非常快。")])]),t._v(" "),e("p",[t._v("那只看 training loss 是不是有可能是因为 pretrain model 会 overfitting 呢？它在面对新的数据时 generalize 的能力如何呢？我们来看下图：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220910161032304.png",alt:"image-20220910161032304"}})]),t._v(" "),e("ul",[e("li",[t._v("可以看到，fine-tuning BERT 所处在的 local minima 是一个盆地，而左图是一个峡谷。一般来说，local minima 处在盆地时的泛化能力是要比处在峡谷时要强的。")])]),t._v(" "),e("h2",{attrs:{id:"_4-how-to-pre-train"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-how-to-pre-train"}},[t._v("#")]),t._v(" 4. How to Pre-train?")]),t._v(" "),e("p",[t._v("这章讲如何得到 pre-train 的模型。")]),t._v(" "),e("p",[t._v("我们希望什么样的 pre-train 的 model 呢？我们希望它能把 token sequence 吃进去，然后把每个 token 变成一个 embedding vector，而且希望这些 embedding vector 是 contextulize 的，即考虑上下文的。")]),t._v(" "),e("h3",{attrs:{id:"_4-1-pre-training-by-translation"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-pre-training-by-translation"}},[t._v("#")]),t._v(" 4.1 Pre-training by Translation")]),t._v(" "),e("p",[t._v("像这种抽取 contextulize 的 embedding 的方法最早是 "),e("mark",[t._v("CoVe")]),t._v(" 这篇 paper，它是通过 translation 而不是现在常用的 unsupervised learning 的方法得到的这个 model：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220911105537473.png",alt:"image-20220911105537473"}})]),t._v(" "),e("ul",[e("li",[t._v("把这个 model 当作是 translation 的 Encoder，最终训练好 Encoder 和 Decoder，这里的 Encoder 就是我们 pretrain 好的 contextulize word embedding 的 model。")])]),t._v(" "),e("p",[t._v("这篇 paper 选择 translation 也是有合理性的，因为他会把input sequence 里面的资讯都如实呈现到输出里面，而像 summarize 之类的任务就不行。但这种方式的问题是收集大量的 pair data 作为 training data 是很困难的，于是就有了之后的 unsupervised 的方法，现在也常称为 self-supervised 方法。")]),t._v(" "),e("h3",{attrs:{id:"_4-2-self-supervised-learning"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-self-supervised-learning"}},[t._v("#")]),t._v(" 4.2 Self-supervised Learning")]),t._v(" "),e("p",[t._v("Self-supervised Learning 是 Yann LeCun 在 Twitter 上提出的，其基本概念如下：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220911110848667.png",alt:"image-20220911110848667"}})]),t._v(" "),e("h3",{attrs:{id:"_4-3-predict-next-token"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-predict-next-token"}},[t._v("#")]),t._v(" 4.3 Predict Next Token")]),t._v(" "),e("p",[t._v("给这个 model 一个 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v(" 得到 representation "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"h"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v("，然后用 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"h"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v(" 来预测下一个 token "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"2"}})],1)],1)],1)],1)],1),t._v("。怎样从 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"h"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v(" 预测 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"2"}})],1)],1)],1)],1)],1),t._v(" 呢，如下图：")],1),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220911111325008.png",alt:"image-20220911111325008"}})]),t._v(" "),e("p",[t._v("这样就用从 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-TeXAtom",{attrs:{size:"s"}},[e("mjx-mi",{staticClass:"mjx-i"},[e("mjx-c",{attrs:{c:"i"}})],1),e("mjx-mo",{staticClass:"mjx-n"},[e("mjx-c",{attrs:{c:"2212"}})],1),e("mjx-mn",{staticClass:"mjx-n"},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1)],1),t._v(" 预测 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"i"}})],1)],1)],1)],1)],1),t._v(" 这个任务来训练 model：")],1),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"63%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220911111557442.png",alt:"image-20220911111557442"}})]),t._v(" "),e("p",[t._v("注意，在训练时"),e("strong",[t._v("不可以")]),t._v("让 model 一次把 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1),e("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[e("mjx-c",{attrs:{c:"223C"}})],1),e("mjx-msub",{attrs:{space:"4"}},[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"4"}})],1)],1)],1)],1)],1),t._v(" 同时读进去，然后让他预测 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"h"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1),e("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[e("mjx-c",{attrs:{c:"223C"}})],1),e("mjx-msub",{attrs:{space:"4"}},[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"h"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"4"}})],1)],1)],1)],1)],1),t._v("，否则 model 可能直接把下一个 token 给输出出去，从而学不到什么东西。")],1),t._v(" "),e("p",[t._v("以上所讲的 "),e("mark",[t._v("Predict Next Token")]),t._v(" 任务是最早的 unsupervised pretrain 技术，这样得到的 model 就是一个 language model（"),e("strong",[t._v("LM")]),t._v("）。")]),t._v(" "),e("p",[t._v("这个 model 可以使用 LSTM，也可以使用 Self-attention。使用 LSTM 的 language model 有 ELMo、ULMFiT 等，使用 Self-attention 的有 GPT、Megatron、Turing NLG 等。")]),t._v(" "),e("p",[t._v("使用 Self-Attention 作为 model 来做 predict next token 时，注意要给 self-attention 加一个 constraint，不能让它看到后面的，比如 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"2"}})],1)],1)],1)],1)],1),t._v(" 位置只能 attend 到 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1),t._v(" 和 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"2"}})],1)],1)],1)],1)],1),t._v("，而不能 attend 到 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"3"}})],1)],1)],1)],1)],1),t._v(" 及 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"4"}})],1)],1)],1)],1)],1),t._v("，从而防止它看到它不该看的以后的答案：")],1),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220911112705093.png",alt:"image-20220911112705093"}})]),t._v(" "),e("h3",{attrs:{id:"_4-4-predict-next-token-bidirectional"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-predict-next-token-bidirectional"}},[t._v("#")]),t._v(" 4.4 Predict Next Token - Bidirectional")]),t._v(" "),e("p",[t._v("刚刚讲的最终得到的 contextualize representation 只考通过 predict next token 得到的，而且是只考虑了 left context，并没有考虑 right context。")]),t._v(" "),e("p",[e("mark",[t._v("ELMo")]),t._v(" 就是同时考虑了 left context 和 right context 用来得到一个 token 的 contextualize representation：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220912225943109.png",alt:"image-20220912225943109"}})]),t._v(" "),e("ul",[e("li",[t._v("它有一个由左向右的 LSTM，看 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"1"}})],1)],1)],1),e("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[e("mjx-c",{attrs:{c:"223C"}})],1),e("mjx-msub",{attrs:{space:"4"}},[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"4"}})],1)],1)],1)],1)],1),t._v("  去预测 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"5"}})],1)],1)],1)],1)],1),t._v("；又有一个由右向左的 LSTM，看 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"7"}})],1)],1)],1),e("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[e("mjx-c",{attrs:{c:"223C"}})],1),e("mjx-msub",{attrs:{space:"4"}},[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"5"}})],1)],1)],1)],1)],1),t._v(" 来预测 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"4"}})],1)],1)],1)],1)],1),t._v("。")],1),t._v(" "),e("li",[t._v("然后 ELMo 把正向的 LSTM 和逆向的 LSTM 输出的 vector 给 concatenate 起来，当作代表 "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"4"}})],1)],1)],1)],1)],1),t._v(" 的 contextualize representation。")],1)]),t._v(" "),e("p",[t._v("所以说 ELMo 通过两个方向的 LSTM 来考虑了一个 token 的 left context 和 right context。但这样还不够，因为 machine 在看 left context 进行 encoding 时没有看到 right context，即两次 encoding 的过程都只是看到句子的一半而非全部，两个 LSTM 得到的 vector 是没有交互的。")]),t._v(" "),e("h3",{attrs:{id:"_4-5-masking-input"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-masking-input"}},[t._v("#")]),t._v(" 4.5 Masking Input")]),t._v(" "),e("p",[t._v("BERT 弥补了刚刚讲的 ELMo 的 encoding 过程没有左右 context 交互的问题，而且 BERT 做的也不再是 predict next token，而是 masking input：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220912231915822.png",alt:"image-20220912231915822"}})]),t._v(" "),e("ul",[e("li",[t._v("BERT 对 input sequence 的一些 token 给 masking 掉，对 masking 的部分有随机两种做法：一种是替换成一个 special token [MASK]，一种是随机 sample 一个 token 替换到这里。")]),t._v(" "),e("li",[t._v("然后用所 masking 掉的部分输出的 vector 来预测 masking 掉的是哪个 token。")])]),t._v(" "),e("p",[t._v("BERT 用的 Model 是 Transformer Encoder 堆叠起来的。")]),t._v(" "),e("blockquote",[e("p",[t._v("其实考古一下的话，Word2Vec 的 CBOW 模型的 training 过程就与 BERT 很像，只不过 BERT 内部结构更加复杂，所考虑的东西也更多了。")])]),t._v(" "),e("p",[t._v("原始 BERT 中要 masking 掉哪些位置是随机决定的，但这不一定很好。具体改进的做法有：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220912232846634.png",alt:"image-20220912231915822"}})]),t._v(" "),e("ul",[e("li",[t._v("上面的 WWM 是 masking 掉一整词，防止出现要预测“黑 [MASK] 江”这种简单的任务；")]),t._v(" "),e("li",[t._v("下面是指讲 entity 先识别出来，然后 masking 掉 entity，这么做的就是 ERNIE。")])]),t._v(" "),e("p",[t._v("还有一种 masking 的方法叫做 "),e("mark",[t._v("SpanBert")]),t._v("，它就是一次 masking 掉很长的一个范围，原来的 BERT 只是每次随机选一个 token 来 masking 掉。SpanBert 每次盖住多长是有一个几率分布：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220912233424453.png",alt:"image-20220912233424453"}})]),t._v(" "),e("p",[t._v("这篇 paper 也对比多不同类型的 masking 方法的效果：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220912233711412.png",alt:"image-20220912233711412"}})]),t._v(" "),e("ul",[e("li",[t._v("Geometric Spans 就是 SpanBert 提出的 masking 方法。")])]),t._v(" "),e("h3",{attrs:{id:"_4-6-span-boundary-objective-sbo"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-6-span-boundary-objective-sbo"}},[t._v("#")]),t._v(" 4.6 Span Boundary Objective（SBO）")]),t._v(" "),e("p",[t._v("SpanBert 同时提出了一个新的预训练方法：Span Boundary Objective（"),e("mark",[t._v("SBO")]),t._v("）。做法如下：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220912234424681.png",alt:"image-20220912233424453"}})]),t._v(" "),e("ul",[e("li",[t._v("先 masking 一个范围，同时有一个 SBO 的 model，它把这个所 masking 部分的左右两边的 token 吃进去，同时给 SBO model 一个数字 2，这个数字表示要预测所 masking 掉 span 里的第 2 个 token "),e("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[e("mjx-math",{staticClass:" MJX-TEX"},[e("mjx-msub",[e("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[e("mjx-c",{attrs:{c:"w"}})],1),e("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[e("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[e("mjx-c",{attrs:{c:"5"}})],1)],1)],1)],1)],1)],1)]),t._v(" "),e("p",[t._v("这个训练方法也许看上去匪夷所思，其实这种设计所期待的是：一个 span 的左右两边的 token 可以包含它内部整个 span 的资讯。为什么这样呢？以后讲到 coreference 时会有用处。")]),t._v(" "),e("h3",{attrs:{id:"_4-7-xlnet"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-xlnet"}},[t._v("#")]),t._v(" 4.7 XLNet")]),t._v(" "),e("p",[t._v("“XL” 指的是 Transformer-XL，具体是什么可以参考 paper。")]),t._v(" "),e("p",[t._v("以往的 predict next token 是根据 left context 去 predict 下一个  token，而 XLNet 是把 input sequence 里面的 token 给随机打乱，比如下图中的下面部分：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913084531392.png",alt:"image-20220913084531392"}})]),t._v(" "),e("ul",[e("li",[t._v("下面就是把“深度学习”打乱成“习度学深”，然后让 model 根据“习度”去预测“学”。")])]),t._v(" "),e("p",[t._v("另外，原始 BERT 是根据整个句子的资讯加上 mask 掉的 [MASK] 本身去预测 mask 掉的 token，如下图的上面部分所示。而 XLNet 是只根据 sentence 的一部分而非全部来预测，而且到底是根据哪些部分是随机决定的，还有一个特别的是它不会给 model 看到 mask 的部分（但也会给它 positional information），如下图的下面部分所示：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913085318325.png",alt:"image-20220913085318325"}})]),t._v(" "),e("p",[t._v("其实 XLNet 为了实现上面所说的，在架构上也做了很多改变，具体可参考原 paper。")]),t._v(" "),e("h3",{attrs:{id:"_4-8-mass-bart"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-8-mass-bart"}},[t._v("#")]),t._v(" 4.8 MASS / BART")]),t._v(" "),e("p",[t._v("其实 BERT 本身有点不善言辞，也就是说它不太适合 generation 的任务。而我们想把它用于 sequence-to-sequence，就要让它具有产生句子的能力，也就是”Given paritial sequence, predict the next token“。但 BERT 的训练任务却是从来没有只看 partial sequence 来 predict。")]),t._v(" "),e("p",[t._v("下面我们的讨论只局限于 autoregressive model 的情况下，即根据前面的 sequence 来产生下一个 token，由左向右地产生，而不讨论 non-autoregressive 的情况。")]),t._v(" "),e("p",[t._v("BERT 本质是一个 encoder，不太适合 seq2seq 的任务，所以我们可以直接 pretain 一个 seq2seq 的 model：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913091212560.png",alt:"image-20220913091212560"}})]),t._v(" "),e("p",[t._v("但要注意，我们"),e("strong",[t._v("要对 input 的做某种程度的破坏")]),t._v("，否则这个 seq2seq model 学不到什么东西。怎么来对 input 进行破坏呢，这里有两篇 paper 来探讨这个事情：")]),t._v(" "),e("ul",[e("li",[t._v("MAsked Sequence to Sequence pre-training （"),e("mark",[t._v("MASS")]),t._v("）")]),t._v(" "),e("li",[t._v("Bidirectional and Auto-Regressive Transformers （"),e("mark",[t._v("BART")]),t._v("）")])]),t._v(" "),e("p",[t._v("那么他俩做的是什么事呢？MASS 的想法与 BERT 很像，就是随机把一些地方 mask 掉，实际上原始 MASS 的 paper 只要求能 reconstruct 一开始 mask 掉的部分就可以了：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913091815205.png",alt:"image-20220913091815205.png"}})]),t._v(" "),e("p",[t._v("在 BART 里面还提出了各式各样的方法，比如 delete 掉一个 token、做 permutation、做 rotation（即改变起始位置）、做 Text Infilling（随机插一个 [MASK] 来误导 model）：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"63%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913092204603.png",alt:"image-20220913092204603"}})]),t._v(" "),e("p",[t._v("BART 做了这么方法，结果表明：")]),t._v(" "),e("ul",[e("li",[t._v("Permutation / Rotation do not perform well.")]),t._v(" "),e("li",[t._v("Text Infilling is consistenly good.")])]),t._v(" "),e("h3",{attrs:{id:"_4-9-unilm"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-9-unilm"}},[t._v("#")]),t._v(" 4.9 UniLM")]),t._v(" "),e("p",[t._v("UniLM 同时是 Encoder 和 Decoder，同时还是一个 seq2seq 的 model：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913092618180.png",alt:"image-20220913092618180"}})]),t._v(" "),e("p",[t._v("UniLM 不像之前 encoder 和 decoder 拆开，而是只有一个 model 来做三种类型 pretrain：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913125600417.png",alt:"image-20220913125600417"}})]),t._v(" "),e("ul",[e("li",[t._v("既当作 BERT 一样训练，又当作 GPT 来训练，还当成一个 seq2seq 来训练。")])]),t._v(" "),e("h3",{attrs:{id:"_4-10-electra"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-10-electra"}},[t._v("#")]),t._v(" 4.10 ELECTRA")]),t._v(" "),e("p",[t._v("ELECTRA 做的是先将一个 sentence 中的某个 token 给 replace 掉，然后让 model 来判断每个输入的 token 是否有被 replace，比如我们将“the chef cooked the meal”中的 “cooked” 给 replace 成 “ate”：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913130327366.png",alt:"image-20220913130327366"}})]),t._v(" "),e("p",[t._v("但问题来了，怎么把一个词 replace 后可以语法上没有错但语义会怪怪的呢？因为太离谱的 replace 很容易就会被发现从而使 model 学不到什么东西。做法就是加一个 small BERT 来产生用来 replace 的 token：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913130652447.png",alt:"image-20220913130652447"}})]),t._v(" "),e("p",[t._v("注意，因为下面的这个 small BERT 不是要效果很好，希望它预测后有点错误。而且这不是一个 GAN。")]),t._v(" "),e("p",[t._v("神奇的是，ELECTRA 训练的效果还很好：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913131002607.png",alt:"image-20220913131002607"}})]),t._v(" "),e("ul",[e("li",[t._v("横轴是所需的计算量，纵轴是在 GLUE 上的得分")])]),t._v(" "),e("h3",{attrs:{id:"_4-11-sentence-level"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-11-sentence-level"}},[t._v("#")]),t._v(" 4.11 Sentence Level")]),t._v(" "),e("p",[t._v("有时候我们希望的不是给一个 token 一个 embedding，而是给一个 sentence 一个 embedding，也就是用一个 global embedding 来表示整个 input 的 token sequence。")]),t._v(" "),e("p",[t._v("基于“You shall know a sentence by the conpany it keeps” 的想法，有一个叫做 "),e("mark",[t._v("Skip Thought")]),t._v(" 的想法：有一个 seq2seq 的 model，encoder 读入一个 sentence 变成一个 vector，然后 decoder 用这个 vector 来预测输入 sentence 的下一个 sentence：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913131739146.png",alt:"image-20220913131739146"}})]),t._v(" "),e("p",[t._v("这样如果两个句子所接的下一句很像，那这两个 sentence 的 embedding 也应该很相近。")]),t._v(" "),e("p",[t._v("但我们说过，如果让 model 去生成东西的话，运算量就往往比较大，于是有了一个进阶版："),e("mark",[t._v("Quick Thought")]),t._v("：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913132033136.png",alt:"image-20220913132033136"}})]),t._v(" "),e("p",[t._v("这个方法是说，有两个 encoder，吃进去两个 sentence，得到两个 vector，如果两个 sentence 是相邻的话，那得到的两个 vector 越相近越好，反之则越远越好。从而避开了做”生成“这个事情。")]),t._v(" "),e("h3",{attrs:{id:"_4-12-nsp-sop"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-12-nsp-sop"}},[t._v("#")]),t._v(" 4.12 NSP -> SOP")]),t._v(" "),e("p",[t._v("原始 BERT 的 pretrain 中有一个任务是 NSP，指的是给 BERT 随便两个 sentence，通过 [CLS] 的输出来让 BERT 告诉我们这两句是否具有上下句关系：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913132901812.png",alt:"image-20220913132901812"}})]),t._v(" "),e("p",[t._v("后来 RoBERTa 等模型发现说 NSP 没什么用，于是墙倒众人推，很多人都说 NSP 没什么用。于是有了 "),e("mark",[t._v("SOP")]),t._v("（Sentence order prediction）任务，就是对给的两个相邻但可能颠倒前后顺序的 sentence，model 要告诉我们给的第一句是否是给的第二句的在语义上的前一句，是就回答 Yes，不是就回答 None。这个方法用在了 "),e("mark",[t._v("ALBERT")]),t._v(" 上。")]),t._v(" "),e("p",[t._v("之所以 SOP 比 NSP 有用，也许是因为 NSP 这个任务本身很简单，而 SOP 相比较来说更难一些。")]),t._v(" "),e("h3",{attrs:{id:"_4-13-t5"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-13-t5"}},[t._v("#")]),t._v(" 4.13 T5")]),t._v(" "),e("p",[t._v("讲了这么多 pretrain 的方法，哪种最好呢？Google 就展现了自己雄厚的财力，把当时几乎所有 pretrain 的方法都做了一遍，发表了 T5 这篇 paper，它长达五十几页。")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913133753191.png",alt:"image-20220913133753191"}})]),t._v(" "),e("ul",[e("li",[t._v("paper 叫做 T5，用的训练数据集叫做 C4。命名大师！")])]),t._v(" "),e("h3",{attrs:{id:"_4-14-others"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-14-others"}},[t._v("#")]),t._v(" 4.14 Others")]),t._v(" "),e("p",[t._v("除了刚刚提到的 ERNIE，还有另外一个同名的 ERNIE：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913135117986.png",alt:"image-20220913135117986"}})]),t._v(" "),e("p",[t._v("另外，还有一种语音版的 BERT，即 Audio BERT：")]),t._v(" "),e("center",[e("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220913135227152.png",alt:"image-20220913135227152"}})]),t._v(" "),e("h2",{attrs:{id:"_5-multilingual-bert"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-multilingual-bert"}},[t._v("#")]),t._v(" 5. Multilingual BERT")])],1)}),[],!1,null,null,null);a.default=i.exports}}]);