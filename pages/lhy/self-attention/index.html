<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Self-Attention | notebook</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="icon" href="/notebook/img/favicon.ico">
    <script data-ad-client="ca-pub-7828333725993554" async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="学习笔记">
    <meta name="keywords" content="全栈学习笔记">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/notebook/assets/css/0.styles.1b58b254.css" as="style"><link rel="preload" href="/notebook/assets/js/app.2bf3b6c1.js" as="script"><link rel="preload" href="/notebook/assets/js/2.0ad58009.js" as="script"><link rel="preload" href="/notebook/assets/js/80.d325f684.js" as="script"><link rel="prefetch" href="/notebook/assets/js/10.99522837.js"><link rel="prefetch" href="/notebook/assets/js/100.e3b56889.js"><link rel="prefetch" href="/notebook/assets/js/101.6ea1d00b.js"><link rel="prefetch" href="/notebook/assets/js/102.eca9dfbd.js"><link rel="prefetch" href="/notebook/assets/js/103.6ea477d4.js"><link rel="prefetch" href="/notebook/assets/js/104.ac820d2b.js"><link rel="prefetch" href="/notebook/assets/js/105.58b259a8.js"><link rel="prefetch" href="/notebook/assets/js/106.a86005d0.js"><link rel="prefetch" href="/notebook/assets/js/107.7a79d36f.js"><link rel="prefetch" href="/notebook/assets/js/108.64404e25.js"><link rel="prefetch" href="/notebook/assets/js/109.75f12c0a.js"><link rel="prefetch" href="/notebook/assets/js/11.d26d59e4.js"><link rel="prefetch" href="/notebook/assets/js/110.1155fe36.js"><link rel="prefetch" href="/notebook/assets/js/111.bf8b5871.js"><link rel="prefetch" href="/notebook/assets/js/112.22833ceb.js"><link rel="prefetch" href="/notebook/assets/js/113.6a080233.js"><link rel="prefetch" href="/notebook/assets/js/114.35de9701.js"><link rel="prefetch" href="/notebook/assets/js/115.f598d8c2.js"><link rel="prefetch" href="/notebook/assets/js/116.e3bd29ce.js"><link rel="prefetch" href="/notebook/assets/js/117.c3c02abc.js"><link rel="prefetch" href="/notebook/assets/js/118.136a552a.js"><link rel="prefetch" href="/notebook/assets/js/119.c124f3f8.js"><link rel="prefetch" href="/notebook/assets/js/12.dc66c4f2.js"><link rel="prefetch" href="/notebook/assets/js/120.f835d124.js"><link rel="prefetch" href="/notebook/assets/js/121.367716ae.js"><link rel="prefetch" href="/notebook/assets/js/122.752b0493.js"><link rel="prefetch" href="/notebook/assets/js/123.9f8d6026.js"><link rel="prefetch" href="/notebook/assets/js/124.e8eb61b6.js"><link rel="prefetch" href="/notebook/assets/js/125.cb081200.js"><link rel="prefetch" href="/notebook/assets/js/126.ab87d911.js"><link rel="prefetch" href="/notebook/assets/js/127.ffdbe74d.js"><link rel="prefetch" href="/notebook/assets/js/128.ec526e42.js"><link rel="prefetch" href="/notebook/assets/js/129.71839012.js"><link rel="prefetch" href="/notebook/assets/js/13.32e95b42.js"><link rel="prefetch" href="/notebook/assets/js/130.2bc0bb4d.js"><link rel="prefetch" href="/notebook/assets/js/131.5595b49b.js"><link rel="prefetch" href="/notebook/assets/js/132.4963c5c4.js"><link rel="prefetch" href="/notebook/assets/js/133.44f48cfd.js"><link rel="prefetch" href="/notebook/assets/js/134.cf25626c.js"><link rel="prefetch" href="/notebook/assets/js/135.5ee30fa9.js"><link rel="prefetch" href="/notebook/assets/js/136.bc43f8e6.js"><link rel="prefetch" href="/notebook/assets/js/137.9ab5beac.js"><link rel="prefetch" href="/notebook/assets/js/138.692a33e6.js"><link rel="prefetch" href="/notebook/assets/js/139.08e7c98d.js"><link rel="prefetch" href="/notebook/assets/js/14.c418d170.js"><link rel="prefetch" href="/notebook/assets/js/140.39a861db.js"><link rel="prefetch" href="/notebook/assets/js/141.46678413.js"><link rel="prefetch" href="/notebook/assets/js/142.f7ef5eac.js"><link rel="prefetch" href="/notebook/assets/js/143.c92cbac1.js"><link rel="prefetch" href="/notebook/assets/js/144.d9c61437.js"><link rel="prefetch" href="/notebook/assets/js/145.9f603b31.js"><link rel="prefetch" href="/notebook/assets/js/146.b875f045.js"><link rel="prefetch" href="/notebook/assets/js/147.55e7c4f8.js"><link rel="prefetch" href="/notebook/assets/js/148.4410c365.js"><link rel="prefetch" href="/notebook/assets/js/149.6096ed98.js"><link rel="prefetch" href="/notebook/assets/js/15.e0e7392a.js"><link rel="prefetch" href="/notebook/assets/js/150.24451f07.js"><link rel="prefetch" href="/notebook/assets/js/151.7cff301c.js"><link rel="prefetch" href="/notebook/assets/js/152.035fee1f.js"><link rel="prefetch" href="/notebook/assets/js/153.c61f8ec3.js"><link rel="prefetch" href="/notebook/assets/js/154.7bb549d0.js"><link rel="prefetch" href="/notebook/assets/js/155.1dc494db.js"><link rel="prefetch" href="/notebook/assets/js/156.b87eaf39.js"><link rel="prefetch" href="/notebook/assets/js/157.e3f5a5c0.js"><link rel="prefetch" href="/notebook/assets/js/158.c565c699.js"><link rel="prefetch" href="/notebook/assets/js/159.a22609ef.js"><link rel="prefetch" href="/notebook/assets/js/16.d1aef4ee.js"><link rel="prefetch" href="/notebook/assets/js/160.b29e761c.js"><link rel="prefetch" href="/notebook/assets/js/161.bee1e522.js"><link rel="prefetch" href="/notebook/assets/js/162.c49fca62.js"><link rel="prefetch" href="/notebook/assets/js/163.2cb4d37d.js"><link rel="prefetch" href="/notebook/assets/js/164.4a0dbc64.js"><link rel="prefetch" href="/notebook/assets/js/165.490d05b3.js"><link rel="prefetch" href="/notebook/assets/js/166.df5d2527.js"><link rel="prefetch" href="/notebook/assets/js/167.89a81814.js"><link rel="prefetch" href="/notebook/assets/js/168.9991702e.js"><link rel="prefetch" href="/notebook/assets/js/169.2f9a5dce.js"><link rel="prefetch" href="/notebook/assets/js/17.88ae5445.js"><link rel="prefetch" href="/notebook/assets/js/170.5f23eb3c.js"><link rel="prefetch" href="/notebook/assets/js/171.c521aaa8.js"><link rel="prefetch" href="/notebook/assets/js/172.42110b0a.js"><link rel="prefetch" href="/notebook/assets/js/173.5e36f1bf.js"><link rel="prefetch" href="/notebook/assets/js/174.f48e078a.js"><link rel="prefetch" href="/notebook/assets/js/175.775da6a5.js"><link rel="prefetch" href="/notebook/assets/js/176.9c3c55ea.js"><link rel="prefetch" href="/notebook/assets/js/177.b54d1cff.js"><link rel="prefetch" href="/notebook/assets/js/178.ff08b7f5.js"><link rel="prefetch" href="/notebook/assets/js/179.c6a1af32.js"><link rel="prefetch" href="/notebook/assets/js/18.dcb78196.js"><link rel="prefetch" href="/notebook/assets/js/180.25dd9eba.js"><link rel="prefetch" href="/notebook/assets/js/181.13e6ec84.js"><link rel="prefetch" href="/notebook/assets/js/182.f6849f0d.js"><link rel="prefetch" href="/notebook/assets/js/183.7e664874.js"><link rel="prefetch" href="/notebook/assets/js/184.e6aba86f.js"><link rel="prefetch" href="/notebook/assets/js/185.df07b919.js"><link rel="prefetch" href="/notebook/assets/js/186.02c77e75.js"><link rel="prefetch" href="/notebook/assets/js/187.e8380ed4.js"><link rel="prefetch" href="/notebook/assets/js/188.eddc8bee.js"><link rel="prefetch" href="/notebook/assets/js/189.fbc1840f.js"><link rel="prefetch" href="/notebook/assets/js/19.5997a514.js"><link rel="prefetch" href="/notebook/assets/js/190.a37bfe4c.js"><link rel="prefetch" href="/notebook/assets/js/191.e53a3d4b.js"><link rel="prefetch" href="/notebook/assets/js/192.2f5be408.js"><link rel="prefetch" href="/notebook/assets/js/193.4ca6de49.js"><link rel="prefetch" href="/notebook/assets/js/194.b8e51d9d.js"><link rel="prefetch" href="/notebook/assets/js/195.70e6b23a.js"><link rel="prefetch" href="/notebook/assets/js/196.5d5fbf2d.js"><link rel="prefetch" href="/notebook/assets/js/197.78456dab.js"><link rel="prefetch" href="/notebook/assets/js/198.4308331c.js"><link rel="prefetch" href="/notebook/assets/js/199.2e537849.js"><link rel="prefetch" href="/notebook/assets/js/20.fc057fd7.js"><link rel="prefetch" href="/notebook/assets/js/200.b3309bbf.js"><link rel="prefetch" href="/notebook/assets/js/201.4723461c.js"><link rel="prefetch" href="/notebook/assets/js/202.b15b5177.js"><link rel="prefetch" href="/notebook/assets/js/203.22c50e61.js"><link rel="prefetch" href="/notebook/assets/js/204.5b8b3b00.js"><link rel="prefetch" href="/notebook/assets/js/205.54ee7630.js"><link rel="prefetch" href="/notebook/assets/js/206.f3f20f94.js"><link rel="prefetch" href="/notebook/assets/js/207.a9608973.js"><link rel="prefetch" href="/notebook/assets/js/208.1a80a593.js"><link rel="prefetch" href="/notebook/assets/js/209.586fd293.js"><link rel="prefetch" href="/notebook/assets/js/21.cb4205ee.js"><link rel="prefetch" href="/notebook/assets/js/210.7829dd53.js"><link rel="prefetch" href="/notebook/assets/js/211.3ce139ab.js"><link rel="prefetch" href="/notebook/assets/js/212.84738a64.js"><link rel="prefetch" href="/notebook/assets/js/213.a631830d.js"><link rel="prefetch" href="/notebook/assets/js/214.9d64cf85.js"><link rel="prefetch" href="/notebook/assets/js/215.87030b6b.js"><link rel="prefetch" href="/notebook/assets/js/216.ddbe1944.js"><link rel="prefetch" href="/notebook/assets/js/217.16ae7e40.js"><link rel="prefetch" href="/notebook/assets/js/218.e7780d65.js"><link rel="prefetch" href="/notebook/assets/js/219.abae5e09.js"><link rel="prefetch" href="/notebook/assets/js/22.256014b4.js"><link rel="prefetch" href="/notebook/assets/js/220.8e3a8702.js"><link rel="prefetch" href="/notebook/assets/js/221.4c279d74.js"><link rel="prefetch" href="/notebook/assets/js/222.6c9b2595.js"><link rel="prefetch" href="/notebook/assets/js/223.cc072424.js"><link rel="prefetch" href="/notebook/assets/js/224.c663b40f.js"><link rel="prefetch" href="/notebook/assets/js/225.f3e52654.js"><link rel="prefetch" href="/notebook/assets/js/226.5e00402c.js"><link rel="prefetch" href="/notebook/assets/js/227.1c28ce97.js"><link rel="prefetch" href="/notebook/assets/js/228.42b8c305.js"><link rel="prefetch" href="/notebook/assets/js/229.df9760ec.js"><link rel="prefetch" href="/notebook/assets/js/23.a3d7d66a.js"><link rel="prefetch" href="/notebook/assets/js/230.cfe18f05.js"><link rel="prefetch" href="/notebook/assets/js/231.3a664a46.js"><link rel="prefetch" href="/notebook/assets/js/232.966ce9dc.js"><link rel="prefetch" href="/notebook/assets/js/233.fc06cb57.js"><link rel="prefetch" href="/notebook/assets/js/234.7bb9b7d4.js"><link rel="prefetch" href="/notebook/assets/js/235.b336116e.js"><link rel="prefetch" href="/notebook/assets/js/236.03a38f77.js"><link rel="prefetch" href="/notebook/assets/js/237.0dbda856.js"><link rel="prefetch" href="/notebook/assets/js/238.c1c19749.js"><link rel="prefetch" href="/notebook/assets/js/239.046875c1.js"><link rel="prefetch" href="/notebook/assets/js/24.8e5e267e.js"><link rel="prefetch" href="/notebook/assets/js/240.4bd9cdc0.js"><link rel="prefetch" href="/notebook/assets/js/241.c3dc5804.js"><link rel="prefetch" href="/notebook/assets/js/242.db0b1a91.js"><link rel="prefetch" href="/notebook/assets/js/243.4d9bd61d.js"><link rel="prefetch" href="/notebook/assets/js/244.ee57770b.js"><link rel="prefetch" href="/notebook/assets/js/245.02aab1c1.js"><link rel="prefetch" href="/notebook/assets/js/246.b76a18bb.js"><link rel="prefetch" href="/notebook/assets/js/247.75a673db.js"><link rel="prefetch" href="/notebook/assets/js/248.ad93f81d.js"><link rel="prefetch" href="/notebook/assets/js/249.fb75a938.js"><link rel="prefetch" href="/notebook/assets/js/25.b12f24fe.js"><link rel="prefetch" href="/notebook/assets/js/250.8395c0b6.js"><link rel="prefetch" href="/notebook/assets/js/251.16a6d2a4.js"><link rel="prefetch" href="/notebook/assets/js/252.ef3ee05e.js"><link rel="prefetch" href="/notebook/assets/js/253.78e3471e.js"><link rel="prefetch" href="/notebook/assets/js/254.a5783e07.js"><link rel="prefetch" href="/notebook/assets/js/255.2ab853f6.js"><link rel="prefetch" href="/notebook/assets/js/256.5430831b.js"><link rel="prefetch" href="/notebook/assets/js/257.99c8a0a4.js"><link rel="prefetch" href="/notebook/assets/js/258.4496955b.js"><link rel="prefetch" href="/notebook/assets/js/259.9152b1d2.js"><link rel="prefetch" href="/notebook/assets/js/26.0fce5172.js"><link rel="prefetch" href="/notebook/assets/js/260.072f65e6.js"><link rel="prefetch" href="/notebook/assets/js/261.0bca81af.js"><link rel="prefetch" href="/notebook/assets/js/262.9c9c5337.js"><link rel="prefetch" href="/notebook/assets/js/263.42470957.js"><link rel="prefetch" href="/notebook/assets/js/264.64b5f4fb.js"><link rel="prefetch" href="/notebook/assets/js/265.836a69c5.js"><link rel="prefetch" href="/notebook/assets/js/266.a00cdeb1.js"><link rel="prefetch" href="/notebook/assets/js/267.09dc5ae4.js"><link rel="prefetch" href="/notebook/assets/js/268.6fa6603e.js"><link rel="prefetch" href="/notebook/assets/js/269.3963ce5e.js"><link rel="prefetch" href="/notebook/assets/js/27.47ba3886.js"><link rel="prefetch" href="/notebook/assets/js/270.2826382d.js"><link rel="prefetch" href="/notebook/assets/js/271.3c746c23.js"><link rel="prefetch" href="/notebook/assets/js/272.30698dda.js"><link rel="prefetch" href="/notebook/assets/js/273.b06e3fd2.js"><link rel="prefetch" href="/notebook/assets/js/274.2016c7fa.js"><link rel="prefetch" href="/notebook/assets/js/275.f4aff624.js"><link rel="prefetch" href="/notebook/assets/js/276.e682aa74.js"><link rel="prefetch" href="/notebook/assets/js/277.0c3f41db.js"><link rel="prefetch" href="/notebook/assets/js/278.3c2d5251.js"><link rel="prefetch" href="/notebook/assets/js/279.a9af5703.js"><link rel="prefetch" href="/notebook/assets/js/28.6bac56c6.js"><link rel="prefetch" href="/notebook/assets/js/280.a5da28a3.js"><link rel="prefetch" href="/notebook/assets/js/281.8cc5a3ba.js"><link rel="prefetch" href="/notebook/assets/js/282.55227ff2.js"><link rel="prefetch" href="/notebook/assets/js/283.13f54ae9.js"><link rel="prefetch" href="/notebook/assets/js/284.88644dec.js"><link rel="prefetch" href="/notebook/assets/js/285.0670211f.js"><link rel="prefetch" href="/notebook/assets/js/286.afa43d34.js"><link rel="prefetch" href="/notebook/assets/js/287.9e98e933.js"><link rel="prefetch" href="/notebook/assets/js/288.175a8a9b.js"><link rel="prefetch" href="/notebook/assets/js/289.0d712953.js"><link rel="prefetch" href="/notebook/assets/js/29.3476ca1f.js"><link rel="prefetch" href="/notebook/assets/js/290.4b258761.js"><link rel="prefetch" href="/notebook/assets/js/291.e7ded33e.js"><link rel="prefetch" href="/notebook/assets/js/292.fcfca63e.js"><link rel="prefetch" href="/notebook/assets/js/293.4d6c0f7d.js"><link rel="prefetch" href="/notebook/assets/js/294.59b7e2de.js"><link rel="prefetch" href="/notebook/assets/js/295.0b8dc8f3.js"><link rel="prefetch" href="/notebook/assets/js/296.65434eb0.js"><link rel="prefetch" href="/notebook/assets/js/297.957ba4a7.js"><link rel="prefetch" href="/notebook/assets/js/298.dd81e487.js"><link rel="prefetch" href="/notebook/assets/js/299.eba0d36a.js"><link rel="prefetch" href="/notebook/assets/js/3.a80649d1.js"><link rel="prefetch" href="/notebook/assets/js/30.51a26022.js"><link rel="prefetch" href="/notebook/assets/js/300.23a6a024.js"><link rel="prefetch" href="/notebook/assets/js/301.eb4276c9.js"><link rel="prefetch" href="/notebook/assets/js/302.2c696c44.js"><link rel="prefetch" href="/notebook/assets/js/303.a748a576.js"><link rel="prefetch" href="/notebook/assets/js/304.95020a99.js"><link rel="prefetch" href="/notebook/assets/js/305.c4bc6072.js"><link rel="prefetch" href="/notebook/assets/js/306.74133b05.js"><link rel="prefetch" href="/notebook/assets/js/307.6ea724f3.js"><link rel="prefetch" href="/notebook/assets/js/308.fc7b065c.js"><link rel="prefetch" href="/notebook/assets/js/309.56497801.js"><link rel="prefetch" href="/notebook/assets/js/31.c351e10d.js"><link rel="prefetch" href="/notebook/assets/js/310.692379f9.js"><link rel="prefetch" href="/notebook/assets/js/311.b7393f95.js"><link rel="prefetch" href="/notebook/assets/js/312.f3eec1e1.js"><link rel="prefetch" href="/notebook/assets/js/313.9227351c.js"><link rel="prefetch" href="/notebook/assets/js/314.6960877d.js"><link rel="prefetch" href="/notebook/assets/js/315.f55a1979.js"><link rel="prefetch" href="/notebook/assets/js/316.6121039c.js"><link rel="prefetch" href="/notebook/assets/js/317.7ba118c8.js"><link rel="prefetch" href="/notebook/assets/js/318.2b71444c.js"><link rel="prefetch" href="/notebook/assets/js/319.bc0d5ccf.js"><link rel="prefetch" href="/notebook/assets/js/32.8a802a22.js"><link rel="prefetch" href="/notebook/assets/js/320.79f13ae1.js"><link rel="prefetch" href="/notebook/assets/js/321.21d3b0cf.js"><link rel="prefetch" href="/notebook/assets/js/322.87e4c143.js"><link rel="prefetch" href="/notebook/assets/js/323.4dee2eb7.js"><link rel="prefetch" href="/notebook/assets/js/324.f8c64322.js"><link rel="prefetch" href="/notebook/assets/js/325.c82057d6.js"><link rel="prefetch" href="/notebook/assets/js/326.3ea0d22b.js"><link rel="prefetch" href="/notebook/assets/js/327.90b878d9.js"><link rel="prefetch" href="/notebook/assets/js/328.59e55f0a.js"><link rel="prefetch" href="/notebook/assets/js/329.95fb2ef0.js"><link rel="prefetch" href="/notebook/assets/js/33.18cd7b09.js"><link rel="prefetch" href="/notebook/assets/js/330.ed1fb0e9.js"><link rel="prefetch" href="/notebook/assets/js/331.b84d88a9.js"><link rel="prefetch" href="/notebook/assets/js/332.20dffd14.js"><link rel="prefetch" href="/notebook/assets/js/333.d625fbd2.js"><link rel="prefetch" href="/notebook/assets/js/334.4fedc08a.js"><link rel="prefetch" href="/notebook/assets/js/335.c3b6c886.js"><link rel="prefetch" href="/notebook/assets/js/336.cf000555.js"><link rel="prefetch" href="/notebook/assets/js/337.891a7e6c.js"><link rel="prefetch" href="/notebook/assets/js/338.23da071e.js"><link rel="prefetch" href="/notebook/assets/js/339.92d07729.js"><link rel="prefetch" href="/notebook/assets/js/34.f39f39b2.js"><link rel="prefetch" href="/notebook/assets/js/340.09cb4417.js"><link rel="prefetch" href="/notebook/assets/js/341.3591e649.js"><link rel="prefetch" href="/notebook/assets/js/342.568a9320.js"><link rel="prefetch" href="/notebook/assets/js/343.e61b523f.js"><link rel="prefetch" href="/notebook/assets/js/344.61bb135b.js"><link rel="prefetch" href="/notebook/assets/js/345.f861e5aa.js"><link rel="prefetch" href="/notebook/assets/js/346.c5c70e0f.js"><link rel="prefetch" href="/notebook/assets/js/347.9b389847.js"><link rel="prefetch" href="/notebook/assets/js/348.eb62b86e.js"><link rel="prefetch" href="/notebook/assets/js/349.d4852195.js"><link rel="prefetch" href="/notebook/assets/js/35.c31fd7ed.js"><link rel="prefetch" href="/notebook/assets/js/350.f1db6bfd.js"><link rel="prefetch" href="/notebook/assets/js/351.4d86adaf.js"><link rel="prefetch" href="/notebook/assets/js/36.624192b1.js"><link rel="prefetch" href="/notebook/assets/js/37.680f8e12.js"><link rel="prefetch" href="/notebook/assets/js/38.f9ecec66.js"><link rel="prefetch" href="/notebook/assets/js/39.afab4ce6.js"><link rel="prefetch" href="/notebook/assets/js/4.03ba6111.js"><link rel="prefetch" href="/notebook/assets/js/40.f66ecac0.js"><link rel="prefetch" href="/notebook/assets/js/41.87cdca0e.js"><link rel="prefetch" href="/notebook/assets/js/42.08461558.js"><link rel="prefetch" href="/notebook/assets/js/43.ad5cf182.js"><link rel="prefetch" href="/notebook/assets/js/44.0bb6ad3f.js"><link rel="prefetch" href="/notebook/assets/js/45.5d2af6d4.js"><link rel="prefetch" href="/notebook/assets/js/46.8a06257e.js"><link rel="prefetch" href="/notebook/assets/js/47.3e37541c.js"><link rel="prefetch" href="/notebook/assets/js/48.024eda4c.js"><link rel="prefetch" href="/notebook/assets/js/49.a0685cf7.js"><link rel="prefetch" href="/notebook/assets/js/5.1071c8dd.js"><link rel="prefetch" href="/notebook/assets/js/50.130eaac4.js"><link rel="prefetch" href="/notebook/assets/js/51.0fe4dbd0.js"><link rel="prefetch" href="/notebook/assets/js/52.9d0ae64a.js"><link rel="prefetch" href="/notebook/assets/js/53.1ca09933.js"><link rel="prefetch" href="/notebook/assets/js/54.679cd78c.js"><link rel="prefetch" href="/notebook/assets/js/55.95cbe3a2.js"><link rel="prefetch" href="/notebook/assets/js/56.a58ec2af.js"><link rel="prefetch" href="/notebook/assets/js/57.0e59339a.js"><link rel="prefetch" href="/notebook/assets/js/58.487f643f.js"><link rel="prefetch" href="/notebook/assets/js/59.a8e9a1e3.js"><link rel="prefetch" href="/notebook/assets/js/6.707a1f11.js"><link rel="prefetch" href="/notebook/assets/js/60.c3080f7a.js"><link rel="prefetch" href="/notebook/assets/js/61.7f77e449.js"><link rel="prefetch" href="/notebook/assets/js/62.a5528e33.js"><link rel="prefetch" href="/notebook/assets/js/63.a787a8ee.js"><link rel="prefetch" href="/notebook/assets/js/64.7d3edfda.js"><link rel="prefetch" href="/notebook/assets/js/65.80e083e6.js"><link rel="prefetch" href="/notebook/assets/js/66.4076f29c.js"><link rel="prefetch" href="/notebook/assets/js/67.cf46f254.js"><link rel="prefetch" href="/notebook/assets/js/68.6fc8b1fd.js"><link rel="prefetch" href="/notebook/assets/js/69.4a344d72.js"><link rel="prefetch" href="/notebook/assets/js/7.c507c0e3.js"><link rel="prefetch" href="/notebook/assets/js/70.b13eef1a.js"><link rel="prefetch" href="/notebook/assets/js/71.20ad9776.js"><link rel="prefetch" href="/notebook/assets/js/72.30f44ef6.js"><link rel="prefetch" href="/notebook/assets/js/73.857a629d.js"><link rel="prefetch" href="/notebook/assets/js/74.a2b5a703.js"><link rel="prefetch" href="/notebook/assets/js/75.252e6fc0.js"><link rel="prefetch" href="/notebook/assets/js/76.d64e4a53.js"><link rel="prefetch" href="/notebook/assets/js/77.40db9cc6.js"><link rel="prefetch" href="/notebook/assets/js/78.7a635d12.js"><link rel="prefetch" href="/notebook/assets/js/79.b2249421.js"><link rel="prefetch" href="/notebook/assets/js/8.a5f34392.js"><link rel="prefetch" href="/notebook/assets/js/81.2e8d667e.js"><link rel="prefetch" href="/notebook/assets/js/82.885af8d1.js"><link rel="prefetch" href="/notebook/assets/js/83.b601bf2e.js"><link rel="prefetch" href="/notebook/assets/js/84.758d5dba.js"><link rel="prefetch" href="/notebook/assets/js/85.2e75fb85.js"><link rel="prefetch" href="/notebook/assets/js/86.6c68d815.js"><link rel="prefetch" href="/notebook/assets/js/87.8fba1553.js"><link rel="prefetch" href="/notebook/assets/js/88.e30608d9.js"><link rel="prefetch" href="/notebook/assets/js/89.be2f87c8.js"><link rel="prefetch" href="/notebook/assets/js/9.1c775f56.js"><link rel="prefetch" href="/notebook/assets/js/90.88dd69c4.js"><link rel="prefetch" href="/notebook/assets/js/91.59a69041.js"><link rel="prefetch" href="/notebook/assets/js/92.b46ca339.js"><link rel="prefetch" href="/notebook/assets/js/93.aeaec51d.js"><link rel="prefetch" href="/notebook/assets/js/94.5a852633.js"><link rel="prefetch" href="/notebook/assets/js/95.4f445663.js"><link rel="prefetch" href="/notebook/assets/js/96.6299f802.js"><link rel="prefetch" href="/notebook/assets/js/97.6cf3ba23.js"><link rel="prefetch" href="/notebook/assets/js/98.b48d73e6.js"><link rel="prefetch" href="/notebook/assets/js/99.f61a2e23.js">
    <link rel="stylesheet" href="/notebook/assets/css/0.styles.1b58b254.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/notebook/" class="home-link router-link-active"><img src="/notebook/img/logo.png" alt="notebook" class="logo"> <span class="site-name can-hide">notebook</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/notebook/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="基础" class="dropdown-title"><!----> <span class="title" style="display:;">基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/network/" class="nav-link">计算机网络</a></li><li class="dropdown-item"><!----> <a href="/notebook/computer-system/" class="nav-link">计算机系统</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-structure/" class="nav-link">数据结构与算法</a></li><li class="dropdown-item"><!----> <a href="/notebook/major/" class="nav-link">计算机专业课</a></li><li class="dropdown-item"><!----> <a href="/notebook/design-pattern/" class="nav-link">设计模式</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="开发" class="dropdown-title"><!----> <span class="title" style="display:;">开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://yubincloud.github.io/notebook-front/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  前端
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="/notebook/java/" class="nav-link">Java 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/python/" class="nav-link">Python 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/golang/" class="nav-link">Golang 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/git/" class="nav-link">Git</a></li><li class="dropdown-item"><!----> <a href="/notebook/software-architecture/" class="nav-link">软件设计与架构</a></li><li class="dropdown-item"><!----> <a href="/notebook/distributed-system/" class="nav-link">大数据与分布式系统</a></li><li class="dropdown-item"><h4>常见开发工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/nginx/" class="nav-link">Nginx</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据科学" class="dropdown-title"><!----> <span class="title" style="display:;">数据科学</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/data-science/spider/" class="nav-link">爬虫</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-science/py-data-analysis/" class="nav-link">Python 数据分析</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-warehouse/" class="nav-link">数据仓库</a></li><li class="dropdown-item"><h4>中间件</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/mysql/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/notebook/redis/" class="nav-link">Redis</a></li><li class="dropdown-subitem"><a href="/notebook/elasticsearch/" class="nav-link">Elasticsearch</a></li><li class="dropdown-subitem"><a href="/notebook/kafka/" class="nav-link">Kafka</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/deep-learning/" class="nav-link">深度学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/machine-learning/" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/kg/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/notebook/gnn/" class="nav-link">图神经网络</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全" class="dropdown-title"><!----> <span class="title" style="display:;">安全</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/security/application-security/" class="nav-link">应用安全</a></li><li class="dropdown-item"><!----> <a href="/notebook/security/penetration/" class="nav-link">渗透测试</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维" class="dropdown-title"><!----> <span class="title" style="display:;">运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/ops/linux/" class="nav-link">Linux</a></li><li class="dropdown-item"><!----> <a href="/notebook/ops/cloud-native/" class="nav-link">云原生</a></li></ul></div></div><div class="nav-item"><a href="/notebook/pages/interview/index/" class="nav-link">面试</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="我的" class="dropdown-title"><!----> <span class="title" style="display:;">我的</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/pages/my/favorite/" class="nav-link">收藏</a></li><li class="dropdown-item"><!----> <a href="/notebook/pages/my/good-sentence/" class="nav-link">paper 好句</a></li></ul></div></div> <a href="https://github.com/yubincloud/notebook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/head.jpg"> <div class="blogger-info"><h3>学习笔记</h3> <span>啦啦啦，向太阳~</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/notebook/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="基础" class="dropdown-title"><!----> <span class="title" style="display:;">基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/network/" class="nav-link">计算机网络</a></li><li class="dropdown-item"><!----> <a href="/notebook/computer-system/" class="nav-link">计算机系统</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-structure/" class="nav-link">数据结构与算法</a></li><li class="dropdown-item"><!----> <a href="/notebook/major/" class="nav-link">计算机专业课</a></li><li class="dropdown-item"><!----> <a href="/notebook/design-pattern/" class="nav-link">设计模式</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="开发" class="dropdown-title"><!----> <span class="title" style="display:;">开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://yubincloud.github.io/notebook-front/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  前端
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="/notebook/java/" class="nav-link">Java 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/python/" class="nav-link">Python 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/golang/" class="nav-link">Golang 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/git/" class="nav-link">Git</a></li><li class="dropdown-item"><!----> <a href="/notebook/software-architecture/" class="nav-link">软件设计与架构</a></li><li class="dropdown-item"><!----> <a href="/notebook/distributed-system/" class="nav-link">大数据与分布式系统</a></li><li class="dropdown-item"><h4>常见开发工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/nginx/" class="nav-link">Nginx</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据科学" class="dropdown-title"><!----> <span class="title" style="display:;">数据科学</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/data-science/spider/" class="nav-link">爬虫</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-science/py-data-analysis/" class="nav-link">Python 数据分析</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-warehouse/" class="nav-link">数据仓库</a></li><li class="dropdown-item"><h4>中间件</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/mysql/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/notebook/redis/" class="nav-link">Redis</a></li><li class="dropdown-subitem"><a href="/notebook/elasticsearch/" class="nav-link">Elasticsearch</a></li><li class="dropdown-subitem"><a href="/notebook/kafka/" class="nav-link">Kafka</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/deep-learning/" class="nav-link">深度学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/machine-learning/" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/kg/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/notebook/gnn/" class="nav-link">图神经网络</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全" class="dropdown-title"><!----> <span class="title" style="display:;">安全</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/security/application-security/" class="nav-link">应用安全</a></li><li class="dropdown-item"><!----> <a href="/notebook/security/penetration/" class="nav-link">渗透测试</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维" class="dropdown-title"><!----> <span class="title" style="display:;">运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/ops/linux/" class="nav-link">Linux</a></li><li class="dropdown-item"><!----> <a href="/notebook/ops/cloud-native/" class="nav-link">云原生</a></li></ul></div></div><div class="nav-item"><a href="/notebook/pages/interview/index/" class="nav-link">面试</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="我的" class="dropdown-title"><!----> <span class="title" style="display:;">我的</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/pages/my/favorite/" class="nav-link">收藏</a></li><li class="dropdown-item"><!----> <a href="/notebook/pages/my/good-sentence/" class="nav-link">paper 好句</a></li></ul></div></div> <a href="https://github.com/yubincloud/notebook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>深度学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Posts</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>PyTorch 入门</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>鱼书进阶-自然语言处理</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>深度学习-李宏毅</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/notebook/pages/lhy/regression/" class="sidebar-link">Regression</a></li><li><a href="/notebook/pages/lhy/training-tricks/" class="sidebar-link">神经网络训练不起来怎么办</a></li><li><a href="/notebook/pages/lhy/cnn/" class="sidebar-link">CNN</a></li><li><a href="/notebook/pages/lhy/self-attention/" aria-current="page" class="active sidebar-link">Self-Attention</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/self-attention/#_1-引言" class="sidebar-link">1. 引言</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_1-1-vector-set-as-input" class="sidebar-link">1.1 Vector Set as Input</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_1-2-what-is-the-output" class="sidebar-link">1.2 What is the output?</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_1-3-sequence-labeling" class="sidebar-link">1.3 Sequence Labeling</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/self-attention/#_2-self-attention" class="sidebar-link">2. Self Attention</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_2-1-self-attention-概述" class="sidebar-link">2.1 self attention 概述</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_2-2-self-attention-过程" class="sidebar-link">2.2 self attention 过程</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_2-3-矩阵的角度看-self-attention-的运行" class="sidebar-link">2.3 矩阵的角度看 self-attention 的运行</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_2-4-multi-head-self-attention" class="sidebar-link">2.4 Multi-head Self-attention</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/self-attention/#_3-positional-encoding" class="sidebar-link">3. Positional Encoding</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_3-1-each-positon-has-a-unique-positional-vector" class="sidebar-link">3.1 Each positon has a unique positional vector $e^i$</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_3-2-hand-crafted-or-learned-from-data" class="sidebar-link">3.2 Hand-crafted or Learned from data</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/self-attention/#_4-application" class="sidebar-link">4. Application</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_4-1-self-attention-for-speech" class="sidebar-link">4.1 Self-attention for Speech</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_4-2-self-attention-for-image" class="sidebar-link">4.2 Self-attention for Image</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_4-3-self-attention-v-s-rnn" class="sidebar-link">4.3 Self-attention v.s. RNN</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_4-4-self-attention-for-graph" class="sidebar-link">4.4 Self-attention for Graph</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/self-attention/#_4-5-more" class="sidebar-link">4.5 More</a></li></ul></li></ul></li><li><a href="/notebook/pages/lhy/various-attention/" class="sidebar-link">各式各样的 Attention</a></li><li><a href="/notebook/pages/lhy/pointer-network/" class="sidebar-link">Pointer Network</a></li><li><a href="/notebook/pages/lhy/gnn/" class="sidebar-link">图神经网络</a></li><li><a href="/notebook/pages/lhy/transformer/" class="sidebar-link">Transformer</a></li><li><a href="/notebook/pages/lhy/gan/" class="sidebar-link">生成对抗网络 GAN</a></li><li><a href="/notebook/pages/lhy/self-supervised-learning/" class="sidebar-link">Self Supervised Learning</a></li><li><a href="/notebook/pages/lhy/bert-and-family/" class="sidebar-link">BERT and its family</a></li><li><a href="/notebook/pages/lhy/data-efficient/" class="sidebar-link">Data Efficient &amp; Parameter-Efficient Tuning</a></li><li><a href="/notebook/pages/lhy/auto-encoder/" class="sidebar-link">Auto-Encoder</a></li><li><a href="/notebook/pages/lhy/explainable-ml/" class="sidebar-link">机器学习的可解释性</a></li><li><a href="/notebook/pages/lhy/adversarial-attack/" class="sidebar-link">Adversarial Attack</a></li><li><a href="/notebook/pages/lhy/domain-adaptation/" class="sidebar-link">Domain Adaptation</a></li><li><a href="/notebook/pages/lhy/RL/" class="sidebar-link">强化学习</a></li><li><a href="/notebook/pages/lhy/network-compression/" class="sidebar-link">神经网络压缩</a></li><li><a href="/notebook/pages/lhy/life-long-learning/" class="sidebar-link">Life Long Learning</a></li><li><a href="/notebook/pages/lhy/meta-learning/" class="sidebar-link">Meta Learning</a></li><li><a href="/notebook/pages/595df8/" class="sidebar-link">ChatGPT 是怎样炼成的</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>李宏毅-2017版</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>李宏毅-2019版</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>预训练语言模型-邵浩2021版</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>王树森</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>机器学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>知识图谱</span> <span class="arrow right"></span></p> <!----></section></li></ul> <div class="sidebar-slot sidebar-slot-bottom"><!-- 正方形 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="3508773082"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div></aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-6"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/notebook/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/notebook/categories/?category=AI" title="分类" data-v-06225672>AI</a></li><li data-v-06225672><a href="/notebook/categories/?category=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" title="分类" data-v-06225672>深度学习</a></li><li data-v-06225672><a href="/notebook/categories/?category=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%9D%8E%E5%AE%8F%E6%AF%85" title="分类" data-v-06225672>深度学习-李宏毅</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/yubincloud" target="_blank" title="作者" class="beLink" data-v-06225672>yubin</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2022-04-05</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">Self-Attention<!----></h1> <div class="page-slot page-slot-top"><!-- 固定100% * 90px可显示，max-height:90px未见显示-->
     <ins class="adsbygoogle"
          style="display:inline-block;width:100%;max-height:90px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6625304284"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="theme-vdoing-content content__default"><p>Self-Attention 是一个很常见的 Network 架构。</p> <h2 id="_1-引言"><a href="#_1-引言" class="header-anchor">#</a> 1. 引言</h2> <p>之前我们的 model 的输入是一个向量，输出可能是一个数值，这是 Regression，还可能是一个类别，这是 Classification。</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405192828786.png" alt="image-20220405192828786" style="zoom:80%;"> <p>假设我们遇到更复杂的问题，比如输入是多个向量，且输入的向量数目会改变。现在如果我们 model 输入的 sequence 的数目、长度都不一样，这时该如何处理？</p> <h3 id="_1-1-vector-set-as-input"><a href="#_1-1-vector-set-as-input" class="header-anchor">#</a> 1.1 Vector Set as Input</h3> <h4 id="_1-文字处理"><a href="#_1-文字处理" class="header-anchor">#</a> 1）文字处理</h4> <p>假设我们今天要Network的输入是一个句子,每一个句子的长度都不一样,每个句子裡面词汇的数目都不一样, 如果我们把一个<strong>句子裡面的每一个词汇都描述成一个向量</strong>,那我们的Model的输入,就会是一个Vector Set,而且每次句子的长度不一样,那 Vector Set 的大小就不一样：</p> <p><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405193330755.png" alt="image-20220405193330755"></p> <p>那怎么把词汇表示成一个向量呢？最简单的是 one-hot encoding，还有一种方法是 Word Embedding，形成单词的分布式表示。</p> <h4 id="_2-声音信号"><a href="#_2-声音信号" class="header-anchor">#</a> 2）声音信号</h4> <p>一段声音讯号其实是一排向量，把一段声音讯号取一个范围，这个范围叫做一个 <strong>Window</strong>，每个 Window 里面得资讯描述成一个向量，这个向量就是一个 <mark>Frame</mark>：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405193742951.png" alt="image-20220405193742951" style="zoom:80%;"> <p>把一小段声音讯号变成一个 Frame，有很多种做法，这里不再细讲了。</p> <p>通常 Window 的长度是 25 个 Millisecond，为了描述一整段声音讯号，我们会把这个 Window 右移一点，通常移动的大小是 10 个 Millisecond：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405194126813.png" alt="image-20220405194126813" style="zoom:80%;"> <p>一秒钟声音讯号就有 100 个向量，一分钟声音讯号有 6000 个向量，所以语音其实还是挺复杂的。</p> <h4 id="_3-图"><a href="#_3-图" class="header-anchor">#</a> 3）图</h4> <p>一个 Graph 也是一堆向量。在 Social Network 上面每个节点是一个向量，关系可以视为向量。</p> <h4 id="_4-分子信息"><a href="#_4-分子信息" class="header-anchor">#</a> 4）分子信息</h4> <p>一个分子也可以看作是一个 Graph：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405194428967.png" alt="image-20220405194428967" style="zoom:67%;"> <p>一个原子可以用 One-Hot Vector 来表示，比如氢就是 <code>1000</code>，碳是 <code>0010</code> 等。</p> <h3 id="_1-2-what-is-the-output"><a href="#_1-2-what-is-the-output" class="header-anchor">#</a> 1.2 What is the output?</h3> <p>刚才看到输入是一堆向量，那我们有可能有什么样的输出呢？</p> <h4 id="_1-每一个向量都有一个对应的-label"><a href="#_1-每一个向量都有一个对应的-label" class="header-anchor">#</a> 1）每一个向量都有一个对应的 Label</h4> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405194956848.png" alt="image-20220405194956848" style="zoom:80%;"></center> <p>当你的模型的输入是四个向量的时候，它就要输出四个 Label，而</p> <ul><li>若每个 Label 是一个数值，那就是 Regression 的问题</li> <li>若每个 Label 是一个类别，那就是 Classification 的问题</li></ul> <p>应用举例：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405195054435.png" alt="image-20220405195054435" style="zoom:67%;"> <ul><li><strong>POS Tagging</strong>，即词性标注，让机器自动决定每一个词汇的词性，是名词、动词还是形容词等</li> <li><strong>语音辨识</strong>，对每一个 vector，来辨识它是哪一个 Phonetic</li> <li>在 Social Network 中，你的 model 来决定每一个节点的特性，比如他会不会买某个商品</li></ul> <h4 id="_2-一整个-sequence-只需要输出一个-label"><a href="#_2-一整个-sequence-只需要输出一个-label" class="header-anchor">#</a> 2）一整个 Sequence，只需要输出一个 Label</h4> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405195419262.png" alt="image-20220405195419262" style="zoom:67%;"></center> <p>比如 Sentiment Analysis（情感分析），给机器看一段话，判断他是正面还是负面的；比如语音辨认，给机器听一段语音，然后判断是谁讲的；比如在 graph 领域，给一个分子，然后预测它有没有毒性等</p> <h4 id="_3-机器要自己决定应该要输出多少个-label"><a href="#_3-机器要自己决定应该要输出多少个-label" class="header-anchor">#</a> 3）机器要自己决定应该要输出多少个 Label</h4> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405195645751.png" alt="image-20220405195645751" style="zoom:67%;"></center> <p>这种任务又叫做 <strong>seq2seq</strong>。</p> <h3 id="_1-3-sequence-labeling"><a href="#_1-3-sequence-labeling" class="header-anchor">#</a> 1.3 Sequence Labeling</h3> <p>这种输入跟输出数目一样多的状况又叫做 <mark>Sequence Labeling</mark>，我们着重研究这个问题。</p> <p>解决这个问题的一个简单想法是用 Fully-Connected（简称 <strong>FC</strong>）的 Network：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405200003629.png" alt="image-20220405200003629" style="zoom:80%;"> <p>但这样有一个巨大的瑕疵，它无法识别出不同语境下“saw”的不同，它有“看见”、“锯子”的意思。怎么办才有可能让 Fully-Connected 的 Network 考虑更多的上下文 context 的资讯呢？</p> <p>这时有可能的，只需要把前后几个向量都串起来，一起丢到 FC 的 network 中就行了：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405200309936.png" alt="image-20220405200309936" style="zoom:80%;"> <p>但这样总是有极限的，比如一个任务不是考虑一个 Window 就可以解决的，而是要考虑一整个 Sequence 才能够解决的话，就只能再把 Window 开大一点直到能覆盖整个 sequence。但是这么大的 Window，意味着 FC 的 network 需要非常多的参数，运算量大且容易 overfitting。</p> <p>所以<u>有没有更好的方法来考虑整个 Input Sequence 的资讯呢？这就要用到我们接下来要跟大家介绍的 Self-Attention 这个技术了</u>。</p> <h2 id="_2-self-attention"><a href="#_2-self-attention" class="header-anchor">#</a> 2. Self Attention</h2> <h3 id="_2-1-self-attention-概述"><a href="#_2-1-self-attention-概述" class="header-anchor">#</a> 2.1 self attention 概述</h3> <p>Self-Attention 的运作方式就是<strong>它会吃一整个 Sequence 的资讯</strong>。</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405213532561.png" alt="image-20220405213532561" style="zoom:80%;"> <ul><li>Self Attention 中 input 几个 vector 就输出几个 vector，这里输出的 4 个 vector 有个特别的地方：<strong>它们都是考虑一整个 Sequence 以后才得到的</strong>。等一会我们会讲 Self-Attention 怎么考虑到一整个 Sequence 的资讯的。</li></ul> <p>Self-Attention 输出的向量是 with context 的，这样一来 FC 的 Network 就不只是考虑一个非常小的 Window 了，而是一整个 Sequence 的资讯，再决定应该输出什么样的结果，这个就是 <mark>Self-Attention</mark>。</p> <p><strong>Self-Attention 不是只能用一次，也可以叠加很多次</strong>，可以把 Fully-Connected 的 network 跟 self attention 交替使用：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220405220625274.png" alt="image-20220405220625274" style="zoom:67%;"> <ul><li>Self-Attention 处理整个 Sequence 的资讯</li> <li>FC 的 Network 专注于处理某一个位置的资讯</li> <li>再用 Self-Attention 把整个 Sequence 资讯再处理一次</li> <li>然后交替使用 Self-Attention 跟 FC</li></ul> <blockquote><p>有关 self attention，最知名的文章就是《Attention is all you need》，它提出了 Transformer 的 Network。</p></blockquote> <h3 id="_2-2-self-attention-过程"><a href="#_2-2-self-attention-过程" class="header-anchor">#</a> 2.2 self attention 过程</h3> <p>Self-Attention 的 input 是一串的 vector，这个 vector 可能是整个 Network 的 input，也可能是某个 hidden layer 的 output，所以我们这边不是用 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-math></mjx-container> 来表示它，而是用 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi></mjx-math></mjx-container> 来表示。self attention 的 output 是另一排的 vector <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-math></mjx-container>。</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406090213518.png" alt="image-20220406090213518" style="zoom:50%;"></center> <ul><li>每一个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-math></mjx-container> 都是考虑了所有的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi></mjx-math></mjx-container> 才生成出来的，所以刻意画了非常非常多的箭头</li></ul> <p>接下来我们说明一下怎样产生 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 这个向量，由此就可以知道怎样产生另外的几个了。</p> <p>这里有个<strong>特别的机制</strong>：<u>这个机制根据 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 这个向量，找出整个 sequence 里到底哪些部分是重要的，哪些部分是我们要决定 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 的 class 或 regression 数值的时候所需要用到的资讯</u>。<strong>每一个向量跟 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 的关联程度用一个数值 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container> 表示</strong>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406091044650.png" alt="image-20220406091044650" style="zoom:80%;"></center> <p>那如何自动计算两个向量之间的关联性呢，即如何计算两个向量之间的数值 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container> 呢？这需要一个计算 attention 的模组：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406091811854.png" alt="image-20220406091811854" style="zoom:80%;"> <p>这个计算 attention 的模组就是拿两个向量作为输入，输出 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container>。我们常用的是左边 Dot-product 的做法：</p> <ul><li>输入的这两个向量分别乘上两个不同的矩阵，得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container></li> <li><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container> 做 dot product 得到一个 scalar，这个 scalar 就是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container></li></ul> <p>还有其他许多计算 attention 的模组，之后我们只用上图左边的那种，它也是最常用的。</p> <p>上图计算过程中的 vector <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-math></mjx-container> 叫做 <mark>Query</mark>，vector <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container> 叫做 <mark>key</mark>，它们的上标与输入向量的上标相同，比如 self-attention 的输入向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 计算得到的是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>。</p> <p>用来表示两个向量的关联性的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container> 叫做 <mark>attention score</mark>，用 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="3"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msup space="4"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="3"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 作为其下标的含义，这样计算各 attention score 的过程如下图：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406092825332.png" alt="image-20220406092825332" style="zoom:67%;"></center> <p>实际情况下，一般也会让 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 与自己算关联性。计算出 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 跟每一个向量的关联性以后，接下来进入一个 softmax：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406094030458.png" alt="image-20220406094030458" style="zoom:80%;"></center> <ul><li>本来有一排的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container>，经过 softmax 后就得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2032"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container></li> <li><strong>不一定非要用 softmax，用别的替代也没问题</strong>，换其他的 activation function 都可以，这需要手工调试一试</li></ul> <p>得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2032"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container> 后就可以根据它去抽取出 sequence 里面重要的资讯。<strong>由 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2032"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container> 可以知道哪些向量跟 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 最有关系</strong>，那怎样抽取重要的资讯呢？</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406094934071.png" alt="image-20220406094934071" style="zoom:90%;"></center> <ul><li>将 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 与 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;margin-left:0.071em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 相乘得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container></li> <li>各 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 乘上 attention score <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2032"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container></li> <li>再累加起来得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>：<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-munder space="4" limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-munder><mjx-msubsup space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.258em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2032"></mjx-c></mjx-mo><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-script></mjx-msubsup><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container></li></ul> <p>如果某一个向量它得到的分数越高，比如说如果 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 与 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 的关联性很强，那这个得到的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2032"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container> 的值就很大，那我们做 weight sum 以后，得到的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 的值就可能会比较接近 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>。所以<strong>谁的那个 attention score 最大，谁的那个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi></mjx-math></mjx-container> 就会 dominant 你抽出来的结果</strong>。</p> <p>以上就讲完了如何从一整个 Sequence 里得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>。</p> <h3 id="_2-3-矩阵的角度看-self-attention-的运行"><a href="#_2-3-矩阵的角度看-self-attention-的运行" class="header-anchor">#</a> 2.3 矩阵的角度看 self-attention 的运行</h3> <p>我们再从矩阵乘法的角度重新看一遍 self-attention 是怎样运行的。</p> <p>现在我们已经知道每一个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi></mjx-math></mjx-container> 都产生 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi></mjx-math></mjx-container>，即：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406160622740.png" alt="image-20220406160622740" style="zoom:67%;"> <p>这样写成矩阵的形式，把 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="3"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="4"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 视为矩阵 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="I"></mjx-c></mjx-mi></mjx-math></mjx-container>，同样将所有 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-math></mjx-container> 视为矩阵 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="Q"></mjx-c></mjx-mi></mjx-math></mjx-container>，于是得到：<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="Q"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msup space="4"><mjx-mi class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;margin-left:0.071em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-script></mjx-msup><mjx-mi class="mjx-i"><mjx-c c="I"></mjx-c></mjx-mi></mjx-math></mjx-container>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406160924998.png" alt="image-20220406160924998" style="zoom:80%;"></center> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi></mjx-math></mjx-container> 的操作跟 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-math></mjx-container> 是一样的，类比可以写出：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406161034512.png" alt="image-20220406161034512" style="zoom:67%;"></center> <p>我们再看 attention score 的计算，之前的计算过程可以绘制为：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406161228525.png" alt="image-20220406161228525" style="zoom:80%;"> <ul><li>比如 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 与 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 做 inner product 得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container></li></ul> <p>上面四个步骤的操作可以拼接起来，视为一个矩阵与向量相乘：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406161435864.png" alt="image-20220406161435864" style="zoom:80%;"></center> <ul><li><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> ~ <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="4"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 可以视为一个矩阵的四个 row</li></ul> <p>现在不只是对 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 计算 attention，还对 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> ~ <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="4"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 都计算，而且它们都是要对 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> ~ <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="4"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 做相同的操作，于是可以继续合并为：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406161736715.png" alt="image-20220406161736715" style="zoom:80%;"></center> <ul><li>所以 attention score 的计算可以视为两个矩阵的相乘</li></ul> <p>我们再来复习一下，整个 self attention 运行过程就是：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406185858516.png" alt="image-20220406185858516" style="zoom:80%;"></center> <p>可以看到，在这个 self-attention layer 中唯一需要学习的参数就是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;margin-left:0.071em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;margin-left:0.071em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;margin-left:0.071em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container>，只有他们是未知的。</p> <p>上面的从 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="I"></mjx-c></mjx-mi></mjx-math></mjx-container> 到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="O"></mjx-c></mjx-mi></mjx-math></mjx-container> 就是 self-attention。</p> <h3 id="_2-4-multi-head-self-attention"><a href="#_2-4-multi-head-self-attention" class="header-anchor">#</a> 2.4 Multi-head Self-attention</h3> <p>Self-attention 有一个进阶的版本，叫做 <mark>Multi-head Self-attention</mark>。在一些任务中，比如语音识别，用较多的 head 可以得到比较好的结果。至于<strong>用多少个 head，这又是一个 hyperparameter</strong>。</p> <p><strong>为什么我们需要比较多的 head 呢</strong>？我们在做 self attention 时，是用 q 去找相关的 k，但**“相关”这件事情可能有很多种不同的形式**。所以也许我们不能只有一个 q，而是应该有多个 q，<strong>不同的 q 负责不同种类的相关性</strong>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406194300497.png" alt="image-20220406194300497" style="zoom:80%;"></center> <ul><li>先把 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 乘上一个矩阵得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container></li> <li>再<u>把 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 乘上两个矩阵，分别得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container>，这里上标中的 1、2 代表说有 2 个 head</u></li></ul> <p>我们认为要解决的问题里面有两种不同的相关性，于是我们需要两个 head，来找这两种不同的相关性。</p> <p>既然 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="q"></mjx-c></mjx-mi></mjx-math></mjx-container> 有两个，那 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container>、<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="v"></mjx-c></mjx-mi></mjx-math></mjx-container> 也自然有两个。<strong>每一个 head 在计算时，与之前的 self-attention 计算过程完全一样，不会与其他 head 产生交集</strong>。最终，head 1 产生 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container>，head 2 产生 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406195516068.png" alt="image-20220406195516068" style="zoom:80%;"></center> <p>得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 后，你可能会把他们接起来，再乘上一个矩阵得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406195636662.png" alt="image-20220406195636662" style="zoom:80%;"></center> <p>最终将 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 送到下一层去。以上就是 Multi-head self-attention。</p> <h2 id="_3-positional-encoding"><a href="#_3-positional-encoding" class="header-anchor">#</a> 3. Positional Encoding</h2> <p>到目前为止，你会发现 <strong>self-attention layer 少了位置的资讯</strong>。这就是说，位置 1 和 位置 2、3 完全没有任何差别。但位置的资讯又是比较重要的，比如在词性标注（POS tagging）中，动词不太容易出现在句首。</p> <p>下面讲解一种解决方案：</p> <h3 id="_3-1-each-positon-has-a-unique-positional-vector"><a href="#_3-1-each-positon-has-a-unique-positional-vector" class="header-anchor">#</a> 3.1 Each positon has a unique positional vector <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container></h3> <p>在做 Self-attention 的时候，如果你觉得位置的资讯是一个重要的事情，那可以想办法把位置的资讯塞进去，这需要用到 <mark>Positional Encoding</mark> 的技术。</p> <p>可以为每个位置设定一个 vector，叫做 <strong>positional vector</strong>，用 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 表示，上标 i 代表位置，每一个不同的位置有不同的 vector <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi></mjx-math></mjx-container>，然后<strong>把这个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 加到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 上面就结束了</strong>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406202640984.png" alt="image-20220406202640984" style="zoom:80%;"></center> <p>这样做其实就是告诉 self-attention 位置的资讯，如果它看到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 好像有被加上 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container>，它就知道现在出现的位置应该是在 i 这个位置。</p> <h3 id="_3-2-hand-crafted-or-learned-from-data"><a href="#_3-2-hand-crafted-or-learned-from-data" class="header-anchor">#</a> 3.2 Hand-crafted or Learned from data</h3> <p>在《Attention is all your need》这篇 paper 中，它用的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 长这个样子：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406203109941.png" alt="image-20220406203109941" style="zoom:80%;"> <ul><li>每一个 column 代表一个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi></mjx-math></mjx-container></li></ul> <p>像这样的 positional vector 是 <strong>handcrafted</strong> 的，但这个人设的 vector 有很多问题，比如我现在在定 vector 的时候，定到了 128，但之后出现一个 Sequence 的长度是 129 就没办法了。不过在《Attention is all your need》中，它的 vector 是透过某一个规则来产生的，是透过一个神奇的 sin、cos 的 function 产生的。</p> <p>其实不一定要这样产生，<strong>positional encoding 仍然是一个尚待研究的问题</strong>。你可以创造自己新的方法，甚至 positional encoding 是可以根据资料学出来的。</p> <blockquote><p>有关 positional encoding，可以参考一下这个<a href="https://arxiv.org/abs/2003.09229" target="_blank" rel="noopener noreferrer">文献<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，这里面提出了新的 positional encoding 方法。</p></blockquote> <h2 id="_4-application"><a href="#_4-application" class="header-anchor">#</a> 4. Application</h2> <p>self-attention 应用很广，在 NLP 中你肯定听到过 Transformer 和 Bert：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406203954274.png" alt="image-20220406203954274" style="zoom:50%;"> <p>但 <strong>Self-attention 不是只能用在 NLP 相关的应用上，它还可以用在很多其他的问题上</strong>。</p> <h3 id="_4-1-self-attention-for-speech"><a href="#_4-1-self-attention-for-speech" class="header-anchor">#</a> 4.1 Self-attention for Speech</h3> <p>对于一般的语音，如果你要把一段声音讯号表示成一排向量的话，这排向量可能会非常地长，这个可观的长度会使得在计算 attention matrix 的时候产生性能问题，因为这一步的计算复杂度是长度的平方。这时不容易训练的，怎么办呢？</p> <p>在做语音的时候，有一招叫做 <mark>Truncated Self-attention</mark>：我们<strong>在做 self-attention 的时候，不要看一整句话，就只看一个小的范围就好</strong>。因为在语音辨识时，只需要前后一定范围之内的资讯，其实就可以判断这个位置有什么样的 phoneme 或内容。</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406204525044.png" alt="image-20220406204525044" style="zoom:67%;"> <h3 id="_4-2-self-attention-for-image"><a href="#_4-2-self-attention-for-image" class="header-anchor">#</a> 4.2 Self-attention for Image</h3> <p>我们在讲 Self-attention 的时候，都说它适用的范围是：输入是一个 vector set 的时候。而一张图片，换一个观点，也可以把它看作是一个 vector 的 set：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406204643646.png" alt="image-20220406204643646" style="zoom:67%;"> <ul><li>每一个 pixel 就是一个三维的 vector，整张图片就是有 5 × 10 个 vector 的 set</li></ul> <p>其实你可以读一篇 paper，叫做 <em>On the Relationship,between Self-attention and Convolutional Layers</em>，它用严谨的数学的方式来告诉了我们，<strong>CNN 就是 self-attention 的特例，只要设定合适的参数，self-attention 可以做到跟 CNN 一模一样的事情</strong>。所以 self attention 相比 CNN 更加 flexible。</p> <p>既然 self-attention 比 CNN 更加 flexible，那就需要更多的 data，如果 data 不够的话就可能 overfitting。来看这个实验结果：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20220406210136644.png" alt="image-20220406210136644" style="zoom:67%;"> <ul><li>可以发现，随着资料量越来越多，Self-attention 的结果就越来越好，最终在资料量最多的时候 Self-attention 可以超过 CNN。但在资料量少的时候，CNN 它是可以比 Self-attention 得到更好的结果的。</li></ul> <h3 id="_4-3-self-attention-v-s-rnn"><a href="#_4-3-self-attention-v-s-rnn" class="header-anchor">#</a> 4.3 Self-attention v.s. RNN</h3> <p>RNN 无法并行化运算，这是它的最大缺点，现在 RNN 的角色很大一部分都可以用 Self-attention 来取代了。这里不再展开。</p> <h3 id="_4-4-self-attention-for-graph"><a href="#_4-4-self-attention-for-graph" class="header-anchor">#</a> 4.4 Self-attention for Graph</h3> <p>Graph 也可以看作是一堆 vector，这样就可以用 Self-attention 来处理。其实当我们把 Self-attention 按照图的限制用在 Graph 上面的时候，其实就是一种 Graph Neural Network，也就是一种 GNN。</p> <h3 id="_4-5-more"><a href="#_4-5-more" class="header-anchor">#</a> 4.5 More</h3> <p>其实 Self-attention 有非常非常多的变形，你可以看一篇 paper，叫做 <em>Long Range Arena</em>，里面比较了各种不同的 Self-attention 的变形。因为 <strong>Self-attention 最大的问题就是它的运算量非常地大</strong>，所以怎样减少 Self-attention 的运算量是一个未来的重点。</p> <p>self-attention 最早用在 Transformer 上，有人说广义的 Transformer 指的就是 Self-attention，以至于后来各种变形都这么做，所以 Self-attention 的变形，现在都叫做 xxformer。</p> <p>现在很多新的 xxformer 的速度比 Transformer 快，但随之而来的是 performance 变差。到底什么样的 Self-attention 才能够真的又快又好，这仍然是一个尚待研究的问题。如果想要对 self attention 进一步研究的话，可以参考 <em>Efficient Transformers: A Survey</em> 这篇 paper，里面介绍了各式各样 self-attention 的变形。</p></div></div> <div class="page-slot page-slot-bottom"><!-- 横向自适应 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6620245489"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="page-edit"><div class="edit-link"><a href="https://github.com/yubincloud/notebook/edit/master/docs/AI/01.深度学习/15.深度学习-李宏毅/15.Self-Attention.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2022/10/03, 13:55:17</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/notebook/pages/lhy/cnn/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">CNN</div></a> <a href="/notebook/pages/lhy/various-attention/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">各式各样的 Attention</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/notebook/pages/lhy/cnn/" class="prev">CNN</a></span> <span class="next"><a href="/notebook/pages/lhy/various-attention/">各式各样的 Attention</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/notebook/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/notebook/pages/ml/lhy/drl17/"><div>
            Deep Reinforcement Learning
            <!----></div></a> <span class="date">10-03</span></dt></dl><dl><dd>02</dd> <dt><a href="/notebook/pages/mysql/geektime/misdeletion/"><div>
            误删数据后怎么办
            <!----></div></a> <span class="date">04-06</span></dt></dl><dl><dd>03</dd> <dt><a href="/notebook/pages/mysql/geektime/multi-slaves/"><div>
            MySQL 一主多从
            <!----></div></a> <span class="date">03-22</span></dt></dl> <dl><dd></dd> <dt><a href="/notebook/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="yubin_inbuy@163.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/yubincloud" title="GitHub" target="_blank" class="iconfont icon-github"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2021-2024
    <span>yubincloud | <a href="https://github.com/yubincloud/notebook/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <div class="custom-html-window custom-html-window-rb" style="display:;"><div class="custom-wrapper"><span class="close-but">×</span> <div><!-- 固定160*160px -->
      <ins class="adsbygoogle"
          style="display:inline-block;max-width:160px;max-height:160px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="8377369658"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
      </div></div></div></div><div class="global-ui"><div></div></div></div>
    <script src="/notebook/assets/js/app.2bf3b6c1.js" defer></script><script src="/notebook/assets/js/2.0ad58009.js" defer></script><script src="/notebook/assets/js/80.d325f684.js" defer></script>
  </body>
</html>
