<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Meta Learning | notebook</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="icon" href="/notebook/img/favicon.ico">
    <script data-ad-client="ca-pub-7828333725993554" async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="学习笔记">
    <meta name="keywords" content="全栈学习笔记">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/notebook/assets/css/0.styles.1b58b254.css" as="style"><link rel="preload" href="/notebook/assets/js/app.2bf3b6c1.js" as="script"><link rel="preload" href="/notebook/assets/js/2.0ad58009.js" as="script"><link rel="preload" href="/notebook/assets/js/96.6299f802.js" as="script"><link rel="prefetch" href="/notebook/assets/js/10.99522837.js"><link rel="prefetch" href="/notebook/assets/js/100.e3b56889.js"><link rel="prefetch" href="/notebook/assets/js/101.6ea1d00b.js"><link rel="prefetch" href="/notebook/assets/js/102.eca9dfbd.js"><link rel="prefetch" href="/notebook/assets/js/103.6ea477d4.js"><link rel="prefetch" href="/notebook/assets/js/104.ac820d2b.js"><link rel="prefetch" href="/notebook/assets/js/105.58b259a8.js"><link rel="prefetch" href="/notebook/assets/js/106.a86005d0.js"><link rel="prefetch" href="/notebook/assets/js/107.7a79d36f.js"><link rel="prefetch" href="/notebook/assets/js/108.64404e25.js"><link rel="prefetch" href="/notebook/assets/js/109.75f12c0a.js"><link rel="prefetch" href="/notebook/assets/js/11.d26d59e4.js"><link rel="prefetch" href="/notebook/assets/js/110.1155fe36.js"><link rel="prefetch" href="/notebook/assets/js/111.bf8b5871.js"><link rel="prefetch" href="/notebook/assets/js/112.22833ceb.js"><link rel="prefetch" href="/notebook/assets/js/113.6a080233.js"><link rel="prefetch" href="/notebook/assets/js/114.35de9701.js"><link rel="prefetch" href="/notebook/assets/js/115.f598d8c2.js"><link rel="prefetch" href="/notebook/assets/js/116.e3bd29ce.js"><link rel="prefetch" href="/notebook/assets/js/117.c3c02abc.js"><link rel="prefetch" href="/notebook/assets/js/118.136a552a.js"><link rel="prefetch" href="/notebook/assets/js/119.c124f3f8.js"><link rel="prefetch" href="/notebook/assets/js/12.dc66c4f2.js"><link rel="prefetch" href="/notebook/assets/js/120.f835d124.js"><link rel="prefetch" href="/notebook/assets/js/121.367716ae.js"><link rel="prefetch" href="/notebook/assets/js/122.752b0493.js"><link rel="prefetch" href="/notebook/assets/js/123.9f8d6026.js"><link rel="prefetch" href="/notebook/assets/js/124.e8eb61b6.js"><link rel="prefetch" href="/notebook/assets/js/125.cb081200.js"><link rel="prefetch" href="/notebook/assets/js/126.ab87d911.js"><link rel="prefetch" href="/notebook/assets/js/127.ffdbe74d.js"><link rel="prefetch" href="/notebook/assets/js/128.ec526e42.js"><link rel="prefetch" href="/notebook/assets/js/129.71839012.js"><link rel="prefetch" href="/notebook/assets/js/13.32e95b42.js"><link rel="prefetch" href="/notebook/assets/js/130.2bc0bb4d.js"><link rel="prefetch" href="/notebook/assets/js/131.5595b49b.js"><link rel="prefetch" href="/notebook/assets/js/132.4963c5c4.js"><link rel="prefetch" href="/notebook/assets/js/133.44f48cfd.js"><link rel="prefetch" href="/notebook/assets/js/134.cf25626c.js"><link rel="prefetch" href="/notebook/assets/js/135.5ee30fa9.js"><link rel="prefetch" href="/notebook/assets/js/136.bc43f8e6.js"><link rel="prefetch" href="/notebook/assets/js/137.9ab5beac.js"><link rel="prefetch" href="/notebook/assets/js/138.692a33e6.js"><link rel="prefetch" href="/notebook/assets/js/139.08e7c98d.js"><link rel="prefetch" href="/notebook/assets/js/14.c418d170.js"><link rel="prefetch" href="/notebook/assets/js/140.39a861db.js"><link rel="prefetch" href="/notebook/assets/js/141.46678413.js"><link rel="prefetch" href="/notebook/assets/js/142.f7ef5eac.js"><link rel="prefetch" href="/notebook/assets/js/143.c92cbac1.js"><link rel="prefetch" href="/notebook/assets/js/144.d9c61437.js"><link rel="prefetch" href="/notebook/assets/js/145.9f603b31.js"><link rel="prefetch" href="/notebook/assets/js/146.b875f045.js"><link rel="prefetch" href="/notebook/assets/js/147.55e7c4f8.js"><link rel="prefetch" href="/notebook/assets/js/148.4410c365.js"><link rel="prefetch" href="/notebook/assets/js/149.6096ed98.js"><link rel="prefetch" href="/notebook/assets/js/15.e0e7392a.js"><link rel="prefetch" href="/notebook/assets/js/150.24451f07.js"><link rel="prefetch" href="/notebook/assets/js/151.7cff301c.js"><link rel="prefetch" href="/notebook/assets/js/152.035fee1f.js"><link rel="prefetch" href="/notebook/assets/js/153.c61f8ec3.js"><link rel="prefetch" href="/notebook/assets/js/154.7bb549d0.js"><link rel="prefetch" href="/notebook/assets/js/155.1dc494db.js"><link rel="prefetch" href="/notebook/assets/js/156.b87eaf39.js"><link rel="prefetch" href="/notebook/assets/js/157.e3f5a5c0.js"><link rel="prefetch" href="/notebook/assets/js/158.c565c699.js"><link rel="prefetch" href="/notebook/assets/js/159.a22609ef.js"><link rel="prefetch" href="/notebook/assets/js/16.d1aef4ee.js"><link rel="prefetch" href="/notebook/assets/js/160.b29e761c.js"><link rel="prefetch" href="/notebook/assets/js/161.bee1e522.js"><link rel="prefetch" href="/notebook/assets/js/162.c49fca62.js"><link rel="prefetch" href="/notebook/assets/js/163.2cb4d37d.js"><link rel="prefetch" href="/notebook/assets/js/164.4a0dbc64.js"><link rel="prefetch" href="/notebook/assets/js/165.490d05b3.js"><link rel="prefetch" href="/notebook/assets/js/166.df5d2527.js"><link rel="prefetch" href="/notebook/assets/js/167.89a81814.js"><link rel="prefetch" href="/notebook/assets/js/168.9991702e.js"><link rel="prefetch" href="/notebook/assets/js/169.2f9a5dce.js"><link rel="prefetch" href="/notebook/assets/js/17.88ae5445.js"><link rel="prefetch" href="/notebook/assets/js/170.5f23eb3c.js"><link rel="prefetch" href="/notebook/assets/js/171.c521aaa8.js"><link rel="prefetch" href="/notebook/assets/js/172.42110b0a.js"><link rel="prefetch" href="/notebook/assets/js/173.5e36f1bf.js"><link rel="prefetch" href="/notebook/assets/js/174.f48e078a.js"><link rel="prefetch" href="/notebook/assets/js/175.775da6a5.js"><link rel="prefetch" href="/notebook/assets/js/176.9c3c55ea.js"><link rel="prefetch" href="/notebook/assets/js/177.b54d1cff.js"><link rel="prefetch" href="/notebook/assets/js/178.ff08b7f5.js"><link rel="prefetch" href="/notebook/assets/js/179.c6a1af32.js"><link rel="prefetch" href="/notebook/assets/js/18.dcb78196.js"><link rel="prefetch" href="/notebook/assets/js/180.25dd9eba.js"><link rel="prefetch" href="/notebook/assets/js/181.13e6ec84.js"><link rel="prefetch" href="/notebook/assets/js/182.f6849f0d.js"><link rel="prefetch" href="/notebook/assets/js/183.7e664874.js"><link rel="prefetch" href="/notebook/assets/js/184.e6aba86f.js"><link rel="prefetch" href="/notebook/assets/js/185.df07b919.js"><link rel="prefetch" href="/notebook/assets/js/186.02c77e75.js"><link rel="prefetch" href="/notebook/assets/js/187.e8380ed4.js"><link rel="prefetch" href="/notebook/assets/js/188.eddc8bee.js"><link rel="prefetch" href="/notebook/assets/js/189.fbc1840f.js"><link rel="prefetch" href="/notebook/assets/js/19.5997a514.js"><link rel="prefetch" href="/notebook/assets/js/190.a37bfe4c.js"><link rel="prefetch" href="/notebook/assets/js/191.e53a3d4b.js"><link rel="prefetch" href="/notebook/assets/js/192.2f5be408.js"><link rel="prefetch" href="/notebook/assets/js/193.4ca6de49.js"><link rel="prefetch" href="/notebook/assets/js/194.b8e51d9d.js"><link rel="prefetch" href="/notebook/assets/js/195.70e6b23a.js"><link rel="prefetch" href="/notebook/assets/js/196.5d5fbf2d.js"><link rel="prefetch" href="/notebook/assets/js/197.78456dab.js"><link rel="prefetch" href="/notebook/assets/js/198.4308331c.js"><link rel="prefetch" href="/notebook/assets/js/199.2e537849.js"><link rel="prefetch" href="/notebook/assets/js/20.fc057fd7.js"><link rel="prefetch" href="/notebook/assets/js/200.b3309bbf.js"><link rel="prefetch" href="/notebook/assets/js/201.4723461c.js"><link rel="prefetch" href="/notebook/assets/js/202.b15b5177.js"><link rel="prefetch" href="/notebook/assets/js/203.22c50e61.js"><link rel="prefetch" href="/notebook/assets/js/204.5b8b3b00.js"><link rel="prefetch" href="/notebook/assets/js/205.54ee7630.js"><link rel="prefetch" href="/notebook/assets/js/206.f3f20f94.js"><link rel="prefetch" href="/notebook/assets/js/207.a9608973.js"><link rel="prefetch" href="/notebook/assets/js/208.1a80a593.js"><link rel="prefetch" href="/notebook/assets/js/209.586fd293.js"><link rel="prefetch" href="/notebook/assets/js/21.cb4205ee.js"><link rel="prefetch" href="/notebook/assets/js/210.7829dd53.js"><link rel="prefetch" href="/notebook/assets/js/211.3ce139ab.js"><link rel="prefetch" href="/notebook/assets/js/212.84738a64.js"><link rel="prefetch" href="/notebook/assets/js/213.a631830d.js"><link rel="prefetch" href="/notebook/assets/js/214.9d64cf85.js"><link rel="prefetch" href="/notebook/assets/js/215.87030b6b.js"><link rel="prefetch" href="/notebook/assets/js/216.ddbe1944.js"><link rel="prefetch" href="/notebook/assets/js/217.16ae7e40.js"><link rel="prefetch" href="/notebook/assets/js/218.e7780d65.js"><link rel="prefetch" href="/notebook/assets/js/219.abae5e09.js"><link rel="prefetch" href="/notebook/assets/js/22.256014b4.js"><link rel="prefetch" href="/notebook/assets/js/220.8e3a8702.js"><link rel="prefetch" href="/notebook/assets/js/221.4c279d74.js"><link rel="prefetch" href="/notebook/assets/js/222.6c9b2595.js"><link rel="prefetch" href="/notebook/assets/js/223.cc072424.js"><link rel="prefetch" href="/notebook/assets/js/224.c663b40f.js"><link rel="prefetch" href="/notebook/assets/js/225.f3e52654.js"><link rel="prefetch" href="/notebook/assets/js/226.5e00402c.js"><link rel="prefetch" href="/notebook/assets/js/227.1c28ce97.js"><link rel="prefetch" href="/notebook/assets/js/228.42b8c305.js"><link rel="prefetch" href="/notebook/assets/js/229.df9760ec.js"><link rel="prefetch" href="/notebook/assets/js/23.a3d7d66a.js"><link rel="prefetch" href="/notebook/assets/js/230.cfe18f05.js"><link rel="prefetch" href="/notebook/assets/js/231.3a664a46.js"><link rel="prefetch" href="/notebook/assets/js/232.966ce9dc.js"><link rel="prefetch" href="/notebook/assets/js/233.fc06cb57.js"><link rel="prefetch" href="/notebook/assets/js/234.7bb9b7d4.js"><link rel="prefetch" href="/notebook/assets/js/235.b336116e.js"><link rel="prefetch" href="/notebook/assets/js/236.03a38f77.js"><link rel="prefetch" href="/notebook/assets/js/237.0dbda856.js"><link rel="prefetch" href="/notebook/assets/js/238.c1c19749.js"><link rel="prefetch" href="/notebook/assets/js/239.046875c1.js"><link rel="prefetch" href="/notebook/assets/js/24.8e5e267e.js"><link rel="prefetch" href="/notebook/assets/js/240.4bd9cdc0.js"><link rel="prefetch" href="/notebook/assets/js/241.c3dc5804.js"><link rel="prefetch" href="/notebook/assets/js/242.db0b1a91.js"><link rel="prefetch" href="/notebook/assets/js/243.4d9bd61d.js"><link rel="prefetch" href="/notebook/assets/js/244.ee57770b.js"><link rel="prefetch" href="/notebook/assets/js/245.02aab1c1.js"><link rel="prefetch" href="/notebook/assets/js/246.b76a18bb.js"><link rel="prefetch" href="/notebook/assets/js/247.75a673db.js"><link rel="prefetch" href="/notebook/assets/js/248.ad93f81d.js"><link rel="prefetch" href="/notebook/assets/js/249.fb75a938.js"><link rel="prefetch" href="/notebook/assets/js/25.b12f24fe.js"><link rel="prefetch" href="/notebook/assets/js/250.8395c0b6.js"><link rel="prefetch" href="/notebook/assets/js/251.16a6d2a4.js"><link rel="prefetch" href="/notebook/assets/js/252.ef3ee05e.js"><link rel="prefetch" href="/notebook/assets/js/253.78e3471e.js"><link rel="prefetch" href="/notebook/assets/js/254.a5783e07.js"><link rel="prefetch" href="/notebook/assets/js/255.2ab853f6.js"><link rel="prefetch" href="/notebook/assets/js/256.5430831b.js"><link rel="prefetch" href="/notebook/assets/js/257.99c8a0a4.js"><link rel="prefetch" href="/notebook/assets/js/258.4496955b.js"><link rel="prefetch" href="/notebook/assets/js/259.9152b1d2.js"><link rel="prefetch" href="/notebook/assets/js/26.0fce5172.js"><link rel="prefetch" href="/notebook/assets/js/260.072f65e6.js"><link rel="prefetch" href="/notebook/assets/js/261.0bca81af.js"><link rel="prefetch" href="/notebook/assets/js/262.9c9c5337.js"><link rel="prefetch" href="/notebook/assets/js/263.42470957.js"><link rel="prefetch" href="/notebook/assets/js/264.64b5f4fb.js"><link rel="prefetch" href="/notebook/assets/js/265.836a69c5.js"><link rel="prefetch" href="/notebook/assets/js/266.a00cdeb1.js"><link rel="prefetch" href="/notebook/assets/js/267.09dc5ae4.js"><link rel="prefetch" href="/notebook/assets/js/268.6fa6603e.js"><link rel="prefetch" href="/notebook/assets/js/269.3963ce5e.js"><link rel="prefetch" href="/notebook/assets/js/27.47ba3886.js"><link rel="prefetch" href="/notebook/assets/js/270.2826382d.js"><link rel="prefetch" href="/notebook/assets/js/271.3c746c23.js"><link rel="prefetch" href="/notebook/assets/js/272.30698dda.js"><link rel="prefetch" href="/notebook/assets/js/273.b06e3fd2.js"><link rel="prefetch" href="/notebook/assets/js/274.2016c7fa.js"><link rel="prefetch" href="/notebook/assets/js/275.f4aff624.js"><link rel="prefetch" href="/notebook/assets/js/276.e682aa74.js"><link rel="prefetch" href="/notebook/assets/js/277.0c3f41db.js"><link rel="prefetch" href="/notebook/assets/js/278.3c2d5251.js"><link rel="prefetch" href="/notebook/assets/js/279.a9af5703.js"><link rel="prefetch" href="/notebook/assets/js/28.6bac56c6.js"><link rel="prefetch" href="/notebook/assets/js/280.a5da28a3.js"><link rel="prefetch" href="/notebook/assets/js/281.8cc5a3ba.js"><link rel="prefetch" href="/notebook/assets/js/282.55227ff2.js"><link rel="prefetch" href="/notebook/assets/js/283.13f54ae9.js"><link rel="prefetch" href="/notebook/assets/js/284.88644dec.js"><link rel="prefetch" href="/notebook/assets/js/285.0670211f.js"><link rel="prefetch" href="/notebook/assets/js/286.afa43d34.js"><link rel="prefetch" href="/notebook/assets/js/287.9e98e933.js"><link rel="prefetch" href="/notebook/assets/js/288.175a8a9b.js"><link rel="prefetch" href="/notebook/assets/js/289.0d712953.js"><link rel="prefetch" href="/notebook/assets/js/29.3476ca1f.js"><link rel="prefetch" href="/notebook/assets/js/290.4b258761.js"><link rel="prefetch" href="/notebook/assets/js/291.e7ded33e.js"><link rel="prefetch" href="/notebook/assets/js/292.fcfca63e.js"><link rel="prefetch" href="/notebook/assets/js/293.4d6c0f7d.js"><link rel="prefetch" href="/notebook/assets/js/294.59b7e2de.js"><link rel="prefetch" href="/notebook/assets/js/295.0b8dc8f3.js"><link rel="prefetch" href="/notebook/assets/js/296.65434eb0.js"><link rel="prefetch" href="/notebook/assets/js/297.957ba4a7.js"><link rel="prefetch" href="/notebook/assets/js/298.dd81e487.js"><link rel="prefetch" href="/notebook/assets/js/299.eba0d36a.js"><link rel="prefetch" href="/notebook/assets/js/3.a80649d1.js"><link rel="prefetch" href="/notebook/assets/js/30.51a26022.js"><link rel="prefetch" href="/notebook/assets/js/300.23a6a024.js"><link rel="prefetch" href="/notebook/assets/js/301.eb4276c9.js"><link rel="prefetch" href="/notebook/assets/js/302.2c696c44.js"><link rel="prefetch" href="/notebook/assets/js/303.a748a576.js"><link rel="prefetch" href="/notebook/assets/js/304.95020a99.js"><link rel="prefetch" href="/notebook/assets/js/305.c4bc6072.js"><link rel="prefetch" href="/notebook/assets/js/306.74133b05.js"><link rel="prefetch" href="/notebook/assets/js/307.6ea724f3.js"><link rel="prefetch" href="/notebook/assets/js/308.fc7b065c.js"><link rel="prefetch" href="/notebook/assets/js/309.56497801.js"><link rel="prefetch" href="/notebook/assets/js/31.c351e10d.js"><link rel="prefetch" href="/notebook/assets/js/310.692379f9.js"><link rel="prefetch" href="/notebook/assets/js/311.b7393f95.js"><link rel="prefetch" href="/notebook/assets/js/312.f3eec1e1.js"><link rel="prefetch" href="/notebook/assets/js/313.9227351c.js"><link rel="prefetch" href="/notebook/assets/js/314.6960877d.js"><link rel="prefetch" href="/notebook/assets/js/315.f55a1979.js"><link rel="prefetch" href="/notebook/assets/js/316.6121039c.js"><link rel="prefetch" href="/notebook/assets/js/317.7ba118c8.js"><link rel="prefetch" href="/notebook/assets/js/318.2b71444c.js"><link rel="prefetch" href="/notebook/assets/js/319.bc0d5ccf.js"><link rel="prefetch" href="/notebook/assets/js/32.8a802a22.js"><link rel="prefetch" href="/notebook/assets/js/320.79f13ae1.js"><link rel="prefetch" href="/notebook/assets/js/321.21d3b0cf.js"><link rel="prefetch" href="/notebook/assets/js/322.87e4c143.js"><link rel="prefetch" href="/notebook/assets/js/323.4dee2eb7.js"><link rel="prefetch" href="/notebook/assets/js/324.f8c64322.js"><link rel="prefetch" href="/notebook/assets/js/325.c82057d6.js"><link rel="prefetch" href="/notebook/assets/js/326.3ea0d22b.js"><link rel="prefetch" href="/notebook/assets/js/327.90b878d9.js"><link rel="prefetch" href="/notebook/assets/js/328.59e55f0a.js"><link rel="prefetch" href="/notebook/assets/js/329.95fb2ef0.js"><link rel="prefetch" href="/notebook/assets/js/33.18cd7b09.js"><link rel="prefetch" href="/notebook/assets/js/330.ed1fb0e9.js"><link rel="prefetch" href="/notebook/assets/js/331.b84d88a9.js"><link rel="prefetch" href="/notebook/assets/js/332.20dffd14.js"><link rel="prefetch" href="/notebook/assets/js/333.d625fbd2.js"><link rel="prefetch" href="/notebook/assets/js/334.4fedc08a.js"><link rel="prefetch" href="/notebook/assets/js/335.c3b6c886.js"><link rel="prefetch" href="/notebook/assets/js/336.cf000555.js"><link rel="prefetch" href="/notebook/assets/js/337.891a7e6c.js"><link rel="prefetch" href="/notebook/assets/js/338.23da071e.js"><link rel="prefetch" href="/notebook/assets/js/339.92d07729.js"><link rel="prefetch" href="/notebook/assets/js/34.f39f39b2.js"><link rel="prefetch" href="/notebook/assets/js/340.09cb4417.js"><link rel="prefetch" href="/notebook/assets/js/341.3591e649.js"><link rel="prefetch" href="/notebook/assets/js/342.568a9320.js"><link rel="prefetch" href="/notebook/assets/js/343.e61b523f.js"><link rel="prefetch" href="/notebook/assets/js/344.61bb135b.js"><link rel="prefetch" href="/notebook/assets/js/345.f861e5aa.js"><link rel="prefetch" href="/notebook/assets/js/346.c5c70e0f.js"><link rel="prefetch" href="/notebook/assets/js/347.9b389847.js"><link rel="prefetch" href="/notebook/assets/js/348.eb62b86e.js"><link rel="prefetch" href="/notebook/assets/js/349.d4852195.js"><link rel="prefetch" href="/notebook/assets/js/35.c31fd7ed.js"><link rel="prefetch" href="/notebook/assets/js/350.f1db6bfd.js"><link rel="prefetch" href="/notebook/assets/js/351.4d86adaf.js"><link rel="prefetch" href="/notebook/assets/js/36.624192b1.js"><link rel="prefetch" href="/notebook/assets/js/37.680f8e12.js"><link rel="prefetch" href="/notebook/assets/js/38.f9ecec66.js"><link rel="prefetch" href="/notebook/assets/js/39.afab4ce6.js"><link rel="prefetch" href="/notebook/assets/js/4.03ba6111.js"><link rel="prefetch" href="/notebook/assets/js/40.f66ecac0.js"><link rel="prefetch" href="/notebook/assets/js/41.87cdca0e.js"><link rel="prefetch" href="/notebook/assets/js/42.08461558.js"><link rel="prefetch" href="/notebook/assets/js/43.ad5cf182.js"><link rel="prefetch" href="/notebook/assets/js/44.0bb6ad3f.js"><link rel="prefetch" href="/notebook/assets/js/45.5d2af6d4.js"><link rel="prefetch" href="/notebook/assets/js/46.8a06257e.js"><link rel="prefetch" href="/notebook/assets/js/47.3e37541c.js"><link rel="prefetch" href="/notebook/assets/js/48.024eda4c.js"><link rel="prefetch" href="/notebook/assets/js/49.a0685cf7.js"><link rel="prefetch" href="/notebook/assets/js/5.1071c8dd.js"><link rel="prefetch" href="/notebook/assets/js/50.130eaac4.js"><link rel="prefetch" href="/notebook/assets/js/51.0fe4dbd0.js"><link rel="prefetch" href="/notebook/assets/js/52.9d0ae64a.js"><link rel="prefetch" href="/notebook/assets/js/53.1ca09933.js"><link rel="prefetch" href="/notebook/assets/js/54.679cd78c.js"><link rel="prefetch" href="/notebook/assets/js/55.95cbe3a2.js"><link rel="prefetch" href="/notebook/assets/js/56.a58ec2af.js"><link rel="prefetch" href="/notebook/assets/js/57.0e59339a.js"><link rel="prefetch" href="/notebook/assets/js/58.487f643f.js"><link rel="prefetch" href="/notebook/assets/js/59.a8e9a1e3.js"><link rel="prefetch" href="/notebook/assets/js/6.707a1f11.js"><link rel="prefetch" href="/notebook/assets/js/60.c3080f7a.js"><link rel="prefetch" href="/notebook/assets/js/61.7f77e449.js"><link rel="prefetch" href="/notebook/assets/js/62.a5528e33.js"><link rel="prefetch" href="/notebook/assets/js/63.a787a8ee.js"><link rel="prefetch" href="/notebook/assets/js/64.7d3edfda.js"><link rel="prefetch" href="/notebook/assets/js/65.80e083e6.js"><link rel="prefetch" href="/notebook/assets/js/66.4076f29c.js"><link rel="prefetch" href="/notebook/assets/js/67.cf46f254.js"><link rel="prefetch" href="/notebook/assets/js/68.6fc8b1fd.js"><link rel="prefetch" href="/notebook/assets/js/69.4a344d72.js"><link rel="prefetch" href="/notebook/assets/js/7.c507c0e3.js"><link rel="prefetch" href="/notebook/assets/js/70.b13eef1a.js"><link rel="prefetch" href="/notebook/assets/js/71.20ad9776.js"><link rel="prefetch" href="/notebook/assets/js/72.30f44ef6.js"><link rel="prefetch" href="/notebook/assets/js/73.857a629d.js"><link rel="prefetch" href="/notebook/assets/js/74.a2b5a703.js"><link rel="prefetch" href="/notebook/assets/js/75.252e6fc0.js"><link rel="prefetch" href="/notebook/assets/js/76.d64e4a53.js"><link rel="prefetch" href="/notebook/assets/js/77.40db9cc6.js"><link rel="prefetch" href="/notebook/assets/js/78.7a635d12.js"><link rel="prefetch" href="/notebook/assets/js/79.b2249421.js"><link rel="prefetch" href="/notebook/assets/js/8.a5f34392.js"><link rel="prefetch" href="/notebook/assets/js/80.d325f684.js"><link rel="prefetch" href="/notebook/assets/js/81.2e8d667e.js"><link rel="prefetch" href="/notebook/assets/js/82.885af8d1.js"><link rel="prefetch" href="/notebook/assets/js/83.b601bf2e.js"><link rel="prefetch" href="/notebook/assets/js/84.758d5dba.js"><link rel="prefetch" href="/notebook/assets/js/85.2e75fb85.js"><link rel="prefetch" href="/notebook/assets/js/86.6c68d815.js"><link rel="prefetch" href="/notebook/assets/js/87.8fba1553.js"><link rel="prefetch" href="/notebook/assets/js/88.e30608d9.js"><link rel="prefetch" href="/notebook/assets/js/89.be2f87c8.js"><link rel="prefetch" href="/notebook/assets/js/9.1c775f56.js"><link rel="prefetch" href="/notebook/assets/js/90.88dd69c4.js"><link rel="prefetch" href="/notebook/assets/js/91.59a69041.js"><link rel="prefetch" href="/notebook/assets/js/92.b46ca339.js"><link rel="prefetch" href="/notebook/assets/js/93.aeaec51d.js"><link rel="prefetch" href="/notebook/assets/js/94.5a852633.js"><link rel="prefetch" href="/notebook/assets/js/95.4f445663.js"><link rel="prefetch" href="/notebook/assets/js/97.6cf3ba23.js"><link rel="prefetch" href="/notebook/assets/js/98.b48d73e6.js"><link rel="prefetch" href="/notebook/assets/js/99.f61a2e23.js">
    <link rel="stylesheet" href="/notebook/assets/css/0.styles.1b58b254.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/notebook/" class="home-link router-link-active"><img src="/notebook/img/logo.png" alt="notebook" class="logo"> <span class="site-name can-hide">notebook</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/notebook/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="基础" class="dropdown-title"><!----> <span class="title" style="display:;">基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/network/" class="nav-link">计算机网络</a></li><li class="dropdown-item"><!----> <a href="/notebook/computer-system/" class="nav-link">计算机系统</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-structure/" class="nav-link">数据结构与算法</a></li><li class="dropdown-item"><!----> <a href="/notebook/major/" class="nav-link">计算机专业课</a></li><li class="dropdown-item"><!----> <a href="/notebook/design-pattern/" class="nav-link">设计模式</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="开发" class="dropdown-title"><!----> <span class="title" style="display:;">开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://yubincloud.github.io/notebook-front/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  前端
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="/notebook/java/" class="nav-link">Java 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/python/" class="nav-link">Python 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/golang/" class="nav-link">Golang 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/git/" class="nav-link">Git</a></li><li class="dropdown-item"><!----> <a href="/notebook/software-architecture/" class="nav-link">软件设计与架构</a></li><li class="dropdown-item"><!----> <a href="/notebook/distributed-system/" class="nav-link">大数据与分布式系统</a></li><li class="dropdown-item"><h4>常见开发工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/nginx/" class="nav-link">Nginx</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据科学" class="dropdown-title"><!----> <span class="title" style="display:;">数据科学</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/data-science/spider/" class="nav-link">爬虫</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-science/py-data-analysis/" class="nav-link">Python 数据分析</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-warehouse/" class="nav-link">数据仓库</a></li><li class="dropdown-item"><h4>中间件</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/mysql/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/notebook/redis/" class="nav-link">Redis</a></li><li class="dropdown-subitem"><a href="/notebook/elasticsearch/" class="nav-link">Elasticsearch</a></li><li class="dropdown-subitem"><a href="/notebook/kafka/" class="nav-link">Kafka</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/deep-learning/" class="nav-link">深度学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/machine-learning/" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/kg/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/notebook/gnn/" class="nav-link">图神经网络</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全" class="dropdown-title"><!----> <span class="title" style="display:;">安全</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/security/application-security/" class="nav-link">应用安全</a></li><li class="dropdown-item"><!----> <a href="/notebook/security/penetration/" class="nav-link">渗透测试</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维" class="dropdown-title"><!----> <span class="title" style="display:;">运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/ops/linux/" class="nav-link">Linux</a></li><li class="dropdown-item"><!----> <a href="/notebook/ops/cloud-native/" class="nav-link">云原生</a></li></ul></div></div><div class="nav-item"><a href="/notebook/pages/interview/index/" class="nav-link">面试</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="我的" class="dropdown-title"><!----> <span class="title" style="display:;">我的</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/pages/my/favorite/" class="nav-link">收藏</a></li><li class="dropdown-item"><!----> <a href="/notebook/pages/my/good-sentence/" class="nav-link">paper 好句</a></li></ul></div></div> <a href="https://github.com/yubincloud/notebook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/head.jpg"> <div class="blogger-info"><h3>学习笔记</h3> <span>啦啦啦，向太阳~</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/notebook/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="基础" class="dropdown-title"><!----> <span class="title" style="display:;">基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/network/" class="nav-link">计算机网络</a></li><li class="dropdown-item"><!----> <a href="/notebook/computer-system/" class="nav-link">计算机系统</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-structure/" class="nav-link">数据结构与算法</a></li><li class="dropdown-item"><!----> <a href="/notebook/major/" class="nav-link">计算机专业课</a></li><li class="dropdown-item"><!----> <a href="/notebook/design-pattern/" class="nav-link">设计模式</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="开发" class="dropdown-title"><!----> <span class="title" style="display:;">开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://yubincloud.github.io/notebook-front/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  前端
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="/notebook/java/" class="nav-link">Java 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/python/" class="nav-link">Python 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/golang/" class="nav-link">Golang 开发</a></li><li class="dropdown-item"><!----> <a href="/notebook/git/" class="nav-link">Git</a></li><li class="dropdown-item"><!----> <a href="/notebook/software-architecture/" class="nav-link">软件设计与架构</a></li><li class="dropdown-item"><!----> <a href="/notebook/distributed-system/" class="nav-link">大数据与分布式系统</a></li><li class="dropdown-item"><h4>常见开发工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/nginx/" class="nav-link">Nginx</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据科学" class="dropdown-title"><!----> <span class="title" style="display:;">数据科学</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/data-science/spider/" class="nav-link">爬虫</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-science/py-data-analysis/" class="nav-link">Python 数据分析</a></li><li class="dropdown-item"><!----> <a href="/notebook/data-warehouse/" class="nav-link">数据仓库</a></li><li class="dropdown-item"><h4>中间件</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/mysql/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/notebook/redis/" class="nav-link">Redis</a></li><li class="dropdown-subitem"><a href="/notebook/elasticsearch/" class="nav-link">Elasticsearch</a></li><li class="dropdown-subitem"><a href="/notebook/kafka/" class="nav-link">Kafka</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/deep-learning/" class="nav-link">深度学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/machine-learning/" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/notebook/kg/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/notebook/gnn/" class="nav-link">图神经网络</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全" class="dropdown-title"><!----> <span class="title" style="display:;">安全</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/security/application-security/" class="nav-link">应用安全</a></li><li class="dropdown-item"><!----> <a href="/notebook/security/penetration/" class="nav-link">渗透测试</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维" class="dropdown-title"><!----> <span class="title" style="display:;">运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/ops/linux/" class="nav-link">Linux</a></li><li class="dropdown-item"><!----> <a href="/notebook/ops/cloud-native/" class="nav-link">云原生</a></li></ul></div></div><div class="nav-item"><a href="/notebook/pages/interview/index/" class="nav-link">面试</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="我的" class="dropdown-title"><!----> <span class="title" style="display:;">我的</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/pages/my/favorite/" class="nav-link">收藏</a></li><li class="dropdown-item"><!----> <a href="/notebook/pages/my/good-sentence/" class="nav-link">paper 好句</a></li></ul></div></div> <a href="https://github.com/yubincloud/notebook" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>深度学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Posts</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>PyTorch 入门</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>鱼书进阶-自然语言处理</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>深度学习-李宏毅</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/notebook/pages/lhy/regression/" class="sidebar-link">Regression</a></li><li><a href="/notebook/pages/lhy/training-tricks/" class="sidebar-link">神经网络训练不起来怎么办</a></li><li><a href="/notebook/pages/lhy/cnn/" class="sidebar-link">CNN</a></li><li><a href="/notebook/pages/lhy/self-attention/" class="sidebar-link">Self-Attention</a></li><li><a href="/notebook/pages/lhy/various-attention/" class="sidebar-link">各式各样的 Attention</a></li><li><a href="/notebook/pages/lhy/pointer-network/" class="sidebar-link">Pointer Network</a></li><li><a href="/notebook/pages/lhy/gnn/" class="sidebar-link">图神经网络</a></li><li><a href="/notebook/pages/lhy/transformer/" class="sidebar-link">Transformer</a></li><li><a href="/notebook/pages/lhy/gan/" class="sidebar-link">生成对抗网络 GAN</a></li><li><a href="/notebook/pages/lhy/self-supervised-learning/" class="sidebar-link">Self Supervised Learning</a></li><li><a href="/notebook/pages/lhy/bert-and-family/" class="sidebar-link">BERT and its family</a></li><li><a href="/notebook/pages/lhy/data-efficient/" class="sidebar-link">Data Efficient &amp; Parameter-Efficient Tuning</a></li><li><a href="/notebook/pages/lhy/auto-encoder/" class="sidebar-link">Auto-Encoder</a></li><li><a href="/notebook/pages/lhy/explainable-ml/" class="sidebar-link">机器学习的可解释性</a></li><li><a href="/notebook/pages/lhy/adversarial-attack/" class="sidebar-link">Adversarial Attack</a></li><li><a href="/notebook/pages/lhy/domain-adaptation/" class="sidebar-link">Domain Adaptation</a></li><li><a href="/notebook/pages/lhy/RL/" class="sidebar-link">强化学习</a></li><li><a href="/notebook/pages/lhy/network-compression/" class="sidebar-link">神经网络压缩</a></li><li><a href="/notebook/pages/lhy/life-long-learning/" class="sidebar-link">Life Long Learning</a></li><li><a href="/notebook/pages/lhy/meta-learning/" aria-current="page" class="active sidebar-link">Meta Learning</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/meta-learning/#_1-回顾-machine-learning" class="sidebar-link">1. 回顾 Machine Learning</a></li><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/meta-learning/#_2-introduction-of-meta-learning" class="sidebar-link">2. Introduction of Meta Learning</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_2-1-what-is-meta-learning" class="sidebar-link">2.1 What is Meta Learning?</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_2-2-meta-learning-step-1" class="sidebar-link">2.2 Meta Learning - Step 1</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_2-3-meta-learning-step-2" class="sidebar-link">2.3 Meta Learning - Step 2</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_2-4-meta-learning-step-3" class="sidebar-link">2.4 Meta Learning - Step 3</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_2-5-ml-v-s-meta" class="sidebar-link">2.5 ML v.s. Meta</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/meta-learning/#_3-what-is-learnable-in-a-learning-algorithm" class="sidebar-link">3. What is learnable in a learning algorithm?</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-1-review-gradient-descent" class="sidebar-link">3.1 Review: Gradient Descent</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-2-learning-to-initialize" class="sidebar-link">3.2 Learning to initialize</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-3-how-to-train-your-maml" class="sidebar-link">3.3 How to train your MAML?</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-4-maml-v-s-pre-training" class="sidebar-link">3.4 MAML v.s. Pre-training</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-5-maml-is-good-because" class="sidebar-link">3.5 MAML is good because …</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-6-学习-optimizer" class="sidebar-link">3.6 学习 Optimizer</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-7-network-architecture-search-nas" class="sidebar-link">3.7 Network Architecture Search（NAS）</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-8-data-processing" class="sidebar-link">3.8 Data Processing</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-9-sample-reweighting" class="sidebar-link">3.9 Sample Reweighting</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-10-beyond-gradient-descent" class="sidebar-link">3.10 Beyond Gradient Descent</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_3-11-learning-to-compare-metric-based-approach" class="sidebar-link">3.11 Learning to compare（metric-based approach）</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/notebook/pages/lhy/meta-learning/#_4-application" class="sidebar-link">4. Application</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_4-1-few-shot-image-classification" class="sidebar-link">4.1 Few-shot Image Classification</a></li><li class="sidebar-sub-header level3"><a href="/notebook/pages/lhy/meta-learning/#_4-2-other" class="sidebar-link">4.2 Other</a></li></ul></li></ul></li><li><a href="/notebook/pages/595df8/" class="sidebar-link">ChatGPT 是怎样炼成的</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>李宏毅-2017版</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>李宏毅-2019版</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>预训练语言模型-邵浩2021版</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>王树森</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>机器学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>知识图谱</span> <span class="arrow right"></span></p> <!----></section></li></ul> <div class="sidebar-slot sidebar-slot-bottom"><!-- 正方形 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="3508773082"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div></aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-6"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/notebook/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/notebook/categories/?category=AI" title="分类" data-v-06225672>AI</a></li><li data-v-06225672><a href="/notebook/categories/?category=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" title="分类" data-v-06225672>深度学习</a></li><li data-v-06225672><a href="/notebook/categories/?category=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%9D%8E%E5%AE%8F%E6%AF%85" title="分类" data-v-06225672>深度学习-李宏毅</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/yubincloud" target="_blank" title="作者" class="beLink" data-v-06225672>yubin</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2022-10-01</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">Meta Learning<!----></h1> <div class="page-slot page-slot-top"><!-- 固定100% * 90px可显示，max-height:90px未见显示-->
     <ins class="adsbygoogle"
          style="display:inline-block;width:100%;max-height:90px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6625304284"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="theme-vdoing-content content__default"><p>Meta Learning: Learn to learn（学习如何学习）</p> <blockquote><p>What does “meta” mean? meta-X = X about X</p></blockquote> <p>Can machine automatically determine the hyper-parameters?</p> <h2 id="_1-回顾-machine-learning"><a href="#_1-回顾-machine-learning" class="header-anchor">#</a> 1. 回顾 Machine Learning</h2> <p>Machine Learning = Looking for a function</p> <p><strong>step 1: Function with unknown</strong></p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001092728938.png" alt="image-20221001092728938" style="zoom:72%;"> <p><strong>step 2: Define loss function</strong></p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001092901925.png" alt="image-20221001092901925" style="zoom:72%;"> <p><strong>step 3: Optimization</strong></p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001093245180.png" alt="image-20221001093245180" style="zoom:72%;"></center> <h2 id="_2-introduction-of-meta-learning"><a href="#_2-introduction-of-meta-learning" class="header-anchor">#</a> 2. Introduction of Meta Learning</h2> <h3 id="_2-1-what-is-meta-learning"><a href="#_2-1-what-is-meta-learning" class="header-anchor">#</a> 2.1 What is Meta Learning?</h3> <p>其实“学习”这件事，它本身也是一个 function F：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001094058012.png" alt="image-20221001094058012" style="zoom:72%;"></center> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi></mjx-math></mjx-container> 的 input 是 training dataset，output 是一个 model。在 typical ML 中，这里的 learning algorithm <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi></mjx-math></mjx-container> 是 hand-crafted 的，而 <mark>Meta Learning</mark> 就是研究 “Can we learn this function <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi></mjx-math></mjx-container>?”</p> <p>怎么找这个 F 呢？Following the same three steps in ML!</p> <h3 id="_2-2-meta-learning-step-1"><a href="#_2-2-meta-learning-step-1" class="header-anchor">#</a> 2.2 Meta Learning - Step 1</h3> <p>What is <strong>learnable</strong> in a learning algorithm?</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001094947175.png" alt="image-20221001094947175" style="zoom:72%;"> <p>之前我们将 model 中 learnable parameters 记作 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi></mjx-math></mjx-container>，这里我们将 meta learning 中 learnable components 记作 <mark><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container></mark>，相对应的 F 就记为 <mark><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container></mark>。</p> <p>根据什么是 learnable components <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container>，可以将 meta learning 分成多个种类。</p> <h3 id="_2-3-meta-learning-step-2"><a href="#_2-3-meta-learning-step-2" class="header-anchor">#</a> 2.3 Meta Learning - Step 2</h3> <p>这一步我们需要 Define loss function <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> for learning algorithm <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container>。这样如果 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 小的话说明 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container> 是一个好的 learning algorithm，反之则是不好的 learning algorithm。</p> <p>How to define <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>? 什么情况下 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 应该小呢？如下图所示：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001193549307.png" alt="image-20221001193549307" style="zoom:72%;"> <p>那我们怎样知道一个 classifier 是好还是坏呢？我们可以 Evaluate the classifier on testing set。图示如下：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001194031345.png" alt="image-20221001194031345" style="zoom:72%;"> <p>这里怎样计算 loss <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 呢？计算方式和之前的 machine learning 是差不多的，图示如下：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001194833091.png" alt="image-20221001194833091" style="zoom:67%;"> <p>这里在测试资料上计算出来的 loss <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 越小，就代表我们训练出来的 classifier 越好，这样也就代表我们的 learning algorithm 越好。反之亦然。</p> <p>注意这里的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container> 是一个能够学出 binary classifier 的 learning algorithm，我们上面是在一个 apple 与 orange 的 binary classification 的 task 来评价它的，<strong>但在 meta learning 中，我们不会只拿一个 task 来评价一个 binary classifier learning 的 algorithm <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container></strong>，而是还会拿其他的 binary classification 的 task 来评价。如下图所示：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001195852322.png" alt="image-20221001195852322" style="zoom:67%;"> <p>在这里，左右两个 learning algorithm <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container> 是一样的，但 input 的资料不一样，那 output 的 binary classifier 也不一样。把所有 task 上得到的 loss 加起来，就得到了最终的 total loss <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>。</p> <blockquote><p>这里的举例只讲了两个 task，但实际上你会有非常多的 task，那么 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-munderover space="4" limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="N"></mjx-c></mjx-mi><mjx-spacer style="margin-top:0.291em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-msup space="2"><mjx-mi class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container></p></blockquote> <p>到了这里，有一点你可能觉得怪怪的。在 typical ML 中，你是用 training examples 去计算 loss，<strong>但在 meta learning 中，你却是用 training tasks 的 testing example 来计算的 loss</strong>。这一点 meta learning 与 typical ML 是不同的，在做 meta learning 时，我们是拿 task 作为的训练单位，所以你是可以将 training tasks 的 testing example 用于训练过程中。在之后讲完 meta learning 的整个流程，你会更加清晰。</p> <h3 id="_2-4-meta-learning-step-3"><a href="#_2-4-meta-learning-step-3" class="header-anchor">#</a> 2.4 Meta Learning - Step 3</h3> <p>我们已经有了 learning algorithm 的 loss function <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-munderover space="4" limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="N"></mjx-c></mjx-mi><mjx-spacer style="margin-top:0.291em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-msup space="2"><mjx-mi class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container>，现在我们要做的是寻找到能够 minimize <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container>，即 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mstyle style="color:blue;"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-mstyle><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-n"><mjx-c c="a"></mjx-c><mjx-c c="r"></mjx-c><mjx-c c="g"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="2061"></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c="m"></mjx-c><mjx-c c="i"></mjx-c><mjx-c c="n"></mjx-c></mjx-mo><mjx-mi space="2" class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>。</p> <p>怎么做呢？Using the optimization approach you know:</p> <ul><li>If you know how to compute <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container> =&gt; <em>Gradient descent is your friend.</em></li> <li>What if <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> is not differentiable? =&gt; <em>用 RL / Evalutionary Algorithm 硬 train 一发</em></li></ul> <p>反正不管你用什么方法，你最终可以学习出一个 “learning algorithm” <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-mstyle style="color:blue;"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-mstyle></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container></p> <p>整个 meta learning 的 framework 如下图所示：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001202936086.png" alt="image-20221001202936086" style="zoom:74%;"></center> <ul><li>我们先从 training task 中学习出一个 learned “learning algorithm” <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container>，然后给他输入 testing task 中的 training examples，得到一个 classifier <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container>，这时再把这个 classifier 用在 testing task 的 testing examples 里面得到我们想要的结果。</li> <li>在这个过程中，testing task 是我们真正关心的 task，而 training tasks 是与 testing task 无关的 tasks，这些 training tasks 就是用来寻找出 learned 的演算法 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container>。</li></ul> <p>像这种学习的演算法厉害在哪里呢？一种东西叫做”few-shot learning“，即”小样本学习“，它期待机器只看几个 training example 就可以让 model 学会做 classification。<strong>而在这里 meta learning 中，testing task 就只需要 little labeled training data 就可以</strong>。</p> <p><strong>通常想要实现 few-shot learning，这种演算法是人类难以想象出来的，往往需要 meta learning 来把这个演算法给找出来</strong>。所以注意区分好 few-shot learning 与 meta learning 的微妙区别。</p> <blockquote><p>在 meta learning 中，单说”training data“是很容易造成误解的，所以使用时要小心。在很多 paper 中就很不讲究，很多说的 training data 很容易导致误解。</p></blockquote> <h3 id="_2-5-ml-v-s-meta"><a href="#_2-5-ml-v-s-meta" class="header-anchor">#</a> 2.5 ML v.s. Meta</h3> <h4 id="_2-5-1-goal"><a href="#_2-5-1-goal" class="header-anchor">#</a> 2.5.1 Goal</h4> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001210356592.png" alt="image-20221001210356592" style="zoom:72%;"> <h4 id="_2-5-2-training-data"><a href="#_2-5-2-training-data" class="header-anchor">#</a> 2.5.2 Training Data</h4> <ul><li>在 machine learning 里面，我们是拿一个 task 的 training set 来进行训练；</li> <li>在 meta learning 里面，我们是拿“task”来进行训练，也就是用 training tasks 来进行训练，在每一个 training task 里面，都有 training data 和 testing data。</li></ul> <p>为了避免对“训练资料”这个说法产生歧义，在 meta learning 中，一个 training task 里面的 training examples 称为 <mark>Support set</mark>，testing examples 称为 <mark>Query set</mark>。在一些文献中就是这么叫的。</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001225153142.png" alt="image-20221001225153142" style="zoom:67%;"> <h4 id="_2-5-3-training"><a href="#_2-5-3-training" class="header-anchor">#</a> 2.5.3 Training</h4> <ul><li>在 machine learning 中，我们是有一个 hand-crafted 的 learning algorithm，然后把训练资料丢进去，得到一个训练的 classifier <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-mstyle style="color:green;"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-mstyle></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container></li> <li>在 meta learning 中，我们是有一堆 training tasks，然后我们是要用这一堆 training tasks 去得到一个 learned “learning algorithm” <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-mstyle style="color:blue;"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-mstyle></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container></li></ul> <p>这里，把 meta learning 的这种 involve 一大堆 tasks 的训练叫做 <mark>Across-task Training</mark></p> <p>；而把一般 ML 的训练叫做 <mark>Within-task Training</mark>。这样就可以区别两种 training 的过程了：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001232645243.png" alt="image-20221001232645243" style="zoom:67%;"> <h4 id="_2-5-4-testing"><a href="#_2-5-4-testing" class="header-anchor">#</a> 2.5.4 Testing</h4> <p>我们把 meta learning 中这个 testing 过程叫做 <mark>Across-task Testing</mark>，而一般 ML 的 testing 过程叫做 <mark>Within-task Testing</mark>，图示如下：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001234414544.png" alt="image-20221001234414544" style="zoom:67%;"> <p>在 meta learning 中，我们要测试的不是一个 classifier 的好坏，而是一个 learning algorithm 的好坏，因此<strong>在一个 Across-task Testing 中，还包含了 Within-task Training  和 Within-task Testing 过程</strong>。在有些文献中，一次 Within-task Training 加一次 Within-task Testing 的流程叫做一个 <mark>Episode</mark>。</p> <h4 id="_2-5-5-loss"><a href="#_2-5-5-loss" class="header-anchor">#</a> 2.5.5 Loss</h4> <p>typical ML 与 meta learning 的 loss 计算方式也不一样：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001235018279.png" alt="image-20221001235018279" style="zoom:67%;"> <ul><li>ML 的 L 是从一个 task 中算出来的；</li> <li>Meta learning 的 L 是从一把 tasks 中算出来的。</li></ul> <p>我们单独看一下 meta learning 中 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 的计算：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221001235645349.png" alt="image-20221001235645349" style="zoom:67%;"> <ul><li>在进行一次 Across-task training 计算 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 时，需要计算多个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container>，而每一个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math></mjx-container> 的计算都需要经过一个 Within-task training + Within-task testing 的 Episode，计算量还是很大的。</li> <li>在“Learning to initialize”系列的 paper 中，也称 Across-task training 叫做 <strong>Outer Loop</strong>，称 Within-task training 叫做 <strong>Inner Loop</strong>。</li></ul> <h4 id="_2-5-6-两者的相似点"><a href="#_2-5-6-两者的相似点" class="header-anchor">#</a> 2.5.6 两者的相似点</h4> <p>What you know about ML can usually apply to meta learning:</p> <ul><li>Overfitting on training tasks</li> <li>Get more training tasks to improve performance</li> <li>Task augmentation</li> <li>There are also hyperparameters when learning a learning algorithm ...... （所以做 meta learning 也是需要暴调一波参数的）</li> <li>Development task（这类似于 ML 的 validation set 用来调 hyper-parameters，在很多文献里并没有这种 task 而是只有 training tasks 和 testing task，但李老师认为应该有）</li></ul> <blockquote><p>有没有可能套娃？这是个梗啦，以后可能有人会提出 meta meta learning ......</p></blockquote> <h2 id="_3-what-is-learnable-in-a-learning-algorithm"><a href="#_3-what-is-learnable-in-a-learning-algorithm" class="header-anchor">#</a> 3. What is learnable in a learning algorithm?</h2> <h3 id="_3-1-review-gradient-descent"><a href="#_3-1-review-gradient-descent" class="header-anchor">#</a> 3.1 Review: Gradient Descent</h3> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002104525213.png" alt="image-20221002104525213" style="zoom:67%;"> <p>首先这里的 initial parameters <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 是 learnable 的，而且我们知道好的 initial parameters 对训练有很大作用。那我们在 meta learning 中能不能可以透过一些 learning tasks 找出一些对训练特别有帮助的 initial parameters  <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 呢？可以！下面介绍。</p> <h3 id="_3-2-learning-to-initialize"><a href="#_3-2-learning-to-initialize" class="header-anchor">#</a> 3.2 Learning to initialize</h3> <p>回答上面问题的最著名的方法就是 <mark>MAML</mark>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002152954312.png" alt="image-20221002152954312" style="zoom:80%;"></center> <ul><li>这里不再细讲这些模型的细节，可以参考原论文，作业题会问。</li></ul> <h3 id="_3-3-how-to-train-your-maml"><a href="#_3-3-how-to-train-your-maml" class="header-anchor">#</a> 3.3 How to train your MAML?</h3> <p>正如之前讲的，我们做 meta learning 时也有很多需要调的 hyper-parameters，所以在用 MAML 时，虽然你是去 learn 一个 initialize 的 parameters，但这个 learn 的过程也有很多 hyper-parameters 需要你去决定。其实最开始的 MAML 不是那么好 train 的，于是就有人发了 paper 叫 “How to train your MAML”，他用了三种 MAML random seed 来 train，发现有两次是 train 不起来的，于是这篇 peper 就新提出了一种方法叫做 <strong>MAML++</strong>:</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002153741780.png" alt="image-20221002153741780" style="zoom:80%;"></center> <p>具体的细节需要再去读原文章。</p> <h3 id="_3-4-maml-v-s-pre-training"><a href="#_3-4-maml-v-s-pre-training" class="header-anchor">#</a> 3.4 MAML v.s. Pre-training</h3> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002154231857.png" alt="image-20221002154231857" style="zoom:67%;"></center> <p>最直观的区别可能就是，MAML 中训练所用的数据是 labeled 的，而 Pre-training 中则是没有 label 的。</p> <p>其实这里说的 Pre-training 是近期的做法，在更早之前，人们是把来自不同 tasks 的 data 统统放在一起里面训练一个 model，来得到一个好的初始化参数，这现在也被叫做 <mark>multi-task learning</mark>，这种 multi-task learning 往往被用作 meta learning 的 baseline。具体了解它与 MAML 的差别可以参考李老师的相关视频（链接就不放在这里了）。</p> <p>在 machine learning 中，对 domain 和 task 的界限并没有那么清晰，你也可以说不同的 task 就是不同的 domain，那这 meta learning 其实也很像 domain adaptation 了。</p> <blockquote><p>我们读文献时不要太拘泥于这些，关键的是这个词汇背后所代表的含义。</p></blockquote> <h3 id="_3-5-maml-is-good-because"><a href="#_3-5-maml-is-good-because" class="header-anchor">#</a> 3.5 MAML is good because …</h3> <p>MAML 为什么好呢？这里有两个假设：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002170632725.png" alt="image-20221002170632725" style="zoom:80%;"></center> <ul><li><strong>Rapid Learning</strong> 的假设是说，MAML 找到的 initial parameter 很厉害，它可以让我们 gradient descent 这种 learning algorithm 快速地找到每一个 task 上好的参数</li> <li><strong>Feature Reuse</strong> 的假设是说，这个 initial parameter 本来就跟每一个 task 上最终好的结果已经非常接近了</li></ul> <p>有一篇 paper 是 <a href="https://arxiv.org/abs/1909.09157" target="_blank" rel="noopener noreferrer">Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，它告诉我们 feature reuse 来是 MAML 好的关键，同时提出了另外一种 MAML 的变形 <strong>ANIL</strong>(Almost No Inner Loop)。</p> <p>MAML 有很多变形和相关资料，More about MAML：</p> <ul><li>More mathematical details behind MAML：https://youtu.be/mxqzGwp_Qys</li> <li>First order MAML (FOMAML)： https://youtu.be/3z997JhL9Oo</li> <li>Reptile：https://youtu.be/9jJe2AD35P8</li></ul> <h3 id="_3-6-学习-optimizer"><a href="#_3-6-学习-optimizer" class="header-anchor">#</a> 3.6 学习 Optimizer</h3> <p>刚刚讲了说我们可以学习初始化的参数，我们还可以学习 Optimizer，在 update 参数的时候，我们需要决定 learning rate、momentum 等等 hyper-parameter，那像这种 hyper-parameter 能不能用学习的方式把它用 meta learning 学习出来呢？这是可以的。</p> <p>NIPS 2016 有一篇 paper “Learning to learn by gradient descent by gradient descent”，这篇 paper 里面就是直接 learn 一个 optimizer，是自动根据 learning tasks 学出来的。具体可以参考该 paper。</p> <h3 id="_3-7-network-architecture-search-nas"><a href="#_3-7-network-architecture-search-nas" class="header-anchor">#</a> 3.7 Network Architecture Search（NAS）</h3> <p>除了可以训练 initial parameters、optimizer，能不能也训练 Network Architecture 呢？这就是需要将 Network Architecture 当作 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container>：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002214248148.png" alt="image-20221002214248148" style="zoom:72%;"></center> <p>研究训练 Network Architecture 的一系列研究就是鼎鼎大名的 <mark>Network Architecture Search</mark>（<strong>NAS</strong>）。</p> <p>在 NAS 里面，既然 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container> 是 Network Architecture，那我们的目标是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mstyle style="color:red;"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.131em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-mstyle><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-n"><mjx-c c="a"></mjx-c><mjx-c c="r"></mjx-c><mjx-c c="g"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="2061"></mjx-c></mjx-mo><mjx-munder space="2" limits="false"><mjx-mo class="mjx-n"><mjx-c c="m"></mjx-c><mjx-c c="i"></mjx-c><mjx-c c="n"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-munder><mjx-mi space="2" class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>，但由于 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container> 是 Network Architecture，那显然对 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container> 做微分 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-n"><mjx-c c="2207"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 就有问题了。怎么办呢？记得我们说过，<strong>当你遇到 Optimization 没法算微分的时候，用 RL 硬 train 一发</strong>！</p> <p>用 RL 怎么做呢？An agent uses a set of actions to determine the network architecture:</p> <ul><li><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mstyle style="color:blue;"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-mstyle></mjx-math></mjx-container>：the agent’s parameters</li> <li><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mstyle style="color:blue;"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-mstyle><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>: Reward to be maximized</li></ul> <p>用 RL 做 NAS 的一个早期 work 的图示如下：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002220422808.png" alt="image-20221002220422808" style="zoom:80%;"></center> <ul><li>这里是把 agent 想成一个 RNN，每次会输出一个跟 Network Architecture 有关的参数。</li></ul> <blockquote><p>RL 解 NAS 问题的相关文献：</p> <ul><li><a href="https://arxiv.org/abs/1611.01578" target="_blank" rel="noopener noreferrer">Neural Architecture Search with Reinforcement Learning<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Zoph_Learning_Transferable_Architectures_CVPR_2018_paper.html" target="_blank" rel="noopener noreferrer">Learning Transferable Architectures for Scalable Image Recognition<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="http://proceedings.mlr.press/v80/pham18a.html" target="_blank" rel="noopener noreferrer">Efficient Neural Architecture Search via Parameters Sharing<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>Evolution Algorithm 解 NAS 问题的相关文献：</p> <ul><li><a href="http://proceedings.mlr.press/v70/real17a.html" target="_blank" rel="noopener noreferrer">Large-Scale Evolution of Image Classifiers<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://ojs.aaai.org/index.php/AAAI/article/view/4405" target="_blank" rel="noopener noreferrer">Regularized Evolution for Image Classifier Architecture Search<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1711.00436" target="_blank" rel="noopener noreferrer">Hierarchical Representations for Efficient Architecture Search<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></blockquote> <p>其实，如果你硬要把 Network Architecture <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container> 改一下，让它变得可以微分，也是可以的，有一个经典的做法 <mark>DARTS</mark>，让 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container> 变得可以微分从而可以用 gradient descent 来做 optimization：（<a href="https://arxiv.org/abs/1806.09055" target="_blank" rel="noopener noreferrer">DARTS: Differentiable Architecture Search<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002221750679.png" alt="image-20221002221750679" style="zoom:73%;"></center> <h3 id="_3-8-data-processing"><a href="#_3-8-data-processing" class="header-anchor">#</a> 3.8 Data Processing</h3> <p>除了 Network Architecture 以外，还有 Data Process 也是可以 learn 的。比如能不能让 machine 自动找出怎样做 Data Augmentation 呢？这也是有可能的，可以参考如下文献：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002222402986.png" alt="image-20221002222402986" style="zoom:67%;"></center> <h3 id="_3-9-sample-reweighting"><a href="#_3-9-sample-reweighting" class="header-anchor">#</a> 3.9 Sample Reweighting</h3> <p>有时候 training 的时候，我们需要给不同的 sample 以不同的 weight，但是要怎么给每一笔 data 不同的权重呢？比如对于离 boundary 近的 sample，有人觉得这些比较难的 sample 应该给一个 larger weights，有人觉得这些 noisy sample 应该给一个 smaller weights。这里我们期望说，可以让 machine 学到根据 data 的特性自动决定说 sample 的 weights 应该怎么设计：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002223007241.png" alt="image-20221002223007241" style="zoom:72%;"></center> <ul><li>上图的 sample weighting strategy 是 learnable 的。</li></ul> <h3 id="_3-10-beyond-gradient-descent"><a href="#_3-10-beyond-gradient-descent" class="header-anchor">#</a> 3.10 Beyond Gradient Descent</h3> <p>我们刚刚讲的方法都是在围绕着 gradient descent 来做改进，刚才所有方法都是 learn 了一个 gradient descent 的其中一个 component。但我们有没有可能完全舍弃掉 gradient descent 呢？比如说我们就直接 learn 一个 network，这个 network 的 parameters 是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3D5"></mjx-c></mjx-mi></mjx-math></mjx-container>，输入训练资料，直接输出训练好的结果 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container>，如果真的这样，那可以说机器发明了新的 learning algorithm 而抛弃了 gradient descent！有可能做到这件事嘛？也不是完全没有可能的，已经有一些论文往这个方向进展：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002224414971.png" alt="image-20221002224414971" style="zoom:72%;"></center> <h3 id="_3-11-learning-to-compare-metric-based-approach"><a href="#_3-11-learning-to-compare-metric-based-approach" class="header-anchor">#</a> 3.11 Learning to compare（metric-based approach）</h3> <p>到目前为止，我们都是将训练和测试分成两个阶段：先拿 training data 训练出一个 learning algorithm（function <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="F"></mjx-c></mjx-mi></mjx-math></mjx-container>），然后输出训练好的结果，再把训练好的结果用到测试资料上。但有没有可能更进一步，把整个 episode（一次 training + 一次 testing）包在一个 network 里面呢？这是有可能的，有一个系列的做法就是直接把 training data 和 testing data 当做 network 的 input：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002225045232.png" alt="image-20221002225045232" style="zoom:67%;"></center> <ul><li>这种就是先把 training data 看完后，也不知道里面发生了什么，再直接把 testing data 输入进去。</li></ul> <p>有一个系列的 meta learning 的做法叫做 <mark>Learning to compare</mark>，又叫做 <mark>metric-based approach</mark>，这一系列的做法就可以看做是训练和测试没有分界。具体可以参考过去上课的录影：</p> <img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002225345826.png" alt="image-20221002225345826" style="zoom:80%;"> <h2 id="_4-application"><a href="#_4-application" class="header-anchor">#</a> 4. Application</h2> <h3 id="_4-1-few-shot-image-classification"><a href="#_4-1-few-shot-image-classification" class="header-anchor">#</a> 4.1 Few-shot Image Classification</h3> <p>今天在做 meta learning 时，最常拿来测试 meta learning 技术的任务是 <strong>Few-shot Image Classification</strong>。在这个任务里，每个 class 都只有很少的几张 image，你希望透过这样一点点的资料，就可以训练出一个 model，你给 model 一张 image，它就能告诉你这张 image 属于哪个 class：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002232856764.png" alt="image-20221002232856764" style="zoom:67%;"></center> <p>在做这种任务时，你时常会听到一个术语：<strong>N-ways K-shot classification</strong>：</p> <div class="custom-block theorem"><p class="title">N-ways K-shot classification</p><p><strong><font color="blue">N-ways</font> <font color="orange">K-shot</font> classification</strong>: In each task, there are <font color="blue">N classes</font>, each has <font color="orange">K examples</font>.</p></div><p>在 meta learning 里面，你需要去准备许多 N-ways K-shot tasks 作为 training 和 testing tasks。那怎样去找这一堆 N-ways K-shot 的 training tasks 呢？</p> <p>在文献上最常用的是使用 <mark>Omniglot</mark> 这个 corpus 当作 benchmark corpus：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221002235938293.png" alt="image-20221002235938293" style="zoom:72%;"></center> <ul><li>在这个 corpus 中，有 1623 个 characters，每个 character 有 20 个 examples，比如右上角的 20 个 example 是同一个 character。</li></ul> <p><strong>在有了 Omniglot 这个 corpus 之后，你就可以制造 N-ways K-shot 的 tasks 了</strong>。比如你选出 20 个 characters，然后每个 character 就只取一个 example，这样你就得到一个 20 ways 1 shot 的 task。测试资料的做法是，你再从那 20 个 characters 里面找一个 example 出来，然后接下来问这个 Query set 是这 20 个 class 里面的哪一个。如下图所示：</p> <center><img src="https://notebook-img-1304596351.cos.ap-beijing.myqcloud.com/img/image-20221003000713603.png" alt="image-20221003000713603" style="zoom:72%;"></center> <ul><li>Split your characters into training and testing characters
<ul><li>Sample N training characters, sample K examples from each sampled characters -&gt; <em>one training task</em></li> <li>Sample N testing characters, sample K examples from each sampled characters -&gt; <em>one testing task</em></li></ul></li></ul> <h3 id="_4-2-other"><a href="#_4-2-other" class="header-anchor">#</a> 4.2 Other</h3> <p>Meta learning 不只是可以用在 Omniglot 上，<a href="https://speech.ee.ntu.edu.tw/~tlkagk/meta_learning_table.pdf" target="_blank" rel="noopener noreferrer">table<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 列举了 meta learning 在语音处理、NLP 等方向的应用。至于 meta learning 能走多远，我们拭目以待。</p></div></div> <div class="page-slot page-slot-bottom"><!-- 横向自适应 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6620245489"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="page-edit"><div class="edit-link"><a href="https://github.com/yubincloud/notebook/edit/master/docs/AI/01.深度学习/15.深度学习-李宏毅/75.Meta Learning.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2022/10/03, 13:55:17</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/notebook/pages/lhy/life-long-learning/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Life Long Learning</div></a> <a href="/notebook/pages/595df8/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">ChatGPT 是怎样炼成的</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/notebook/pages/lhy/life-long-learning/" class="prev">Life Long Learning</a></span> <span class="next"><a href="/notebook/pages/595df8/">ChatGPT 是怎样炼成的</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/notebook/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/notebook/pages/ml/lhy/drl17/"><div>
            Deep Reinforcement Learning
            <!----></div></a> <span class="date">10-03</span></dt></dl><dl><dd>02</dd> <dt><a href="/notebook/pages/mysql/geektime/misdeletion/"><div>
            误删数据后怎么办
            <!----></div></a> <span class="date">04-06</span></dt></dl><dl><dd>03</dd> <dt><a href="/notebook/pages/mysql/geektime/multi-slaves/"><div>
            MySQL 一主多从
            <!----></div></a> <span class="date">03-22</span></dt></dl> <dl><dd></dd> <dt><a href="/notebook/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="yubin_inbuy@163.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/yubincloud" title="GitHub" target="_blank" class="iconfont icon-github"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2021-2024
    <span>yubincloud | <a href="https://github.com/yubincloud/notebook/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <div class="custom-html-window custom-html-window-rb" style="display:;"><div class="custom-wrapper"><span class="close-but">×</span> <div><!-- 固定160*160px -->
      <ins class="adsbygoogle"
          style="display:inline-block;max-width:160px;max-height:160px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="8377369658"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
      </div></div></div></div><div class="global-ui"><div></div></div></div>
    <script src="/notebook/assets/js/app.2bf3b6c1.js" defer></script><script src="/notebook/assets/js/2.0ad58009.js" defer></script><script src="/notebook/assets/js/96.6299f802.js" defer></script>
  </body>
</html>
